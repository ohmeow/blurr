# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/00_utils.ipynb (unless otherwise specified).

__all__ = ['str_to_class', 'Singleton', 'ModelHelper', 'BLURR_MODEL_HELPER', 'HF_ARCHITECTURES', 'HF_TASKS_ALL',
           'HF_TASKS_AUTO', 'HF_MODELS', 'ForMaskedLMTask', 'ForQuestionAnsweringTask', 'ForSequenceClassificationTask',
           'ForTokenClassificationTask', 'ForPreTrainingTask', 'WithLMHeadTask', 'ForConditionalGenerationTask',
           'ForMultipleChoiceTask', 'ForNextSentencePredictionTask', 'ForQuestionAnsweringSimpleTask',
           'WithLMHeadModelTask', 'ForClassificationTask']

# Cell
import sys, inspect
from enum import Enum

import pandas as pd
import torch

from transformers import *
from fastai2.text.all import *

# Cell
def str_to_class(classname):
    "converts string representation to class"
    return getattr(sys.modules[__name__], classname)

# Cell
class Singleton:
    def __init__(self,cls):
        self._cls, self._instance = cls, None

    def __call__(self, *args, **kwargs):
        if self._instance == None: self._instance = self._cls(*args, **kwargs)
        return self._instance

# Cell
@Singleton
class ModelHelper():

    def __init__(self):
        # get hf classes (tokenizers, configs, models, etc...)
        transformer_classes = inspect.getmembers(sys.modules[__name__],
                                                 lambda member: inspect.isclass(member)
                                                 and member.__module__.startswith('transformers.'))

        # build a df that we can query against to get various transformers objects/info
        self._df = pd.DataFrame(transformer_classes, columns=['class_name', 'class_location'])

        # add the module each class is included in
        self._df['module'] = self._df.class_location.apply(lambda v: v.__module__)

        # remove class_location (don't need it anymore)
        self._df.drop(labels=['class_location'], axis=1, inplace=True)

        # break up the module into separate cols
        module_parts_df = self._df.module.str.split(".", n = -1, expand = True)
        for i in range(len(module_parts_df.columns)):
            self._df[f'module_part_{i}'] = module_parts_df[i]

        # using module part 1, break up the functional area and arch into separate cols
        module_part_1_df = self._df.module_part_1.str.split("_", n = 1, expand = True)
        self._df[['functional_area', 'arch']] = module_part_1_df

        # if functional area = modeling, pull out the task it is built for
        model_type_df = self._df[(self._df.functional_area == 'modeling')].class_name.str.split('For', n=1, expand=True)

        model_type_df[1] = np.where(model_type_df[1].notnull(),
                                    'For' + model_type_df[1].astype(str),
                                    model_type_df[1])

        self._df['model_task'] = model_type_df[1]

        model_type_df = self._df[(self._df.functional_area == 'modeling')].class_name.str.split('With', n=1, expand=True)
        model_type_df[1] = np.where(model_type_df[1].notnull(),
                                    'With' + model_type_df[1].astype(str),
                                    self._df[(self._df.functional_area == 'modeling')].model_task)

        self._df['model_task'] = model_type_df[1]

        # look at what we're going to remove (use to verify we're just getting rid of stuff we want too)
        # df[~df['hf_class_type'].isin(['modeling', 'configuration', 'tokenization'])]

        # only need these 3 functional areas for our querying purposes
        self._df = self._df[self._df['functional_area'].isin(['modeling', 'configuration', 'tokenization'])]

    def get_architectures(self):
        """Used to get all the architectures supported by your `Transformers` install"""
        return self._df[(self._df.arch.notna()) & (self._df.arch != None)].arch.unique().tolist()

    def get_config(self, arch):
        """Used the locate the name of the configuration class for a given architecture"""
        return self._df[(self._df.functional_area == 'configuration') & (self._df.arch == arch)].class_name.values[0]

    def get_tokenizers(self, arch):
        """Used to get the available huggingface tokenizers for a given architecture. Note: There may be
        multiple tokenizers and so this returns a list.
        """
        return self._df[(self._df.functional_area == 'tokenization') & (self._df.arch == arch)].class_name.values

    def get_tasks(self, arch=None):
        """Get the type of tasks for which there is a custom model for (*optional: by architecture*).
        There are a number of customized models built for specific tasks like token classification,
        question/answering, LM, etc....
        """
        query = ['model_task.notna()']
        if (arch): query.append(f'arch == "{arch}"')

        return self._df.query(' & '.join(query)).model_task.unique().tolist()

    def get_models(self, arch=None, task=None):
        """The transformer models available for use (optional: by architecture | task)"""
        query = ['functional_area == "modeling"']
        if (arch): query.append(f'arch == "{arch}"')
        if (task): query.append(f'model_task == "{task}"')

        return self._df.query(' & '.join(query)).class_name.tolist()

    def get_classes_for_model(self, model_name_or_enum):
        """Get tokenizers, config, and model for a given model name / enum"""
        model_name = model_name_or_enum if isinstance(model_name_or_enum, str) else model_name_or_enum.name

        meta = self._df[self._df.class_name == model_name]
        tokenizers = self.get_tokenizers(meta.arch.values[0])
        config = self.get_config(meta.arch.values[0])

        return ([str_to_class(tok) for tok in tokenizers], str_to_class(config), str_to_class(model_name))

    def get_model_architecture(self, model_name_or_enum):
        """Get the architecture for a given model name / enum"""
        model_name = model_name_or_enum if isinstance(model_name_or_enum, str) else model_name_or_enum.name
        return self._df[self._df.class_name == model_name].arch.values[0]

    def get_auto_hf_objects(self, pretrained_model_name_or_path, task, config=None):
        """Returns the architecture (str), tokenizer (obj), config (obj), and model (obj)
        given a known pre-trained model name or path and a task using Hugginface `AutoModel` capabilities.
        If a `config` is passed in, it will be  used when building the model, else the default configuration
        will be used (e.g., `AutoConfig.from_pretrained(...)`)
        """
        tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path)
        config = AutoConfig.from_pretrained(pretrained_model_name_or_path) if (config is None) else config

        model = str_to_class(f'AutoModel{task.name}').from_pretrained(pretrained_model_name_or_path,
                                                                      config=config)
        arch = self.get_model_architecture(type(model).__name__)

        return (arch, tokenizer, config, model)

    def get_hf_objects(self, pretrained_model_name_or_path, tokenizer_cls, model_cls, config=None):
        """Returns the architecture (str), tokenizer (class), config (class), and model (class)
        given a known pre-trained model name or path, a tokenizer class, and model class.  If a `config` object
        is passed in, it will be used when building the model, else the default configuration will be used.
        """
        tokenizer = tokenizer_cls.from_pretrained(pretrained_model_name_or_path)

        if (config is None):
            model = str_to_class(model_cls.name).from_pretrained(pretrained_model_name_or_path)
            config = model.config
        else:
            model = str_to_class(model_cls.name).from_pretrained(pretrained_model_name_or_path, config=config)

        arch = self.get_model_architecture(type(model).__name__)

        return (arch, tokenizer, config, model)


# Cell
BLURR_MODEL_HELPER = ModelHelper()

# Cell
HF_ARCHITECTURES = Enum('HF_ARCHITECTURES', BLURR_MODEL_HELPER.get_architectures())

# Cell
HF_TASKS_ALL = Enum('HF_TASKS_ALL', BLURR_MODEL_HELPER.get_tasks())
HF_TASKS_AUTO = Enum('HF_TASKS_AUTO', BLURR_MODEL_HELPER.get_tasks('auto'))

# Cell
HF_MODELS = Enum('HF_MODELS', BLURR_MODEL_HELPER.get_models())

# Cell
class ForMaskedLMTask: pass
class ForQuestionAnsweringTask: pass
class ForSequenceClassificationTask: pass
class ForTokenClassificationTask: pass
class ForPreTrainingTask: pass
class WithLMHeadTask: pass
class ForConditionalGenerationTask: pass
class ForMultipleChoiceTask: pass
class ForNextSentencePredictionTask: pass
class ForQuestionAnsweringSimpleTask: pass
class WithLMHeadModelTask: pass
class ForClassificationTask: pass