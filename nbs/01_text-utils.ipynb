{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |default_exp text.utils\n",
    "# |default_cls_lvl 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# utils\n",
    "\n",
    "> `text.utils` contains various text specific utility classes/functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "import importlib, inspect, os, random, sys, warnings\n",
    "from typing import List, Optional, Union, Tuple, Type\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from enum import Enum\n",
    "from fastcore.foundation import L\n",
    "from transformers import AutoConfig, AutoTokenizer, PretrainedConfig, PreTrainedTokenizerBase, PreTrainedModel\n",
    "from transformers.utils import logging as hf_logging\n",
    "\n",
    "from blurr.utils import Singleton\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "# silence all the HF warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "hf_logging.set_verbosity_error()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |hide\n",
    "import pdb\n",
    "\n",
    "from IPython.display import display\n",
    "from fastcore.test import *\n",
    "from nbdev import nbdev_export\n",
    "from nbdev.showdoc import show_doc\n",
    "\n",
    "from blurr.utils import print_versions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What we're running with at the time this documentation was generated:\n",
      "torch: 1.9.0+cu102\n",
      "fastai: 2.7.9\n",
      "transformers: 4.21.2\n"
     ]
    }
   ],
   "source": [
    "# | echo: false\n",
    "print(\"What we're running with at the time this documentation was generated:\")\n",
    "print_versions(\"torch fastai transformers\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU #1: GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "# |hide\n",
    "# |cuda\n",
    "torch.cuda.set_device(1)\n",
    "print(f\"Using GPU #{torch.cuda.current_device()}: {torch.cuda.get_device_name()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "def get_hf_objects(\n",
    "    pretrained_model_name_or_path: Optional[Union[str, os.PathLike]],\n",
    "    model_cls: PreTrainedModel,\n",
    "    config: Union[PretrainedConfig, str, os.PathLike] = None,\n",
    "    tokenizer_cls: PreTrainedTokenizerBase = None,\n",
    "    config_kwargs: dict = {},\n",
    "    tokenizer_kwargs: dict = {},\n",
    "    model_kwargs: dict = {},\n",
    "    cache_dir: Union[str, os.PathLike] = None,\n",
    ") -> Tuple[str, PretrainedConfig, PreTrainedTokenizerBase, PreTrainedModel]:\n",
    "    \"\"\"\n",
    "    Given at minimum a `pretrained_model_name_or_path` and `model_cls (such as\n",
    "    `AutoModelForSequenceClassification\"), this method returns all the Hugging Face objects you need to train\n",
    "    a model using Blurr\n",
    "    \"\"\"\n",
    "    # config\n",
    "    if config is None:\n",
    "        config = AutoConfig.from_pretrained(pretrained_model_name_or_path, cache_dir=cache_dir, **config_kwargs)\n",
    "\n",
    "    # tokenizer (gpt2, roberta, bart (and maybe others) tokenizers require a prefix space)\n",
    "    if any(s in pretrained_model_name_or_path for s in [\"gpt2\", \"roberta\", \"bart\", \"longformer\"]):\n",
    "        tokenizer_kwargs = {**{\"add_prefix_space\": True}, **tokenizer_kwargs}\n",
    "\n",
    "    if tokenizer_cls is None:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path, cache_dir=cache_dir, **tokenizer_kwargs)\n",
    "    else:\n",
    "        tokenizer = tokenizer_cls.from_pretrained(pretrained_model_name_or_path, cache_dir=cache_dir, **tokenizer_kwargs)\n",
    "\n",
    "    # model\n",
    "    model = model_cls.from_pretrained(pretrained_model_name_or_path, config=config, cache_dir=cache_dir, **model_kwargs)\n",
    "\n",
    "    # arch\n",
    "    try:\n",
    "        arch = model.__module__.split(\".\")[2]\n",
    "    except:\n",
    "        arch = \"unknown\"\n",
    "\n",
    "    return (arch, config, tokenizer, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "## get_hf_objects\n",
       "\n",
       ">      get_hf_objects\n",
       ">                      (pretrained_model_name_or_path:Union[str,os.PathLike,None\n",
       ">                      Type],\n",
       ">                      model_cls:transformers.modeling_utils.PreTrainedModel, co\n",
       ">                      nfig:Union[transformers.configuration_utils.PretrainedCon\n",
       ">                      fig,str,os.PathLike]=None, tokenizer_cls:transformers.tok\n",
       ">                      enization_utils_base.PreTrainedTokenizerBase=None,\n",
       ">                      config_kwargs:dict={}, tokenizer_kwargs:dict={},\n",
       ">                      model_kwargs:dict={},\n",
       ">                      cache_dir:Union[str,os.PathLike]=None)\n",
       "\n",
       "Given at minimum a `pretrained_model_name_or_path` and `model_cls (such as\n",
       "`AutoModelForSequenceClassification\"), this method returns all the Hugging Face objects you need to train\n",
       "a model using Blurr"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "## get_hf_objects\n",
       "\n",
       ">      get_hf_objects\n",
       ">                      (pretrained_model_name_or_path:Union[str,os.PathLike,None\n",
       ">                      Type],\n",
       ">                      model_cls:transformers.modeling_utils.PreTrainedModel, co\n",
       ">                      nfig:Union[transformers.configuration_utils.PretrainedCon\n",
       ">                      fig,str,os.PathLike]=None, tokenizer_cls:transformers.tok\n",
       ">                      enization_utils_base.PreTrainedTokenizerBase=None,\n",
       ">                      config_kwargs:dict={}, tokenizer_kwargs:dict={},\n",
       ">                      model_kwargs:dict={},\n",
       ">                      cache_dir:Union[str,os.PathLike]=None)\n",
       "\n",
       "Given at minimum a `pretrained_model_name_or_path` and `model_cls (such as\n",
       "`AutoModelForSequenceClassification\"), this method returns all the Hugging Face objects you need to train\n",
       "a model using Blurr"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(get_hf_objects, title_level=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BlurrText -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export\n",
    "@Singleton\n",
    "class BlurrText:\n",
    "    \"\"\"A general utility class for getting your Hugging Face objects\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        # get hf classes (tokenizers, configs, models, etc...)\n",
    "        transformer_classes = inspect.getmembers(importlib.import_module(\"transformers\"))\n",
    "\n",
    "        # build a df that we can query against to get various transformers objects/info\n",
    "        self._df = pd.DataFrame(transformer_classes, columns=[\"class_name\", \"class_location\"])\n",
    "        self._df = self._df[self._df.class_location.apply(lambda v: isinstance(v, type))]\n",
    "\n",
    "        # add the module each class is included in\n",
    "        self._df[\"module\"] = self._df.class_location.apply(lambda v: v.__module__)\n",
    "\n",
    "        # remove class_location (don't need it anymore)\n",
    "        self._df.drop(labels=[\"class_location\"], axis=1, inplace=True)\n",
    "\n",
    "        # break up the module into separate cols\n",
    "        module_parts_df = self._df.module.str.split(\".\", n=-1, expand=True)\n",
    "        for i in range(len(module_parts_df.columns)):\n",
    "            self._df[f\"module_part_{i}\"] = module_parts_df[i]\n",
    "\n",
    "        # using module part 1, break up the functional area and arch into separate cols\n",
    "        module_part_3_df = self._df.module_part_3.str.split(\"_\", n=1, expand=True)\n",
    "        self._df[[\"functional_area\", \"arch\"]] = module_part_3_df\n",
    "\n",
    "        self._df[\"arch\"] = self._df[\"arch\"].str.replace(\"_fast\", \"\")\n",
    "\n",
    "        # transformers >=4.5.x does \"auto\" differently; so remove it and \"utils\" from \"arch\" column\n",
    "        self._df = self._df[~self._df[\"arch\"].isin([\"auto\", \"utils\"])]\n",
    "\n",
    "        # if functional area = modeling, pull out the task it is built for\n",
    "        model_type_df = self._df[(self._df.functional_area == \"modeling\")].class_name.str.rsplit(\"For\", n=1, expand=True)\n",
    "\n",
    "        model_type_df[1] = np.where(model_type_df[1].notnull(), \"For\" + model_type_df[1].astype(str), model_type_df[1])\n",
    "\n",
    "        self._df[\"model_task\"] = model_type_df[1]\n",
    "        self._df[\"model_task\"] = self._df[\"model_task\"].str.replace(\"For\", \"\", n=1, case=True, regex=False)\n",
    "\n",
    "        model_type_df = self._df[(self._df.functional_area == \"modeling\")].class_name.str.rsplit(\"With\", n=1, expand=True)\n",
    "        model_type_df[1] = np.where(\n",
    "            model_type_df[1].notnull(), \"With\" + model_type_df[1].astype(str), self._df[(self._df.functional_area == \"modeling\")].model_task\n",
    "        )\n",
    "\n",
    "        self._df[\"model_task\"] = model_type_df[1]\n",
    "        self._df[\"model_task\"] = self._df[\"model_task\"].str.replace(\"With\", \"\", n=1, case=True, regex=False)\n",
    "\n",
    "        # look at what we're going to remove (use to verify we're just getting rid of stuff we want too)\n",
    "        # df[~df['hf_class_type'].isin(['modeling', 'configuration', 'tokenization'])]\n",
    "\n",
    "        # only need these 3 functional areas for our querying purposes\n",
    "        self._df = self._df[self._df[\"functional_area\"].isin([\"modeling\", \"configuration\", \"tokenization\"])]\n",
    "\n",
    "    def get_tasks(self, arch: str = None):\n",
    "        \"\"\"This method can be used to get a list of all tasks supported by your transformers install, or\n",
    "        just those available to a specific architecture\n",
    "        \"\"\"\n",
    "        query = [\"model_task.notna()\"]\n",
    "        if arch:\n",
    "            query.append(f'arch == \"{arch}\"')\n",
    "\n",
    "        return sorted(self._df.query(\" & \".join(query), engine=\"python\").model_task.unique().tolist())\n",
    "\n",
    "    def get_architectures(self):\n",
    "        return sorted(self._df[(self._df.arch.notna()) & (self._df.arch != None)].arch.unique().tolist())\n",
    "\n",
    "    def get_models(self, arch: str = None, task: str = None):\n",
    "        \"\"\"The transformer models available for use (optional: by architecture | task)\"\"\"\n",
    "        query = ['functional_area == \"modeling\"']\n",
    "        if arch:\n",
    "            query.append(f'arch == \"{arch}\"')\n",
    "        if task:\n",
    "            query.append(f'model_task == \"{task}\"')\n",
    "\n",
    "        models = sorted(self._df.query(\" & \".join(query)).class_name.tolist())\n",
    "        return models\n",
    "\n",
    "    def get_model_architecture(self, model_name_or_enum):\n",
    "        \"\"\"Get the architecture for a given model name / enum\"\"\"\n",
    "        model_name = model_name_or_enum if isinstance(model_name_or_enum, str) else model_name_or_enum.name\n",
    "        return self._df[self._df.class_name == model_name].arch.values[0]\n",
    "\n",
    "    def get_hf_objects(\n",
    "        self,\n",
    "        pretrained_model_name_or_path: Optional[Union[str, os.PathLike]],\n",
    "        model_cls: PreTrainedModel,\n",
    "        config: Union[PretrainedConfig, str, os.PathLike] = None,\n",
    "        tokenizer_cls: PreTrainedTokenizerBase = None,\n",
    "        config_kwargs: dict = {},\n",
    "        tokenizer_kwargs: dict = {},\n",
    "        model_kwargs: dict = {},\n",
    "        cache_dir: Union[str, os.PathLike] = None,\n",
    "    ) -> Tuple[str, PretrainedConfig, PreTrainedTokenizerBase, PreTrainedModel]:\n",
    "\n",
    "        arch, config, tokenizer, model = get_hf_objects(\n",
    "            pretrained_model_name_or_path, model_cls, config, tokenizer_cls, config_kwargs, tokenizer_kwargs, model_kwargs, cache_dir\n",
    "        )\n",
    "\n",
    "        if arch == \"unknown\":\n",
    "            arch = self.get_model_architecture(type(model).__name__)\n",
    "\n",
    "        return (arch, config, tokenizer, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "## Singleton object at 0x7fae29e96040>\n",
       "\n",
       ">      Singleton object at 0x7fae29e96040> (*args, **kwargs)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "## Singleton object at 0x7fae29e96040>\n",
       "\n",
       ">      Singleton object at 0x7fae29e96040> (*args, **kwargs)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(BlurrText, title_level=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`BlurrText` is a `Singleton` (there exists only one instance, and the same instance is returned upon subsequent instantiation requests).  You can get at via the `NLP` constant below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NLP = BlurrText()\n",
    "NLP2 = BlurrText()\n",
    "test_eq(NLP, NLP2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_name</th>\n",
       "      <th>module</th>\n",
       "      <th>module_part_0</th>\n",
       "      <th>module_part_1</th>\n",
       "      <th>module_part_2</th>\n",
       "      <th>module_part_3</th>\n",
       "      <th>functional_area</th>\n",
       "      <th>arch</th>\n",
       "      <th>model_task</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AdaptiveEmbedding</td>\n",
       "      <td>transformers.models.transfo_xl.modeling_transfo_xl</td>\n",
       "      <td>transformers</td>\n",
       "      <td>models</td>\n",
       "      <td>transfo_xl</td>\n",
       "      <td>modeling_transfo_xl</td>\n",
       "      <td>modeling</td>\n",
       "      <td>transfo_xl</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AlbertConfig</td>\n",
       "      <td>transformers.models.albert.configuration_albert</td>\n",
       "      <td>transformers</td>\n",
       "      <td>models</td>\n",
       "      <td>albert</td>\n",
       "      <td>configuration_albert</td>\n",
       "      <td>configuration</td>\n",
       "      <td>albert</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AlbertForMaskedLM</td>\n",
       "      <td>transformers.models.albert.modeling_albert</td>\n",
       "      <td>transformers</td>\n",
       "      <td>models</td>\n",
       "      <td>albert</td>\n",
       "      <td>modeling_albert</td>\n",
       "      <td>modeling</td>\n",
       "      <td>albert</td>\n",
       "      <td>MaskedLM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AlbertForMultipleChoice</td>\n",
       "      <td>transformers.models.albert.modeling_albert</td>\n",
       "      <td>transformers</td>\n",
       "      <td>models</td>\n",
       "      <td>albert</td>\n",
       "      <td>modeling_albert</td>\n",
       "      <td>modeling</td>\n",
       "      <td>albert</td>\n",
       "      <td>MultipleChoice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AlbertForPreTraining</td>\n",
       "      <td>transformers.models.albert.modeling_albert</td>\n",
       "      <td>transformers</td>\n",
       "      <td>models</td>\n",
       "      <td>albert</td>\n",
       "      <td>modeling_albert</td>\n",
       "      <td>modeling</td>\n",
       "      <td>albert</td>\n",
       "      <td>PreTraining</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 class_name  \\\n",
       "6         AdaptiveEmbedding   \n",
       "8              AlbertConfig   \n",
       "9         AlbertForMaskedLM   \n",
       "10  AlbertForMultipleChoice   \n",
       "11     AlbertForPreTraining   \n",
       "\n",
       "                                                module module_part_0  \\\n",
       "6   transformers.models.transfo_xl.modeling_transfo_xl  transformers   \n",
       "8      transformers.models.albert.configuration_albert  transformers   \n",
       "9           transformers.models.albert.modeling_albert  transformers   \n",
       "10          transformers.models.albert.modeling_albert  transformers   \n",
       "11          transformers.models.albert.modeling_albert  transformers   \n",
       "\n",
       "   module_part_1 module_part_2         module_part_3 functional_area  \\\n",
       "6         models    transfo_xl   modeling_transfo_xl        modeling   \n",
       "8         models        albert  configuration_albert   configuration   \n",
       "9         models        albert       modeling_albert        modeling   \n",
       "10        models        albert       modeling_albert        modeling   \n",
       "11        models        albert       modeling_albert        modeling   \n",
       "\n",
       "          arch      model_task  \n",
       "6   transfo_xl            None  \n",
       "8       albert             NaN  \n",
       "9       albert        MaskedLM  \n",
       "10      albert  MultipleChoice  \n",
       "11      albert     PreTraining  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, nan, 'MaskedLM', 'MultipleChoice', 'PreTraining', 'QuestionAnswering', 'SequenceClassification', 'TokenClassification', 'CausalLM', 'ConditionalGeneration', 'ImageClassification', 'MaskedImageModeling', 'SemanticSegmentation', 'NextSentencePrediction', 'DepthEstimation', 'AudioFrameClassification', 'CTC', 'XVector', 'Teacher', 'QuestionAnsweringSimple', 'LMHeadModel', 'CausalImageModeling', 'EntityClassification', 'EntityPairClassification', 'EntitySpanClassification', 'Classification', 'InstanceSegmentation', 'merModel', 'merPreTrainedModel', 'ObjectDetection', 'ImageClassificationConvProcessing', 'ImageClassificationFourier', 'ImageClassificationLearned', 'MultimodalAutoencoding', 'OpticalFlow', 'Generation', 'OpenQA', 'LMHead', 'merLayer', 'ImageAndTextRetrieval', 'ImagesAndTextClassification', 'RegionToPhraseAlignment', 'VisualReasoning']\n",
      "\n",
      "['modeling', 'configuration', 'tokenization']\n",
      "\n",
      "['transfo_xl', 'albert', 'bart', 'barthez', 'bartpho', 'bert', 'beit', 'bert_generation', 'bert_japanese', 'bertweet', 'big_bird', 'bigbird_pegasus', 'blenderbot', 'blenderbot_small', 'bloom', 'byt5', 'clip', 'ctrl', 'camembert', 'canine', 'codegen', 'convbert', 'convnext', 'cpm', 'cvt', 'dpr', 'dpt', 'data2vec_audio', 'data2vec_text', 'data2vec_vision', 'deberta', 'deberta_v2', 'decision_transformer', 'deit', 'detr', 'distilbert', 'electra', 'encoder_decoder', 'fnet', 'fsmt', 'flaubert', 'flava', 'funnel', 'glpn', 'gpt2', 'gptj', 'gpt_neo', 'gpt_neox', 'groupvit', 'herbert', 'hubert', 'ibert', 'imagegpt', 'led', 'layoutlm', 'layoutlmv2', 'layoutlmv3', 'layoutxlm', 'levit', 'longt5', 'longformer', 'luke', 'lxmert', 'm2m_100', 'mbart50', 'mbart', 'mctct', 'mluke', 'mmbt', 'mpnet', 'mt5', 't5', 'marian', 'maskformer', 'megatron_bert', 'mobilebert', 'mobilevit', 'mvp', 'nezha', 'nllb', 'nystromformer', 'opt', 'openai', 'owlvit', 'plbart', 'pegasus', 'perceiver', 'phobert', 'poolformer', 'prophetnet', 'qdqbert', 'rag', 'realm', 'reformer', 'regnet', 'rembert', 'resnet', 'retribert', 'roformer', 'roberta', 'sew', 'sew_d', 'segformer', 'speech_to_text_2', 'speech_to_text', 'speech_encoder_decoder', 'splinter', 'squeezebert', 'swin', 'tapas', 'tapex', 'trocr', 'trajectory_transformer', 'unispeech', 'unispeech_sat', 'van', 'vit', 'vit_mae', 'vilt', 'vision_encoder_decoder', 'vision_text_dual_encoder', 'visual_bert', 'wav2vec2', 'wav2vec2_conformer', 'wav2vec2_phoneme', 'wavlm', 'xglm', 'xlm', 'xlm_prophetnet', 'xlm_roberta', 'xlm_roberta_xl', 'xlnet', 'yolos', 'yoso']\n",
      "\n",
      "['modeling_transfo_xl', 'configuration_albert', 'modeling_albert', 'tokenization_albert', 'tokenization_albert_fast', 'configuration_bart', 'modeling_bart', 'tokenization_bart', 'tokenization_bart_fast', 'tokenization_barthez', 'tokenization_barthez_fast', 'tokenization_bartpho', 'tokenization_bert', 'configuration_beit', 'modeling_beit', 'configuration_bert', 'modeling_bert', 'configuration_bert_generation', 'modeling_bert_generation', 'tokenization_bert_generation', 'tokenization_bert_japanese', 'tokenization_bert_fast', 'tokenization_bertweet', 'configuration_big_bird', 'modeling_big_bird', 'configuration_bigbird_pegasus', 'modeling_bigbird_pegasus', 'tokenization_big_bird', 'tokenization_big_bird_fast', 'configuration_blenderbot', 'modeling_blenderbot', 'configuration_blenderbot_small', 'modeling_blenderbot_small', 'tokenization_blenderbot_small', 'tokenization_blenderbot_small_fast', 'tokenization_blenderbot', 'tokenization_blenderbot_fast', 'configuration_bloom', 'modeling_bloom', 'tokenization_bloom_fast', 'tokenization_byt5', 'configuration_clip', 'modeling_clip', 'tokenization_clip', 'tokenization_clip_fast', 'configuration_ctrl', 'modeling_ctrl', 'tokenization_ctrl', 'configuration_camembert', 'modeling_camembert', 'tokenization_camembert', 'tokenization_camembert_fast', 'configuration_canine', 'modeling_canine', 'tokenization_canine', 'configuration_codegen', 'modeling_codegen', 'tokenization_codegen', 'tokenization_codegen_fast', 'configuration_convbert', 'modeling_convbert', 'tokenization_convbert', 'tokenization_convbert_fast', 'configuration_convnext', 'modeling_convnext', 'tokenization_cpm', 'tokenization_cpm_fast', 'configuration_cvt', 'modeling_cvt', 'configuration_dpr', 'modeling_dpr', 'tokenization_dpr', 'tokenization_dpr_fast', 'configuration_dpt', 'modeling_dpt', 'configuration_data2vec_audio', 'modeling_data2vec_audio', 'configuration_data2vec_text', 'modeling_data2vec_text', 'configuration_data2vec_vision', 'modeling_data2vec_vision', 'configuration_deberta', 'modeling_deberta', 'tokenization_deberta', 'tokenization_deberta_fast', 'configuration_deberta_v2', 'modeling_deberta_v2', 'tokenization_deberta_v2', 'tokenization_deberta_v2_fast', 'configuration_decision_transformer', 'modeling_decision_transformer', 'configuration_deit', 'modeling_deit', 'configuration_detr', 'configuration_distilbert', 'modeling_distilbert', 'tokenization_distilbert', 'tokenization_distilbert_fast', 'configuration_electra', 'modeling_electra', 'tokenization_electra', 'tokenization_electra_fast', 'configuration_encoder_decoder', 'modeling_encoder_decoder', 'configuration_fnet', 'modeling_fnet', 'tokenization_fnet', 'tokenization_fnet_fast', 'configuration_fsmt', 'modeling_fsmt', 'tokenization_fsmt', 'configuration_flaubert', 'modeling_flaubert', 'tokenization_flaubert', 'configuration_flava', 'modeling_flava', 'modeling_funnel', 'configuration_funnel', 'tokenization_funnel', 'tokenization_funnel_fast', 'configuration_glpn', 'modeling_glpn', 'configuration_gpt2', 'modeling_gpt2', 'tokenization_gpt2', 'tokenization_gpt2_fast', 'configuration_gptj', 'modeling_gptj', 'configuration_gpt_neo', 'modeling_gpt_neo', 'configuration_gpt_neox', 'modeling_gpt_neox', 'tokenization_gpt_neox_fast', 'configuration_groupvit', 'modeling_groupvit', 'tokenization_herbert', 'tokenization_herbert_fast', 'configuration_hubert', 'modeling_hubert', 'configuration_ibert', 'modeling_ibert', 'configuration_imagegpt', 'modeling_imagegpt', 'configuration_led', 'modeling_led', 'tokenization_led', 'tokenization_led_fast', 'configuration_layoutlm', 'modeling_layoutlm', 'tokenization_layoutlm', 'tokenization_layoutlm_fast', 'configuration_layoutlmv2', 'modeling_layoutlmv2', 'tokenization_layoutlmv2', 'tokenization_layoutlmv2_fast', 'configuration_layoutlmv3', 'modeling_layoutlmv3', 'tokenization_layoutlmv3', 'tokenization_layoutlmv3_fast', 'tokenization_layoutxlm', 'tokenization_layoutxlm_fast', 'configuration_levit', 'modeling_levit', 'configuration_longt5', 'modeling_longt5', 'configuration_longformer', 'modeling_longformer', 'tokenization_longformer', 'tokenization_longformer_fast', 'configuration_luke', 'modeling_luke', 'tokenization_luke', 'configuration_lxmert', 'modeling_lxmert', 'tokenization_lxmert', 'tokenization_lxmert_fast', 'configuration_m2m_100', 'modeling_m2m_100', 'tokenization_m2m_100', 'tokenization_mbart50', 'tokenization_mbart50_fast', 'configuration_mbart', 'modeling_mbart', 'tokenization_mbart', 'tokenization_mbart_fast', 'configuration_mctct', 'modeling_mctct', 'tokenization_mluke', 'configuration_mmbt', 'modeling_mmbt', 'configuration_mpnet', 'modeling_mpnet', 'tokenization_mpnet', 'tokenization_mpnet_fast', 'configuration_mt5', 'modeling_mt5', 'tokenization_t5', 'tokenization_t5_fast', 'configuration_marian', 'modeling_marian', 'tokenization_marian', 'configuration_maskformer', 'modeling_maskformer', 'configuration_megatron_bert', 'modeling_megatron_bert', 'configuration_mobilebert', 'modeling_mobilebert', 'tokenization_mobilebert', 'tokenization_mobilebert_fast', 'configuration_mobilevit', 'modeling_mobilevit', 'configuration_mvp', 'modeling_mvp', 'tokenization_mvp', 'tokenization_mvp_fast', 'configuration_nezha', 'modeling_nezha', 'tokenization_nllb', 'tokenization_nllb_fast', 'configuration_nystromformer', 'modeling_nystromformer', 'configuration_opt', 'modeling_opt', 'configuration_openai', 'modeling_openai', 'tokenization_openai', 'tokenization_openai_fast', 'configuration_owlvit', 'modeling_owlvit', 'configuration_plbart', 'modeling_plbart', 'tokenization_plbart', 'configuration_pegasus', 'modeling_pegasus', 'tokenization_pegasus', 'tokenization_pegasus_fast', 'configuration_perceiver', 'modeling_perceiver', 'tokenization_perceiver', 'tokenization_phobert', 'configuration_poolformer', 'modeling_poolformer', 'configuration_prophetnet', 'modeling_prophetnet', 'tokenization_prophetnet', 'configuration_qdqbert', 'modeling_qdqbert', 'configuration_rag', 'modeling_rag', 'tokenization_rag', 'configuration_realm', 'modeling_realm', 'tokenization_realm', 'tokenization_realm_fast', 'modeling_reformer', 'configuration_reformer', 'tokenization_reformer', 'tokenization_reformer_fast', 'configuration_regnet', 'modeling_regnet', 'configuration_rembert', 'modeling_rembert', 'tokenization_rembert', 'tokenization_rembert_fast', 'configuration_resnet', 'modeling_resnet', 'configuration_retribert', 'modeling_retribert', 'tokenization_retribert', 'tokenization_retribert_fast', 'configuration_roformer', 'modeling_roformer', 'tokenization_roformer', 'tokenization_roformer_fast', 'configuration_roberta', 'modeling_roberta', 'tokenization_roberta', 'tokenization_roberta_fast', 'configuration_sew', 'configuration_sew_d', 'modeling_sew_d', 'modeling_sew', 'configuration_segformer', 'modeling_segformer', 'configuration_speech_to_text_2', 'modeling_speech_to_text_2', 'tokenization_speech_to_text_2', 'configuration_speech_to_text', 'modeling_speech_to_text', 'tokenization_speech_to_text', 'configuration_speech_encoder_decoder', 'modeling_speech_encoder_decoder', 'configuration_splinter', 'modeling_splinter', 'tokenization_splinter', 'tokenization_splinter_fast', 'configuration_squeezebert', 'modeling_squeezebert', 'tokenization_squeezebert', 'tokenization_squeezebert_fast', 'configuration_swin', 'modeling_swin', 'configuration_t5', 'modeling_t5', 'configuration_tapas', 'tokenization_tapas', 'tokenization_tapex', 'configuration_trocr', 'modeling_trocr', 'configuration_trajectory_transformer', 'modeling_trajectory_transformer', 'configuration_transfo_xl', 'tokenization_transfo_xl', 'configuration_unispeech', 'modeling_unispeech', 'configuration_unispeech_sat', 'modeling_unispeech_sat', 'configuration_van', 'modeling_van', 'configuration_vit', 'modeling_vit', 'configuration_vit_mae', 'modeling_vit_mae', 'configuration_vilt', 'modeling_vilt', 'configuration_vision_encoder_decoder', 'modeling_vision_encoder_decoder', 'configuration_vision_text_dual_encoder', 'modeling_vision_text_dual_encoder', 'configuration_visual_bert', 'modeling_visual_bert', 'tokenization_wav2vec2', 'configuration_wav2vec2', 'configuration_wav2vec2_conformer', 'modeling_wav2vec2_conformer', 'modeling_wav2vec2', 'tokenization_wav2vec2_phoneme', 'configuration_wavlm', 'modeling_wavlm', 'configuration_xglm', 'modeling_xglm', 'tokenization_xglm', 'tokenization_xglm_fast', 'configuration_xlm', 'modeling_xlm', 'configuration_xlm_prophetnet', 'modeling_xlm_prophetnet', 'tokenization_xlm_prophetnet', 'configuration_xlm_roberta', 'modeling_xlm_roberta', 'tokenization_xlm_roberta', 'tokenization_xlm_roberta_fast', 'configuration_xlm_roberta_xl', 'modeling_xlm_roberta_xl', 'tokenization_xlm', 'configuration_xlnet', 'modeling_xlnet', 'tokenization_xlnet', 'tokenization_xlnet_fast', 'configuration_yolos', 'modeling_yolos', 'configuration_yoso', 'modeling_yoso']\n"
     ]
    }
   ],
   "source": [
    "# |hide\n",
    "display(NLP._df.head())\n",
    "\n",
    "print(list(NLP._df.model_task.unique()))\n",
    "print(\"\")\n",
    "print(list(NLP._df.functional_area.unique()))\n",
    "print(\"\")\n",
    "print(list(NLP._df.arch.unique()))\n",
    "print(\"\")\n",
    "print(list(NLP._df.module_part_3.unique()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... the ***task***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_doc(BlurrText(BlurrText).get_tasks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AudioFrameClassification', 'CTC', 'CausalImageModeling', 'CausalLM', 'Classification', 'ConditionalGeneration', 'DepthEstimation', 'EntityClassification', 'EntityPairClassification', 'EntitySpanClassification', 'Generation', 'ImageAndTextRetrieval', 'ImageClassification', 'ImageClassificationConvProcessing', 'ImageClassificationFourier', 'ImageClassificationLearned', 'ImagesAndTextClassification', 'InstanceSegmentation', 'LMHead', 'LMHeadModel', 'MaskedImageModeling', 'MaskedLM', 'MultimodalAutoencoding', 'MultipleChoice', 'NextSentencePrediction', 'ObjectDetection', 'OpenQA', 'OpticalFlow', 'PreTraining', 'QuestionAnswering', 'QuestionAnsweringSimple', 'RegionToPhraseAlignment', 'SemanticSegmentation', 'SequenceClassification', 'Teacher', 'TokenClassification', 'VisualReasoning', 'XVector', 'merLayer', 'merModel', 'merPreTrainedModel']\n",
      "\n",
      "['CausalLM', 'ConditionalGeneration', 'QuestionAnswering', 'SequenceClassification']\n"
     ]
    }
   ],
   "source": [
    "print(NLP.get_tasks())\n",
    "print(\"\")\n",
    "print(NLP.get_tasks(\"bart\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... the ***architecture***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_doc(BlurrText(BlurrText).get_architectures)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['albert', 'bart', 'barthez', 'bartpho', 'beit', 'bert', 'bert_generation', 'bert_japanese', 'bertweet', 'big_bird', 'bigbird_pegasus', 'blenderbot', 'blenderbot_small', 'bloom', 'byt5', 'camembert', 'canine', 'clip', 'codegen', 'convbert', 'convnext', 'cpm', 'ctrl', 'cvt', 'data2vec_audio', 'data2vec_text', 'data2vec_vision', 'deberta', 'deberta_v2', 'decision_transformer', 'deit', 'detr', 'distilbert', 'dpr', 'dpt', 'electra', 'encoder_decoder', 'flaubert', 'flava', 'fnet', 'fsmt', 'funnel', 'glpn', 'gpt2', 'gpt_neo', 'gpt_neox', 'gptj', 'groupvit', 'herbert', 'hubert', 'ibert', 'imagegpt', 'layoutlm', 'layoutlmv2', 'layoutlmv3', 'layoutxlm', 'led', 'levit', 'longformer', 'longt5', 'luke', 'lxmert', 'm2m_100', 'marian', 'maskformer', 'mbart', 'mbart50', 'mctct', 'megatron_bert', 'mluke', 'mmbt', 'mobilebert', 'mobilevit', 'mpnet', 'mt5', 'mvp', 'nezha', 'nllb', 'nystromformer', 'openai', 'opt', 'owlvit', 'pegasus', 'perceiver', 'phobert', 'plbart', 'poolformer', 'prophetnet', 'qdqbert', 'rag', 'realm', 'reformer', 'regnet', 'rembert', 'resnet', 'retribert', 'roberta', 'roformer', 'segformer', 'sew', 'sew_d', 'speech_encoder_decoder', 'speech_to_text', 'speech_to_text_2', 'splinter', 'squeezebert', 'swin', 't5', 'tapas', 'tapex', 'trajectory_transformer', 'transfo_xl', 'trocr', 'unispeech', 'unispeech_sat', 'van', 'vilt', 'vision_encoder_decoder', 'vision_text_dual_encoder', 'visual_bert', 'vit', 'vit_mae', 'wav2vec2', 'wav2vec2_conformer', 'wav2vec2_phoneme', 'wavlm', 'xglm', 'xlm', 'xlm_prophetnet', 'xlm_roberta', 'xlm_roberta_xl', 'xlnet', 'yolos', 'yoso']\n"
     ]
    }
   ],
   "source": [
    "print(NLP.get_architectures())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_doc(BlurrText(BlurrText).get_model_architecture)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roberta\n"
     ]
    }
   ],
   "source": [
    "print(NLP.get_model_architecture(\"RobertaForSequenceClassification\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and lastly the ***models*** (optionally for a given task and/or architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_doc(BlurrText(BlurrText).get_models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AdaptiveEmbedding', 'AlbertForMaskedLM', 'AlbertForMultipleChoice', 'AlbertForPreTraining', 'AlbertForQuestionAnswering']\n"
     ]
    }
   ],
   "source": [
    "print(L(NLP.get_models())[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BertForMaskedLM', 'BertForMultipleChoice', 'BertForNextSentencePrediction', 'BertForPreTraining', 'BertForQuestionAnswering']\n"
     ]
    }
   ],
   "source": [
    "print(NLP.get_models(arch=\"bert\")[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AlbertForTokenClassification', 'BertForTokenClassification', 'BigBirdForTokenClassification', 'BloomForTokenClassification', 'CamembertForTokenClassification']\n"
     ]
    }
   ],
   "source": [
    "print(NLP.get_models(task=\"TokenClassification\")[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BertForTokenClassification']\n"
     ]
    }
   ],
   "source": [
    "print(NLP.get_models(arch=\"bert\", task=\"TokenClassification\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To get all your Hugging Face objects (arch, config, tokenizer, and model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert\n",
      "<class 'transformers.models.bert.configuration_bert.BertConfig'>\n",
      "<class 'transformers.models.bert.tokenization_bert_fast.BertTokenizerFast'>\n",
      "<class 'transformers.models.bert.modeling_bert.BertForMaskedLM'>\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForMaskedLM\n",
    "\n",
    "hf_logging.set_verbosity_error()\n",
    "\n",
    "arch, config, tokenizer, model = get_hf_objects(\"bert-base-cased-finetuned-mrpc\", model_cls=AutoModelForMaskedLM)\n",
    "\n",
    "print(arch)\n",
    "print(type(config))\n",
    "print(type(tokenizer))\n",
    "print(type(model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flaubert\n",
      "<class 'transformers.models.flaubert.configuration_flaubert.FlaubertConfig'>\n",
      "<class 'transformers.models.flaubert.tokenization_flaubert.FlaubertTokenizer'>\n",
      "<class 'transformers.models.flaubert.modeling_flaubert.FlaubertForQuestionAnsweringSimple'>\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForQuestionAnswering\n",
    "\n",
    "hf_logging.set_verbosity_error()\n",
    "\n",
    "arch, config, tokenizer, model = get_hf_objects(\"fmikaelian/flaubert-base-uncased-squad\", model_cls=AutoModelForQuestionAnswering)\n",
    "\n",
    "print(arch)\n",
    "print(type(config))\n",
    "print(type(tokenizer))\n",
    "print(type(model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert\n",
      "<class 'transformers.models.bert.configuration_bert.BertConfig'>\n",
      "<class 'transformers.models.bert.tokenization_bert.BertTokenizer'>\n",
      "<class 'transformers.models.bert.modeling_bert.BertForNextSentencePrediction'>\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForNextSentencePrediction\n",
    "\n",
    "hf_logging.set_verbosity_error()\n",
    "\n",
    "arch, config, tokenizer, model = get_hf_objects(\n",
    "    \"bert-base-cased-finetuned-mrpc\", config=None, tokenizer_cls=BertTokenizer, model_cls=BertForNextSentencePrediction\n",
    ")\n",
    "print(arch)\n",
    "print(type(config))\n",
    "print(type(tokenizer))\n",
    "print(type(model))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |hide\n",
    "nbdev_export()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('blurr')",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
