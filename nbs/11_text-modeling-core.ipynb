{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp text.modeling.core\n",
    "# default_cls_lvl 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_slow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# text.modeling.core\n",
    "\n",
    "> This module contains core custom models, loss functions, and a default layer group splitter for use in applying discriminiative learning rates to your Hugging Face models trained via fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import os, inspect, mimetypes\n",
    "from typing import Any, Callable, Dict, List, Optional, Union, Type\n",
    "\n",
    "from fastcore.all import *\n",
    "from fastai.callback.all import *\n",
    "from fastai.data.block import DataBlock, ColReader, CategoryBlock, MultiCategoryBlock, ColSplitter, RandomSplitter\n",
    "from fastai.data.core import DataLoader, DataLoaders, TfmdDL\n",
    "from fastai.imports import *\n",
    "from fastai.learner import *\n",
    "from fastai.losses import BCEWithLogitsLossFlat, CrossEntropyLossFlat\n",
    "from fastai.optimizer import Adam, OptimWrapper, params\n",
    "from fastai.metrics import accuracy, F1Score, accuracy_multi, F1ScoreMulti\n",
    "from fastai.torch_core import *\n",
    "from fastai.torch_imports import *\n",
    "from transformers import AutoModelForSequenceClassification, PreTrainedModel, logging\n",
    "\n",
    "from blurr.text.data.core import TextBlock, TextInput, first_blurr_tfm\n",
    "from blurr.text.utils import get_hf_objects\n",
    "from blurr.utils import PreCalculatedLoss, PreCalculatedBCELoss, PreCalculatedCrossEntropyLoss, PreCalculatedMSELoss, set_seed\n",
    "\n",
    "logging.set_verbosity_error()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What we're running with at the time this documentation was generated:\n",
      "torch: 1.11.0\n",
      "fastai: 2.6.0\n",
      "transformers: 4.18.0\n"
     ]
    }
   ],
   "source": [
    "# hide_input\n",
    "import pdb\n",
    "\n",
    "from datasets import concatenate_datasets, load_dataset\n",
    "from fastai.data.external import untar_data, URLs\n",
    "from fastcore.test import *\n",
    "from nbdev.showdoc import show_doc\n",
    "\n",
    "from blurr.text.data.core import TextDataLoader\n",
    "from blurr.text.utils import BlurrText\n",
    "from blurr.utils import print_versions\n",
    "\n",
    "NLP = BlurrText()\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "print(\"What we're running with at the time this documentation was generated:\")\n",
    "print_versions(\"torch fastai transformers\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU #1: NVIDIA GeForce RTX 3080\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "# cuda\n",
    "torch.cuda.set_device(1)\n",
    "print(f\"Using GPU #{torch.cuda.current_device()}: {torch.cuda.get_device_name()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mid-level API\n",
    "\n",
    "Base splitter, model wrapper, and model callback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `blurr_splitter` -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def blurr_splitter(m: Module):\n",
    "    \"\"\"Splits the Hugging Face model based on various model architecture conventions\"\"\"\n",
    "    model = m.hf_model if (hasattr(m, \"hf_model\")) else m\n",
    "    root_modules = list(model.named_children())\n",
    "    top_module_name, top_module = root_modules[0]\n",
    "\n",
    "    groups = L([m for m_name, m in list(top_module.named_children())])\n",
    "    groups += L([m for m_name, m in root_modules[1:]])\n",
    "\n",
    "    return groups.map(params).filter(lambda el: len(el) > 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"blurr_splitter\" class=\"doc_header\"><code>blurr_splitter</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>blurr_splitter</code>(**`m`**:`Module`)\n",
       "\n",
       "Splits the Hugging Face model based on various model architecture conventions"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(blurr_splitter, title_level=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `BaseModelWrapper` -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class BaseModelWrapper(Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        # Your Hugging Face model\n",
    "        hf_model: PreTrainedModel,\n",
    "        # If True, hidden_states will be returned and accessed from Learner\n",
    "        output_hidden_states: bool = False,\n",
    "        # If True, attentions will be returned and accessed from Learner\n",
    "        output_attentions: bool = False,\n",
    "        # Any additional keyword arguments you want passed into your models forward method\n",
    "        hf_model_kwargs={},\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        store_attr()\n",
    "        self.hf_model = hf_model.cuda() if torch.cuda.is_available() else hf_model\n",
    "        self.hf_model_fwd_args = list(inspect.signature(self.hf_model.forward).parameters.keys())\n",
    "\n",
    "    def forward(self, x):\n",
    "        for k in list(x):\n",
    "            if k not in self.hf_model_fwd_args:\n",
    "                del x[k]\n",
    "\n",
    "        return self.hf_model(\n",
    "            **x,\n",
    "            output_hidden_states=self.output_hidden_states,\n",
    "            output_attentions=self.output_attentions,\n",
    "            return_dict=True,\n",
    "            **self.hf_model_kwargs\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `BaseModelWrapper` includes some nifty code for just passing in the things your model needs, as not all transformer architectures require/use the same information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `BaseModelCallback` -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class BaseModelCallback(Callback):\n",
    "    def before_fit(self):\n",
    "        if isinstance(self.learn.model, PreTrainedModel):\n",
    "            self.learn.model = BaseModelWrapper(self.learn.model)\n",
    "            self.was_wrapped = False\n",
    "        elif isinstance(self.learn.model, BaseModelWrapper):\n",
    "            self.was_wrapped = True\n",
    "\n",
    "    def before_batch(self):\n",
    "        self.hf_loss = None\n",
    "\n",
    "    def after_pred(self):\n",
    "        model_outputs = self.pred\n",
    "        self.learn.blurr_model_outputs = {}\n",
    "\n",
    "        for k, v in model_outputs.items():\n",
    "            # if the \"labels\" are included, we are training with target labels in which case the loss is returned\n",
    "            if k == \"loss\" and isinstance(self.learn.loss_func, PreCalculatedLoss):\n",
    "                self.hf_loss = to_float(v)\n",
    "            # the logits represent the prediction\n",
    "            elif k == \"logits\":\n",
    "                self.learn.pred = v\n",
    "            # add any other things included in model_outputs as blurr_{model_output_key}\n",
    "            else:\n",
    "                self.learn.blurr_model_outputs[k] = v\n",
    "\n",
    "    def after_loss(self):\n",
    "        # if we already have the loss from the model, update the Learner's loss to be it\n",
    "        if self.hf_loss is not None:\n",
    "            self.learn.loss_grad = self.hf_loss\n",
    "            self.learn.loss = self.learn.loss_grad.clone()\n",
    "    \n",
    "    def after_fit(self):\n",
    "       if not self.was_wrapped:\n",
    "            self.learn.model = self.learn.model.hf_model           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class BaseModelCallback(Callback):\n",
    "    def before_fit(self):\n",
    "        if isinstance(self.learn.model, PreTrainedModel):\n",
    "            self.learn.model = BaseModelWrapper(self.learn.model)\n",
    "            self.was_wrapped = False\n",
    "        elif isinstance(self.learn.model, BaseModelWrapper):\n",
    "            self.was_wrapped = True\n",
    "\n",
    "    def before_batch(self):\n",
    "        self.hf_loss = None\n",
    "\n",
    "    def after_pred(self):\n",
    "        model_outputs = self.pred\n",
    "        self.learn.blurr_model_outputs = {}\n",
    "\n",
    "        for k, v in model_outputs.items():\n",
    "            # if the \"labels\" are included, we are training with target labels in which case the loss is returned\n",
    "            if k == \"loss\" and isinstance(self.learn.loss_func, PreCalculatedLoss):\n",
    "                self.hf_loss = to_float(v)\n",
    "            # the logits represent the prediction\n",
    "            elif k == \"logits\":\n",
    "                self.learn.pred = v\n",
    "            # add any other things included in model_outputs as blurr_{model_output_key}\n",
    "            else:\n",
    "                self.learn.blurr_model_outputs[k] = v\n",
    "\n",
    "    def after_loss(self):\n",
    "        # if we already have the loss from the model, update the Learner's loss to be it\n",
    "        if self.hf_loss is not None:\n",
    "            self.learn.loss_grad = self.hf_loss\n",
    "            self.learn.loss = self.learn.loss_grad.clone()\n",
    "    \n",
    "    def after_fit(self):\n",
    "       if not self.was_wrapped:\n",
    "            self.learn.model = self.learn.model.hf_model           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class BaseModelCallback(Callback):\n",
    "    def before_fit(self):\n",
    "        if isinstance(self.learn.model, PreTrainedModel):\n",
    "            self.learn.model = BaseModelWrapper(self.learn.model)\n",
    "            self.was_wrapped = False\n",
    "        elif isinstance(self.learn.model, BaseModelWrapper):\n",
    "            self.was_wrapped = True\n",
    "\n",
    "    def before_batch(self):\n",
    "        self.hf_loss = None\n",
    "\n",
    "    def after_pred(self):\n",
    "        model_outputs = self.pred\n",
    "        self.learn.blurr_model_outputs = {}\n",
    "\n",
    "        for k, v in model_outputs.items():\n",
    "            # if the \"labels\" are included, we are training with target labels in which case the loss is returned\n",
    "            if k == \"loss\" and isinstance(self.learn.loss_func, PreCalculatedLoss):\n",
    "                self.hf_loss = to_float(v)\n",
    "            # the logits represent the prediction\n",
    "            elif k == \"logits\":\n",
    "                self.learn.pred = v\n",
    "            # add any other things included in model_outputs as blurr_{model_output_key}\n",
    "            else:\n",
    "                self.learn.blurr_model_outputs[k] = v\n",
    "\n",
    "    def after_loss(self):\n",
    "        # if we already have the loss from the model, update the Learner's loss to be it\n",
    "        if self.hf_loss is not None:\n",
    "            self.learn.loss_grad = self.hf_loss\n",
    "            self.learn.loss = self.learn.loss_grad.clone()\n",
    "    \n",
    "    def after_fit(self):\n",
    "        if not self.was_wrapped:\n",
    "            self.learn.model = self.learn.model.hf_model           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class BaseModelCallback(Callback):\n",
    "    def before_fit(self):\n",
    "        if isinstance(self.learn.model, PreTrainedModel):\n",
    "            self.learn.model = BaseModelWrapper(self.learn.model)\n",
    "            self.was_wrapped = False\n",
    "        elif isinstance(self.learn.model, BaseModelWrapper):\n",
    "            self.was_wrapped = True\n",
    "\n",
    "    def before_batch(self):\n",
    "        self.hf_loss = None\n",
    "\n",
    "    def after_pred(self):\n",
    "        model_outputs = self.pred\n",
    "        self.learn.blurr_model_outputs = {}\n",
    "\n",
    "        for k, v in model_outputs.items():\n",
    "            # if the \"labels\" are included, we are training with target labels in which case the loss is returned\n",
    "            if k == \"loss\" and isinstance(self.learn.loss_func, PreCalculatedLoss):\n",
    "                self.hf_loss = to_float(v)\n",
    "            # the logits represent the prediction\n",
    "            elif k == \"logits\":\n",
    "                self.learn.pred = v\n",
    "            # add any other things included in model_outputs as blurr_{model_output_key}\n",
    "            else:\n",
    "                self.learn.blurr_model_outputs[k] = v\n",
    "\n",
    "    def after_loss(self):\n",
    "        # if we already have the loss from the model, update the Learner's loss to be it\n",
    "        if self.hf_loss is not None:\n",
    "            self.learn.loss_grad = self.hf_loss\n",
    "            self.learn.loss = self.learn.loss_grad.clone()\n",
    "    \n",
    "    def after_fit(self):\n",
    "       if not self.was_wrapped:\n",
    "            self.learn.model = self.learn.model.hf_model           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class BaseModelCallback(Callback):\n",
    "    def before_fit(self):\n",
    "        if isinstance(self.learn.model, PreTrainedModel):\n",
    "            self.learn.model = BaseModelWrapper(self.learn.model)\n",
    "            self.was_wrapped = False\n",
    "        elif isinstance(self.learn.model, BaseModelWrapper):\n",
    "            self.was_wrapped = True\n",
    "\n",
    "    def before_batch(self):\n",
    "        self.hf_loss = None\n",
    "\n",
    "    def after_pred(self):\n",
    "        model_outputs = self.pred\n",
    "        self.learn.blurr_model_outputs = {}\n",
    "\n",
    "        for k, v in model_outputs.items():\n",
    "            # if the \"labels\" are included, we are training with target labels in which case the loss is returned\n",
    "            if k == \"loss\" and isinstance(self.learn.loss_func, PreCalculatedLoss):\n",
    "                self.hf_loss = to_float(v)\n",
    "            # the logits represent the prediction\n",
    "            elif k == \"logits\":\n",
    "                self.learn.pred = v\n",
    "            # add any other things included in model_outputs as blurr_{model_output_key}\n",
    "            else:\n",
    "                self.learn.blurr_model_outputs[k] = v\n",
    "\n",
    "    def after_loss(self):\n",
    "        # if we already have the loss from the model, update the Learner's loss to be it\n",
    "        if self.hf_loss is not None:\n",
    "            self.learn.loss_grad = self.hf_loss\n",
    "            self.learn.loss = self.learn.loss_grad.clone()\n",
    "    \n",
    "    def after_fit(self):\n",
    "       if not self.was_wrapped:\n",
    "            self.learn.model = self.learn.model.hf_model           \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a `Callback` for handling the [`ModelOutput`](https://huggingface.co/transformers/main_classes/output.html#transformers.file_utils.ModelOutput) returned by Hugging Face transformers. It allows us to associate anything we want from that object to our `Learner`.\n",
    "\n",
    "**Note** that your `Learner`'s loss will be set for you only if the Hugging Face model returns one *and* you are using the `PreCalculatedLoss` loss function.  \n",
    "\n",
    "Also note that anything else you asked the model to return (for example, last hidden state, etc..) will be available for you via the `blurr_model_outputs` property attached to your `Learner`. For example, assuming you are using BERT for a classification task ... if you have told your `BaseModelWrapper` instance to return attentions, you'd be able to access them via `learn.blurr_model_outputs['attentions']`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example\n",
    "\n",
    "Below demonstrates how to setup your pipeline for a sequence classification task (e.g., a model that requires a single text input) using the mid, high, and low-level API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset imdb (/home/wgilliam/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0080e17ece54ff28d50d589616d443e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at /home/wgilliam/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-d7fa5c9b748166d2.arrow\n",
      "Loading cached shuffled indices for dataset at /home/wgilliam/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-c5f1241ea667d1dc.arrow\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>is_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ah, the sex-and-gore movie. It's too bad they don't make these anymore (unless you live in Japan). But if they all turned out like this, that is not a bad thing.&lt;br /&gt;&lt;br /&gt;The movie basically consists of the two lovely vampires picking up \"johns\" along a country road, taking them home to their castle, having crazy sex with them, and then eating them (except the first victim, who they keep around for no particular reason). Things are complicated when a woman camping with her husband becomes too curious about these mysterious women she keeps seeing. It gets real ugly from here. By the end, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is the film in Antonioni's middle period that most critics dismiss quickly, as a 'flawed' look at 60s American youth culture/politics. For what it's worth, I found it more touching and memorable than his more acclaimed films like L'AVVENTURA, perhaps because he shows more emotion &amp; empathy here than anywhere else. The story is simple, but it is used as a frame for Antonioni's brilliant observations of, and critique on American consumerist culture, student life, the counter-culture, and the whole anti-establishment, anti-war backlash that was so prominent then. &lt;br /&gt;&lt;br /&gt;Even from a ...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is the definitive movie version of Hamlet. Branagh cuts nothing, but there are no wasted moments.</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i thought it was pretty interesting my social studies/language arts teacher was the police chief guy that was holding the microphone on the water barrel part =D i was excited my teacher is in some commercials he was in a gas/coffee/phone/play station commercial its nice seeing him on TV he was also on everybody hates Chris except he always get the small part la la why do we have to right 10 lines thats so stupid -_- i think I'm done never mind I'm still not done what is this a joke? why do we have to go all the way to line ten... really what's the point of it??!! i will just right random w...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What a dog of a movie. Noni Hazelhurst's performance is quite good, but it sits amidst a jungle of abhorrent scriptwriting, mediocre direction and wooden acting from the bulk of the cast. Many of the characters are woefully miscast, particularly the ever overrated Colin Friels.&lt;br /&gt;&lt;br /&gt;Very little works in this pretentious garbage. Much of the \"character development\" is done through a silly, angst-ridden voice over and frequently completely contradicts the behaviour of characters on-screen. In fact, it's hard to even figure out who the voice overs are talking about because they describe...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      text  \\\n",
       "0  Ah, the sex-and-gore movie. It's too bad they don't make these anymore (unless you live in Japan). But if they all turned out like this, that is not a bad thing.<br /><br />The movie basically consists of the two lovely vampires picking up \"johns\" along a country road, taking them home to their castle, having crazy sex with them, and then eating them (except the first victim, who they keep around for no particular reason). Things are complicated when a woman camping with her husband becomes too curious about these mysterious women she keeps seeing. It gets real ugly from here. By the end, ...   \n",
       "1  This is the film in Antonioni's middle period that most critics dismiss quickly, as a 'flawed' look at 60s American youth culture/politics. For what it's worth, I found it more touching and memorable than his more acclaimed films like L'AVVENTURA, perhaps because he shows more emotion & empathy here than anywhere else. The story is simple, but it is used as a frame for Antonioni's brilliant observations of, and critique on American consumerist culture, student life, the counter-culture, and the whole anti-establishment, anti-war backlash that was so prominent then. <br /><br />Even from a ...   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   This is the definitive movie version of Hamlet. Branagh cuts nothing, but there are no wasted moments.   \n",
       "3  i thought it was pretty interesting my social studies/language arts teacher was the police chief guy that was holding the microphone on the water barrel part =D i was excited my teacher is in some commercials he was in a gas/coffee/phone/play station commercial its nice seeing him on TV he was also on everybody hates Chris except he always get the small part la la why do we have to right 10 lines thats so stupid -_- i think I'm done never mind I'm still not done what is this a joke? why do we have to go all the way to line ten... really what's the point of it??!! i will just right random w...   \n",
       "4  What a dog of a movie. Noni Hazelhurst's performance is quite good, but it sits amidst a jungle of abhorrent scriptwriting, mediocre direction and wooden acting from the bulk of the cast. Many of the characters are woefully miscast, particularly the ever overrated Colin Friels.<br /><br />Very little works in this pretentious garbage. Much of the \"character development\" is done through a silly, angst-ridden voice over and frequently completely contradicts the behaviour of characters on-screen. In fact, it's hard to even figure out who the voice overs are talking about because they describe...   \n",
       "\n",
       "   label  is_valid  \n",
       "0      0     False  \n",
       "1      1     False  \n",
       "2      1     False  \n",
       "3      1     False  \n",
       "4      0     False  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets = load_dataset(\"imdb\", split=[\"train\", \"test\"])\n",
    "raw_datasets[0] = raw_datasets[0].add_column(\"is_valid\", [False] * len(raw_datasets[0]))\n",
    "raw_datasets[1] = raw_datasets[1].add_column(\"is_valid\", [True] * len(raw_datasets[1]))\n",
    "\n",
    "final_ds = concatenate_datasets([raw_datasets[0].shuffle().select(range(1000)), raw_datasets[1].shuffle().select(range(200))])\n",
    "imdb_df = pd.DataFrame(final_ds)\n",
    "imdb_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neg', 'pos']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = raw_datasets[0].features[\"label\"].names\n",
    "labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide_output\n",
    "model_cls = AutoModelForSequenceClassification\n",
    "\n",
    "pretrained_model_name = \"distilroberta-base\"  # \"distilbert-base-uncased\" \"bert-base-uncased\"\n",
    "hf_arch, hf_config, hf_tokenizer, hf_model = get_hf_objects(pretrained_model_name, model_cls=model_cls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single input\n",
    "set_seed()\n",
    "blocks = (TextBlock(hf_arch, hf_config, hf_tokenizer, hf_model, batch_tokenize_kwargs={\"labels\": labels}), CategoryBlock)\n",
    "dblock = DataBlock(blocks=blocks, get_x=ColReader(\"text\"), get_y=ColReader(\"label\"), splitter=RandomSplitter(seed=42))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "# dblock.summary(imdb_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = dblock.dataloaders(imdb_df, bs=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>With Iphigenia, Mikhali Cacoyannis is perhaps the first film director to have successfully brought the feel of ancient Greek theatre to the screen. His own screenplay, an adaptation of Euripides' tragedy, was far from easy, compared to that of the other two films of the trilogy he directed. The story has been very carefully deconstructed from Euripides' version and placed in a logical, strictly chronological framework, better conforming to the modern methods of cinematic story-telling. Cacoyann</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This comment does contain spoilers!!&lt;br /&gt;&lt;br /&gt;There are few actors that have an intangible to them. That innate quality which is an amalgamation of charisma, panache and swagger. It's the quality that can separate good actors from the truly great. I think George Clooney has it and so does Jack Nicholson. You can look at Clooney's subtle touches in scenes like his one word good-bye to Andy Garcia in Ocean's 11 when they just utter each other's name disdainfully. \"Terry.\" \"Danny.\" You can pick</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch(dataloaders=dls, max_n=2, trunc_at=500)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training\n",
    "\n",
    "`.to_fp16()` requires a GPU so had to remove for tests to run on github.  Let's check that we can get predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed()\n",
    "\n",
    "model = BaseModelWrapper(hf_model)\n",
    "\n",
    "learn = Learner(\n",
    "    dls,\n",
    "    model,\n",
    "    opt_func=partial(OptimWrapper, opt=torch.optim.Adam),\n",
    "    loss_func=PreCalculatedCrossEntropyLoss(),  # CrossEntropyLossFlat(),\n",
    "    metrics=[accuracy],\n",
    "    cbs=[BaseModelCallback],\n",
    "    splitter=blurr_splitter,\n",
    ")\n",
    "\n",
    "learn.freeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "BaseModelWrapper (Input shape: 4 x 512)\n",
       "============================================================================\n",
       "Layer (type)         Output Shape         Param #    Trainable \n",
       "============================================================================\n",
       "                     4 x 512 x 768       \n",
       "Embedding                                 38603520   False     \n",
       "Embedding                                 394752     False     \n",
       "Embedding                                 768        False     \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "Linear                                    590592     False     \n",
       "Linear                                    590592     False     \n",
       "Linear                                    590592     False     \n",
       "Dropout                                                        \n",
       "Linear                                    590592     False     \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "____________________________________________________________________________\n",
       "                     4 x 512 x 3072      \n",
       "Linear                                    2362368    False     \n",
       "____________________________________________________________________________\n",
       "                     4 x 512 x 768       \n",
       "Linear                                    2360064    False     \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "Linear                                    590592     False     \n",
       "Linear                                    590592     False     \n",
       "Linear                                    590592     False     \n",
       "Dropout                                                        \n",
       "Linear                                    590592     False     \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "____________________________________________________________________________\n",
       "                     4 x 512 x 3072      \n",
       "Linear                                    2362368    False     \n",
       "____________________________________________________________________________\n",
       "                     4 x 512 x 768       \n",
       "Linear                                    2360064    False     \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "Linear                                    590592     False     \n",
       "Linear                                    590592     False     \n",
       "Linear                                    590592     False     \n",
       "Dropout                                                        \n",
       "Linear                                    590592     False     \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "____________________________________________________________________________\n",
       "                     4 x 512 x 3072      \n",
       "Linear                                    2362368    False     \n",
       "____________________________________________________________________________\n",
       "                     4 x 512 x 768       \n",
       "Linear                                    2360064    False     \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "Linear                                    590592     False     \n",
       "Linear                                    590592     False     \n",
       "Linear                                    590592     False     \n",
       "Dropout                                                        \n",
       "Linear                                    590592     False     \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "____________________________________________________________________________\n",
       "                     4 x 512 x 3072      \n",
       "Linear                                    2362368    False     \n",
       "____________________________________________________________________________\n",
       "                     4 x 512 x 768       \n",
       "Linear                                    2360064    False     \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "Linear                                    590592     False     \n",
       "Linear                                    590592     False     \n",
       "Linear                                    590592     False     \n",
       "Dropout                                                        \n",
       "Linear                                    590592     False     \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "____________________________________________________________________________\n",
       "                     4 x 512 x 3072      \n",
       "Linear                                    2362368    False     \n",
       "____________________________________________________________________________\n",
       "                     4 x 512 x 768       \n",
       "Linear                                    2360064    False     \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "Linear                                    590592     False     \n",
       "Linear                                    590592     False     \n",
       "Linear                                    590592     False     \n",
       "Dropout                                                        \n",
       "Linear                                    590592     False     \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "____________________________________________________________________________\n",
       "                     4 x 512 x 3072      \n",
       "Linear                                    2362368    False     \n",
       "____________________________________________________________________________\n",
       "                     4 x 512 x 768       \n",
       "Linear                                    2360064    False     \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "Linear                                    590592     True      \n",
       "Dropout                                                        \n",
       "____________________________________________________________________________\n",
       "                     4 x 2               \n",
       "Linear                                    1538       True      \n",
       "____________________________________________________________________________\n",
       "\n",
       "Total params: 82,119,938\n",
       "Total trainable params: 612,098\n",
       "Total non-trainable params: 81,507,840\n",
       "\n",
       "Optimizer used: functools.partial(<class 'fastai.optimizer.OptimWrapper'>, opt=<class 'torch.optim.adam.Adam'>)\n",
       "Loss function: FlattenedLoss of CrossEntropyLoss()\n",
       "\n",
       "Model frozen up to parameter group #2\n",
       "\n",
       "Callbacks:\n",
       "  - TrainEvalCallback\n",
       "  - BaseModelCallback\n",
       "  - Recorder\n",
       "  - ProgressCallback"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hide_output\n",
    "learn.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(len(learn.opt.param_groups))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(minimum=8.317637839354575e-05, steep=0.033113110810518265, valley=0.00015848931798245758, slide=0.001737800776027143)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find(suggest_funcs=[minimum, steep, valley, slide])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.325592</td>\n",
       "      <td>0.345017</td>\n",
       "      <td>0.862500</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_seed()\n",
    "learn.fit_one_cycle(1, lr_max=1e-3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Showing results\n",
    "\n",
    "And here we create a `@typedispatch`ed implementation of `Learner.show_results`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@typedispatch\n",
    "def show_results(\n",
    "    # This typedispatched `show_results` will be called for `TextInput` typed inputs\n",
    "    x: TextInput,\n",
    "    # Your targets\n",
    "    y,\n",
    "    # Your raw inputs/targets\n",
    "    samples,\n",
    "    # The model's predictions\n",
    "    outs,\n",
    "    # Your `Learner`. This is required so as to get at the Hugging Face objects for decoding them into\n",
    "    # something understandable\n",
    "    learner,\n",
    "    # Your `show_results` context\n",
    "    ctxs=None,\n",
    "    # The maximum number of items to show\n",
    "    max_n=6,\n",
    "    # Any truncation your want applied to your decoded inputs\n",
    "    trunc_at=None,\n",
    "    # Any other keyword arguments you want applied to `show_results`\n",
    "    **kwargs,\n",
    "):\n",
    "    # grab our tokenizer\n",
    "    tfm = first_blurr_tfm(learner.dls)\n",
    "    hf_tokenizer = tfm.hf_tokenizer\n",
    "\n",
    "    # if we've included our labels list, we'll use it to look up the value of our target(s)\n",
    "    trg_labels = tfm.kwargs[\"labels\"] if (\"labels\" in tfm.kwargs) else None\n",
    "\n",
    "    res = L()\n",
    "    n_inp = learner.dls.n_inp\n",
    "\n",
    "    for idx, (input_ids, label, pred, sample) in enumerate(zip(x, y, outs, samples)):\n",
    "        if idx >= max_n:\n",
    "            break\n",
    "\n",
    "        # add in the input text\n",
    "        rets = [hf_tokenizer.decode(input_ids, skip_special_tokens=True)[:trunc_at]]\n",
    "        # add in the targets\n",
    "        for item in sample[n_inp:]:\n",
    "            if not torch.is_tensor(item):\n",
    "                trg = trg_labels[int(item)] if trg_labels else item\n",
    "            elif is_listy(item.tolist()):\n",
    "                trg = [trg_labels[idx] for idx, val in enumerate(label.numpy().tolist()) if (val == 1)] if (trg_labels) else label.numpy()\n",
    "            else:\n",
    "                trg = trg_labels[label.item()] if (trg_labels) else label.item()\n",
    "\n",
    "            rets.append(trg)\n",
    "        # add in the predictions\n",
    "        for item in pred:\n",
    "            if not torch.is_tensor(item):\n",
    "                p = trg_labels[int(item)] if trg_labels else item\n",
    "            elif is_listy(item.tolist()):\n",
    "                p = [trg_labels[idx] for idx, val in enumerate(item.numpy().tolist()) if (val == 1)] if (trg_labels) else item.numpy()\n",
    "            else:\n",
    "                p = trg_labels[item.item()] if (trg_labels) else item.item()\n",
    "\n",
    "            rets.append(p)\n",
    "\n",
    "        res.append(tuplify(rets))\n",
    "\n",
    "    cols = [\"text\"] + [\"target\" if (i == 0) else f\"target_{i}\" for i in range(len(res[0]) - n_inp * 2)]\n",
    "    cols += [\"prediction\" if (i == 0) else f\"prediction_{i}\" for i in range(len(res[0]) - n_inp * 2)]\n",
    "    display_df(pd.DataFrame(res, columns=cols)[:max_n])\n",
    "    return ctxs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Match 1: Tag Team Table Match Bubba Ray and Spike Dudley vs Eddie Guerrero and Chris Benoit Bubba Ray and Spike Dudley started things off with a Tag Team Table Match against Eddie Guerrero and Chris Benoit. According to the rules of the match, both opponents have to go through tables in order to get the win. Benoit and Guerrero heated up early on by taking turns hammering first Spike and then Bubba Ray. A German suplex by Benoit to Bubba took the wind out of the Dudley brother. Spike tried to h</td>\n",
       "      <td>pos</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>THE SHOP AROUND THE CORNER is one of the sweetest and most feel-good romantic comedies ever made. There's just no getting around that, and it's hard to actually put one's feeling for this film into words. It's not one of those films that tries too hard, nor does it come up with the oddest possible scenarios to get the two protagonists together in the end. In fact, all its charm is innate, contained within the characters and the setting and the plot... which is highly believable to boot. It's ea</td>\n",
       "      <td>pos</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, max_n=2, trunc_at=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.283300</td>\n",
       "      <td>0.308957</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>00:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.199706</td>\n",
       "      <td>0.322771</td>\n",
       "      <td>0.862500</td>\n",
       "      <td>00:21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_seed()\n",
    "learn.fit_one_cycle(2, lr_max=slice(1e-7, 1e-4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.recorder.plot_loss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Match 1: Tag Team Table Match Bubba Ray and Spike Dudley vs Eddie Guerrero and Chris Benoit Bubba Ray and Spike Dudley started things off with a Tag Team Table Match against Eddie Guerrero and Chris Benoit. According to the rules of the match, both opponents have to go through tables in order to get the win. Benoit and Guerrero heated up early on by taking turns hammering first Spike and then Bubba Ray. A German suplex by Benoit to Bubba took the wind out of the Dudley brother. Spike tried to h</td>\n",
       "      <td>pos</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Feroz Abbas Khan's Gandhi My Father, a film that sheds light on the fractured relationship between the Mahatma and his son Harilal Gandhi. For a story that's as dramatic as the one this film attempts to tell, it's a pity the director fails to tell it dramatically. Gandhi My Father is narrated to you like that boring history lesson that put you to sleep at school. Now the film aims to convey one very interesting point - the fact that Gandhi in his attempt to be a fair person, ended up being an u</td>\n",
       "      <td>pos</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, max_n=2, trunc_at=500)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction\n",
    "\n",
    "We need to replace fastai's `Learner.predict` method with the one above which is able to work with inputs that are represented by multiple tensors included in a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@patch\n",
    "def blurr_predict(self: Learner, items, rm_type_tfms=None):\n",
    "    # grab our blurr tfm with the bits to properly decode/show our inputs/targets\n",
    "    tfm = first_blurr_tfm(self.dls)\n",
    "    trg_labels = tfm.kwargs[\"labels\"] if (\"labels\" in tfm.kwargs) else None\n",
    "\n",
    "    is_split_str = tfm.is_split_into_words and isinstance(items[0], str)\n",
    "    is_df = isinstance(items, pd.DataFrame)\n",
    "\n",
    "    if not is_df and (is_split_str or not is_listy(items)):\n",
    "        items = [items]\n",
    "\n",
    "    dl = self.dls.test_dl(items, rm_type_tfms=rm_type_tfms, num_workers=0)\n",
    "\n",
    "    with self.no_bar():\n",
    "        probs, _, decoded_preds = self.get_preds(dl=dl, with_input=False, with_decoded=True)\n",
    "\n",
    "    trg_tfms = self.dls.tfms[self.dls.n_inp :]\n",
    "\n",
    "    outs = []\n",
    "    is_multilabel = isinstance(self.loss_func, BCEWithLogitsLossFlat)\n",
    "    probs, decoded_preds = L(probs), L(decoded_preds)\n",
    "    for i in range(len(items)):\n",
    "        item_probs = probs.itemgot(i)\n",
    "        item_dec_preds = decoded_preds.itemgot(i)\n",
    "        item_dec_labels = tuplify([tfm.decode(item_dec_preds[tfm_idx]) for tfm_idx, tfm in enumerate(trg_tfms)])[0]\n",
    "        if trg_labels:\n",
    "            item_dec_labels = [trg_labels[int(lbl)] for item in item_dec_labels for lbl in item]\n",
    "\n",
    "        res = {}\n",
    "        if is_multilabel:\n",
    "            res[\"labels\"] = list(item_dec_labels)\n",
    "            msk = item_dec_preds[0]\n",
    "            res[\"scores\"] = item_probs[0][msk].tolist()\n",
    "            res[\"class_indices\"] = [int(val) for val in item_dec_preds[0]]\n",
    "        else:\n",
    "            res[\"label\"] = item_dec_labels[0]\n",
    "            res[\"score\"] = item_probs[0].tolist()[item_dec_preds[0]]\n",
    "            res[\"class_index\"] = item_dec_preds[0].item()\n",
    "\n",
    "        res[\"class_labels\"] = trg_labels if trg_labels else self.dls.vocab\n",
    "        res[\"probs\"] = item_probs[0].tolist()\n",
    "\n",
    "        outs.append(res)\n",
    "\n",
    "        # outs.append((item_dec_labels, [p.tolist() if p.dim() > 0 else p.item() for p in item_dec_preds], [p.tolist() for p in item_probs]))\n",
    "\n",
    "    return outs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"Learner.blurr_predict\" class=\"doc_header\"><code>Learner.blurr_predict</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Learner.blurr_predict</code>(**`items`**, **`rm_type_tfms`**=*`None`*)\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Learner.blurr_predict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'pos',\n",
       "  'score': 0.9268715381622314,\n",
       "  'class_index': 1,\n",
       "  'class_labels': ['neg', 'pos'],\n",
       "  'probs': [0.07312848418951035, 0.9268715381622314]}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.blurr_predict(\"I really liked the movie\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'neg',\n",
       "  'score': 0.951835036277771,\n",
       "  'class_index': 0,\n",
       "  'class_labels': ['neg', 'pos'],\n",
       "  'probs': [0.951835036277771, 0.04816494137048721]}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.blurr_predict(\"Acting was so bad it was almost funny.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'pos',\n",
       "  'score': 0.9268715977668762,\n",
       "  'class_index': 1,\n",
       "  'class_labels': ['neg', 'pos'],\n",
       "  'probs': [0.07312841713428497, 0.9268715977668762]},\n",
       " {'label': 'neg',\n",
       "  'score': 0.7611569762229919,\n",
       "  'class_index': 0,\n",
       "  'class_labels': ['neg', 'pos'],\n",
       "  'probs': [0.7611569762229919, 0.23884305357933044]}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.blurr_predict([\"I really liked the movie\", \"I really hated the movie\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text generation\n",
    "\n",
    "Though not useful in sequence classification, we will also add a `blurr_generate` method to `Learner` that uses Hugging Face's `PreTrainedModel.generate` for text generation tasks.  \n",
    "\n",
    "For the full list of arguments you can pass in see [here](https://huggingface.co/transformers/main_classes/model.html#transformers.PreTrainedModel.generate). You can also check out their [\"How To Generate\"](https://github.com/huggingface/blog/blob/master/notebooks/02_how_to_generate.ipynb) notebook for more information about how it all works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@patch\n",
    "def blurr_generate(self: Learner, items, key=\"generated_texts\", **kwargs):\n",
    "    \"\"\"Uses the built-in `generate` method to generate the text\n",
    "    (see [here](https://huggingface.co/transformers/main_classes/model.html#transformers.PreTrainedModel.generate)\n",
    "    for a list of arguments you can pass in)\n",
    "    \"\"\"\n",
    "    if not is_listy(items):\n",
    "        items = [items]\n",
    "\n",
    "    # grab our blurr tfm with the bits to properly decode/show our inputs/targets\n",
    "    tfm = first_blurr_tfm(self.dls)\n",
    "\n",
    "    # grab the Hugging Face tokenizer from the learner's dls.tfms\n",
    "    hf_tokenizer = tfm.hf_tokenizer\n",
    "    tok_kwargs = tfm.tok_kwargs\n",
    "\n",
    "    # grab the text generation kwargs\n",
    "    text_gen_kwargs = tfm.text_gen_kwargs if (len(kwargs) == 0) else kwargs\n",
    "\n",
    "    results = []\n",
    "    for idx, inp in enumerate(items):\n",
    "        if isinstance(inp, str):\n",
    "            input_ids = hf_tokenizer.encode(inp, padding=True, truncation=True, return_tensors=\"pt\", **tok_kwargs)\n",
    "        else:\n",
    "            # note (10/30/2020): as of pytorch 1.7, this has to be a plain ol tensor (not a subclass of TensorBase)\n",
    "            input_ids = inp.as_subclass(Tensor)\n",
    "\n",
    "        input_ids = input_ids.to(self.model.hf_model.device)\n",
    "\n",
    "        gen_texts = self.model.hf_model.generate(input_ids, **text_gen_kwargs)\n",
    "        outputs = [hf_tokenizer.decode(txt, skip_special_tokens=True, clean_up_tokenization_spaces=False) for txt in gen_texts]\n",
    "\n",
    "        if tfm.hf_arch == \"pegasus\":\n",
    "            outputs = [o.replace(\"<n>\", \" \") for o in outputs]\n",
    "\n",
    "        results.append({key: outputs[0] if len(outputs) == 1 else outputs})\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"Learner.blurr_generate\" class=\"doc_header\"><code>Learner.blurr_generate</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Learner.blurr_generate</code>(**`items`**, **`key`**=*`'generated_texts'`*, **\\*\\*`kwargs`**)\n",
       "\n",
       "Uses the built-in `generate` method to generate the text\n",
       "(see [here](https://huggingface.co/transformers/main_classes/model.html#transformers.PreTrainedModel.generate)\n",
       "for a list of arguments you can pass in)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Learner.blurr_generate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference\n",
    "\n",
    "Using fast.ai `Learner.export` and `load_learner`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_fname = \"seq_class_learn_export\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.export(fname=f\"{export_fname}.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'neg',\n",
       "  'score': 0.9319486618041992,\n",
       "  'class_index': 0,\n",
       "  'class_labels': ['neg', 'pos'],\n",
       "  'probs': [0.9319486618041992, 0.0680513009428978]}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_learn = load_learner(fname=f\"{export_fname}.pkl\")\n",
    "inf_learn.blurr_predict(\"This movie should not be seen by anyone!!!!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "try:\n",
    "    del learn\n",
    "    del inf_learn\n",
    "    torch.cuda.empty_cache()\n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High-level API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Blearner` -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide_output\n",
    "model_cls = AutoModelForSequenceClassification\n",
    "\n",
    "pretrained_model_name = \"distilroberta-base\"  # \"distilbert-base-uncased\" \"bert-base-uncased\"\n",
    "hf_arch, hf_config, hf_tokenizer, hf_model = get_hf_objects(pretrained_model_name, model_cls=model_cls)\n",
    "\n",
    "dls = dblock.dataloaders(imdb_df, bs=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@delegates(Learner.__init__)\n",
    "class Blearner(Learner):\n",
    "    def __init__(\n",
    "        self,\n",
    "        # Your fastai DataLoaders\n",
    "        dls: DataLoaders,\n",
    "        # Your pretrained Hugging Face transformer\n",
    "        hf_model: PreTrainedModel,\n",
    "        # Your `BaseModelCallback`\n",
    "        base_model_cb: BaseModelCallback = BaseModelCallback,\n",
    "        # Any kwargs you want to pass to your `BLearner`\n",
    "        **kwargs\n",
    "    ) -> Learner:\n",
    "        \"\"\"\n",
    "        Returns a Blurr friendly `Learner` ready for model training\n",
    "        \"\"\"\n",
    "        model = kwargs.get(\"model\", BaseModelWrapper(hf_model))\n",
    "        splitter = kwargs.pop(\"splitter\", blurr_splitter)\n",
    "        loss_func = kwargs.pop(\"loss_func\", dls.loss_func if hasattr(dls, \"loss_func\") else None)\n",
    "\n",
    "        # if we are letting the Hugging Face model calculate the loss for us (which is the default), we update\n",
    "        # our loss function here to simply used the correct `PrecalculatedLoss`\n",
    "        tfm = first_blurr_tfm(dls)\n",
    "        if hasattr(tfm, \"include_labels\") and tfm.include_labels:\n",
    "            if isinstance(loss_func, CrossEntropyLossFlat):\n",
    "                loss_func = PreCalculatedCrossEntropyLoss()\n",
    "            elif isinstance(loss_func, BCEWithLogitsLossFlat):\n",
    "                loss_func = PreCalculatedBCELoss()\n",
    "            elif isinstance(loss_func.func, nn.MSELoss):\n",
    "                loss_func = PreCalculatedMSELoss()\n",
    "\n",
    "        super().__init__(dls, model=model, loss_func=loss_func, splitter=splitter, **kwargs)\n",
    "\n",
    "        self.add_cb(base_model_cb)\n",
    "        self.freeze()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of constructing our low-level `Learner`, we can use the `Blearner` class which provides sensible defaults for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Blearner(dls, hf_model, metrics=[accuracy])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.304205</td>\n",
       "      <td>0.334683</td>\n",
       "      <td>0.854167</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, lr_max=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Match 1: Tag Team Table Match Bubba Ray and Spike Dudley vs Eddie Guerrero and Chris Benoit Bubba Ray and Spike Dudley started things off with a Tag Team Table Match against Eddie Guerrero and Chris Benoit. According to the rules of the match, both opponents have to go through tables in order to get the win. Benoit and Guerrero heated up early on by taking turns hammering first Spike and then Bubba Ray. A German suplex by Benoit to Bubba took the wind out of the Dudley brother. Spike tried to h</td>\n",
       "      <td>pos</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>THE SHOP AROUND THE CORNER is one of the sweetest and most feel-good romantic comedies ever made. There's just no getting around that, and it's hard to actually put one's feeling for this film into words. It's not one of those films that tries too hard, nor does it come up with the oddest possible scenarios to get the two protagonists together in the end. In fact, all its charm is innate, contained within the characters and the setting and the plot... which is highly believable to boot. It's ea</td>\n",
       "      <td>pos</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, max_n=2, trunc_at=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'pos',\n",
       "  'score': 0.9181244969367981,\n",
       "  'class_index': 1,\n",
       "  'class_labels': ['neg', 'pos'],\n",
       "  'probs': [0.08187545090913773, 0.9181244969367981]}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.blurr_predict(\"This was a really good movie\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'neg',\n",
       "  'score': 0.9200975894927979,\n",
       "  'class_index': 0,\n",
       "  'class_labels': ['neg', 'pos'],\n",
       "  'probs': [0.9200975894927979, 0.07990235835313797]}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.export(fname=f\"{export_fname}.pkl\")\n",
    "inf_learn = load_learner(fname=f\"{export_fname}.pkl\")\n",
    "inf_learn.blurr_predict(\"This movie should not be seen by anyone!!!!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "try:\n",
    "    del learn\n",
    "    del inf_learn\n",
    "    torch.cuda.empty_cache()\n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `BlearnerForSequenceClassification` -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@delegates(Blearner.__init__)\n",
    "class BlearnerForSequenceClassification(Blearner):\n",
    "    def __init__(self, dls: DataLoaders, hf_model: PreTrainedModel, **kwargs):\n",
    "        super().__init__(dls, hf_model, **kwargs)\n",
    "\n",
    "    def predict(self, text):\n",
    "        return self.blurr_predict(text)\n",
    "\n",
    "    @classmethod\n",
    "    def get_model_cls(self):\n",
    "        return AutoModelForSequenceClassification\n",
    "\n",
    "    @classmethod\n",
    "    def _get_x(cls, r, attr):\n",
    "        return r[attr] if (isinstance(attr, str)) else tuple(r[inp] for inp in attr)\n",
    "\n",
    "    @classmethod\n",
    "    def _get_y(cls, r, attr):\n",
    "        return r[attr] if (isinstance(attr, str)) else [r[inp] for inp in attr]\n",
    "\n",
    "    @classmethod\n",
    "    def from_data(\n",
    "        cls,\n",
    "        # Your raw dataset. Supports DataFrames, Hugging Face Datasets, as well as file paths\n",
    "        # to .csv, .xlsx, .xls, and .jsonl files\n",
    "        data: Union[pd.DataFrame, Path, str, List[Dict]],\n",
    "        # The name or path of the pretrained model you want to fine-tune\n",
    "        pretrained_model_name_or_path: Optional[Union[str, os.PathLike]],\n",
    "        # The attribute in your dataset that contains your raw text\n",
    "        text_attr: str = \"text\",\n",
    "        # The attribute in your dataset that contains your labels/targets\n",
    "        label_attr: str = \"label\",\n",
    "        # The number of labels/classes your model should predict\n",
    "        n_labels: Optional[int] = None,\n",
    "        # A function that will split your Dataset into a training and validation set\n",
    "        # See [here](https://docs.fast.ai/data.transforms.html#Split) for a list of fast.ai splitters\n",
    "        dblock_splitter: Optional[Callable] = None,\n",
    "        # Any kwargs to pass to your `DataLoaders`\n",
    "        dl_kwargs: dict = {},\n",
    "        # Any kwargs to pass to your task specific `Blearner`\n",
    "        learner_kwargs: dict = {},\n",
    "    ):\n",
    "        # if we get a path/str then we're loading something like a .csv file\n",
    "        if isinstance(data, Path) or isinstance(data, str):\n",
    "            content_type = mimetypes.guess_type(data)[0]\n",
    "            if content_type == \"application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\":\n",
    "                data = pd.read_excel(data)\n",
    "            elif content_type == \"text/csv\":\n",
    "                data = pd.read_csv(data)\n",
    "            elif content_type == \"application/json\":\n",
    "                data = pd.read_json(data, orient=\"records\")\n",
    "            else:\n",
    "                raise ValueError(\"'data' must be a .xlsx, .xls, .csv, or .jsonl file\")\n",
    "\n",
    "            data = pd.read_csv(data)\n",
    "\n",
    "        # we need to tell transformer how many labels/classes to expect\n",
    "        if n_labels is None:\n",
    "            if isinstance(data, pd.DataFrame):\n",
    "                n_labels = len(label_attr) if (is_listy(label_attr)) else len(data[label_attr].unique())\n",
    "            else:\n",
    "                n_labels = len(label_attr) if (is_listy(label_attr)) else len(set([item[label_attr] for item in data]))\n",
    "\n",
    "        # infer our datablock splitter if None\n",
    "        if dblock_splitter is None:\n",
    "            dblock_splitter = ColSplitter() if hasattr(data, \"is_valid\") else RandomSplitter()\n",
    "\n",
    "        # get our hf objects\n",
    "        hf_arch, hf_config, hf_tokenizer, hf_model = get_hf_objects(\n",
    "            pretrained_model_name_or_path, model_cls=cls.get_model_cls(), config_kwargs={\"num_labels\": n_labels}\n",
    "        )\n",
    "\n",
    "        # not all architectures include a native pad_token (e.g., gpt2, ctrl, etc...), so we add one here\n",
    "        if hf_tokenizer.pad_token is None:\n",
    "            hf_tokenizer.add_special_tokens({\"pad_token\": \"<pad>\"})\n",
    "            hf_config.pad_token_id = hf_tokenizer.get_vocab()[\"<pad>\"]\n",
    "            hf_model.resize_token_embeddings(len(hf_tokenizer))\n",
    "\n",
    "        # infer loss function and default metrics\n",
    "        if is_listy(label_attr):\n",
    "            trg_block = MultiCategoryBlock(encoded=True, vocab=label_attr)\n",
    "            learner_kwargs[\"metrics\"] = learner_kwargs.get(\"metrics\", [F1ScoreMulti(), accuracy_multi])\n",
    "        else:\n",
    "            trg_block = CategoryBlock\n",
    "            learner_kwargs[\"metrics\"] = learner_kwargs.get(\"metrics\", [F1Score(), accuracy])\n",
    "\n",
    "        # build our DataBlock and DataLoaders\n",
    "        blocks = (TextBlock(hf_arch, hf_config, hf_tokenizer, hf_model), trg_block)\n",
    "        dblock = DataBlock(\n",
    "            blocks=blocks, get_x=partial(cls._get_x, attr=text_attr), get_y=partial(cls._get_y, attr=label_attr), splitter=dblock_splitter\n",
    "        )\n",
    "\n",
    "        dls = dblock.dataloaders(data, **dl_kwargs.copy())\n",
    "\n",
    "        # return BLearner instance\n",
    "        return cls(dls, hf_model, **learner_kwargs.copy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also introduce a classification task specific `Blearner` that get you your DataBlock, DataLoaders, and BLearner in one line of code!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Mid-level API building blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = BlearnerForSequenceClassification.from_data(\n",
    "    imdb_df, \"distilroberta-base\", text_attr=\"text\", label_attr=\"label\", dl_kwargs={\"bs\": 4}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.277279</td>\n",
       "      <td>0.241745</td>\n",
       "      <td>0.932203</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, lr_max=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is one of those films where it is easy to see how some people wouldn't like it. My wife has never seen it, and when I just rewatched it last night, I waited until after she went to bed. She might have been amused by a couple small snippets, but I know she would have had enough within ten minutes.&lt;br /&gt;&lt;br /&gt;Head has nothing like a conventional story. The film is firmly mired in the psychedelic era. It could be seen as filmic surrealism in a nutshell, or as something of a postmodern acid tr</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The opening night for the 'South Asian International Film Festival' (SAIFF) in New York was an event a lot of us were waiting for.&lt;br /&gt;&lt;br /&gt;I would finally get to watch 'Hari Om'  I was tired of watching the \"promo\" on a loop and the lingering taste of the song Angel by Nitin Sawhney in the promo, left me begging to hear the rest of it. I was impressed by the visuals and tremendously curious about how the rugged looking auto rickshaw driver would win the hearts of the stunning sophisticated</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, max_n=2, trunc_at=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': '1',\n",
       "  'score': 0.886829137802124,\n",
       "  'class_index': 1,\n",
       "  'class_labels': [0, 1],\n",
       "  'probs': [0.11317088454961777, 0.886829137802124]}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.predict(\"This was a really good movie\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': '0',\n",
       "  'score': 0.920820951461792,\n",
       "  'class_index': 0,\n",
       "  'class_labels': [0, 1],\n",
       "  'probs': [0.920820951461792, 0.07917908579111099]}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.export(fname=f\"{export_fname}.pkl\")\n",
    "inf_learn = load_learner(fname=f\"{export_fname}.pkl\")\n",
    "inf_learn.blurr_predict(\"This movie should not be seen by anyone!!!!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Low-level API building blocks\n",
    "\n",
    "Thanks to the `TextDataLoader`, there isn't really anything you have to do to use plain ol' PyTorch or fast.ai `Dataset`s and `DataLoaders` with Blurr.  Let's take a look at fine-tuning a model against Glue's MRPC dataset ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Build your Hugging Face objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cls = AutoModelForSequenceClassification\n",
    "\n",
    "pretrained_model_name = \"distilroberta-base\"  # \"distilbert-base-uncased\" \"bert-base-uncased\"\n",
    "hf_arch, hf_config, hf_tokenizer, hf_model = get_hf_objects(pretrained_model_name, model_cls=model_cls)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preprocess your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset glue (/home/wgilliam/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c8ca0a4e5c0468c8535931c0e8dc2ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from blurr.text.data.core import preproc_hf_dataset\n",
    "\n",
    "raw_datasets = load_dataset(\"glue\", \"mrpc\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/wgilliam/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-f3774ba9358a732c.arrow\n",
      "Loading cached processed dataset at /home/wgilliam/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-84263331ad583603.arrow\n",
      "Loading cached processed dataset at /home/wgilliam/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-b7fe644c800de3c0.arrow\n"
     ]
    }
   ],
   "source": [
    "def tokenize_function(example):\n",
    "    return hf_tokenizer(example[\"sentence1\"], example[\"sentence2\"], truncation=True)\n",
    "\n",
    "\n",
    "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Build your `DataLoaders`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = raw_datasets[\"train\"].features[\"label\"].names\n",
    "\n",
    "trn_dl = TextDataLoader(\n",
    "    tokenized_datasets[\"train\"],\n",
    "    hf_arch=hf_arch,\n",
    "    hf_config=hf_config,\n",
    "    hf_tokenizer=hf_tokenizer,\n",
    "    hf_model=hf_model,\n",
    "    preproccesing_func=preproc_hf_dataset,\n",
    "    batch_decode_kwargs={\"labels\": label_names},\n",
    "    shuffle=True,\n",
    "    batch_size=8,\n",
    ")\n",
    "\n",
    "val_dl = TextDataLoader(\n",
    "    tokenized_datasets[\"validation\"],\n",
    "    hf_arch=hf_arch,\n",
    "    hf_config=hf_config,\n",
    "    hf_tokenizer=hf_tokenizer,\n",
    "    hf_model=hf_model,\n",
    "    preproccesing_func=preproc_hf_dataset,\n",
    "    batch_decode_kwargs={\"labels\": label_names},\n",
    "    batch_size=16,\n",
    ")\n",
    "\n",
    "dls = DataLoaders(trn_dl, val_dl)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define your `Blearner`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = BlearnerForSequenceClassification(dls, hf_model, loss_func=PreCalculatedCrossEntropyLoss())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(valley=9.120108734350652e-05)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.509355</td>\n",
       "      <td>0.475181</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, lr_max=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.509265</td>\n",
       "      <td>0.475472</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.484401</td>\n",
       "      <td>0.474938</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(2, lr_max=slice(1e-8, 1e-6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Spansion products are to be available from both AMD and Fujitsu, AMD said. Spansion Flash memory solutions are available worldwide from AMD and Fujitsu.</td>\n",
       "      <td>equivalent</td>\n",
       "      <td>equivalent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>However, EPA officials would not confirm the 20 percent figure. Only in the past few weeks have officials settled on the 20 percent figure.</td>\n",
       "      <td>not_equivalent</td>\n",
       "      <td>equivalent</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, max_n=2, trunc_at=500)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests\n",
    "\n",
    "The tests below to ensure the core training code above works for **all** pretrained sequence classification models available in Hugging Face.  These tests are excluded from the CI workflow because of how long they would take to run and the amount of data that would be required to download.\n",
    "\n",
    "**Note**: Feel free to modify the code below to test whatever pretrained classification models you are working with ... and if any of your pretrained sequence classification models fail, please submit a github issue *(or a PR if you'd like to fix it yourself)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "try:\n",
    "    del learn\n",
    "    del inf_learn\n",
    "    torch.cuda.empty_cache()\n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AlbertForSequenceClassification',\n",
       " 'BartForSequenceClassification',\n",
       " 'BertForSequenceClassification',\n",
       " 'BigBirdForSequenceClassification',\n",
       " 'BigBirdPegasusForSequenceClassification',\n",
       " 'CTRLForSequenceClassification',\n",
       " 'CamembertForSequenceClassification',\n",
       " 'CanineForSequenceClassification',\n",
       " 'ConvBertForSequenceClassification',\n",
       " 'DebertaForSequenceClassification',\n",
       " 'DebertaV2ForSequenceClassification',\n",
       " 'DistilBertForSequenceClassification',\n",
       " 'ElectraForSequenceClassification',\n",
       " 'FNetForSequenceClassification',\n",
       " 'FlaubertForSequenceClassification',\n",
       " 'FunnelForSequenceClassification',\n",
       " 'GPT2ForSequenceClassification',\n",
       " 'GPTJForSequenceClassification',\n",
       " 'GPTNeoForSequenceClassification',\n",
       " 'HubertForSequenceClassification',\n",
       " 'IBertForSequenceClassification',\n",
       " 'LEDForSequenceClassification',\n",
       " 'LayoutLMForSequenceClassification',\n",
       " 'LayoutLMv2ForSequenceClassification',\n",
       " 'LongformerForSequenceClassification',\n",
       " 'MBartForSequenceClassification',\n",
       " 'MPNetForSequenceClassification',\n",
       " 'MegatronBertForSequenceClassification',\n",
       " 'MobileBertForSequenceClassification',\n",
       " 'NystromformerForSequenceClassification',\n",
       " 'OpenAIGPTForSequenceClassification',\n",
       " 'PerceiverForSequenceClassification',\n",
       " 'ReformerForSequenceClassification',\n",
       " 'RemBertForSequenceClassification',\n",
       " 'RoFormerForSequenceClassification',\n",
       " 'RobertaForSequenceClassification',\n",
       " 'SEWDForSequenceClassification',\n",
       " 'SEWForSequenceClassification',\n",
       " 'SqueezeBertForSequenceClassification',\n",
       " 'TransfoXLForSequenceClassification',\n",
       " 'UniSpeechForSequenceClassification',\n",
       " 'UniSpeechSatForSequenceClassification',\n",
       " 'Wav2Vec2ForSequenceClassification',\n",
       " 'WavLMForSequenceClassification',\n",
       " 'XLMForSequenceClassification',\n",
       " 'XLMRobertaForSequenceClassification',\n",
       " 'XLNetForSequenceClassification',\n",
       " 'YosoForSequenceClassification']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hide\n",
    "[model_type for model_type in NLP.get_models(task=\"SequenceClassification\") if (not model_type.startswith(\"TF\"))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "pretrained_model_names = [\n",
    "    \"hf-internal-testing/tiny-albert\",\n",
    "    \"hf-internal-testing/tiny-random-bart\",\n",
    "    \"hf-internal-testing/tiny-bert\",\n",
    "    \"google/bigbird-roberta-base\",\n",
    "    \"google/bigbird-pegasus-large-arxiv\",\n",
    "    \"hf-internal-testing/tiny-random-ctrl\",\n",
    "    \"camembert-base\",\n",
    "    \"hf-internal-testing/tiny-random-canine\",\n",
    "    \"YituTech/conv-bert-base\",\n",
    "    \"hf-internal-testing/tiny-deberta\",\n",
    "    \"hf-internal-testing/tiny-random-deberta-v2\",\n",
    "    \"hf-internal-testing/tiny-random-distilbert\",\n",
    "    \"hf-internal-testing/tiny-electra\",\n",
    "    \"google/fnet-base\",\n",
    "    \"hf-internal-testing/tiny-random-flaubert\",\n",
    "    \"hf-internal-testing/tiny-random-funnel\",\n",
    "    \"hf-internal-testing/tiny-random-gpt2\",\n",
    "    \"anton-l/gpt-j-tiny-random\",\n",
    "    \"hf-internal-testing/tiny-random-gpt_neo\",\n",
    "    \"kssteven/ibert-roberta-base\",\n",
    "    \"hf-internal-testing/tiny-random-led\",\n",
    "    \"hf-internal-testing/tiny-random-longformer\",\n",
    "    \"hf-internal-testing/tiny-random-mbart\",\n",
    "    \"hf-internal-testing/tiny-random-mpnet\",\n",
    "    # \"nvidia/megatron-bert-cased-345m\",                 could not test\n",
    "    \"hf-internal-testing/tiny-random-mobilebert\",\n",
    "    \"openai-gpt\",\n",
    "    \"google/reformer-crime-and-punishment\",\n",
    "    \"google/rembert\",\n",
    "    \"junnyu/roformer_chinese_sim_char_ft_small\",\n",
    "    \"roberta-base\",\n",
    "    \"squeezebert/squeezebert-uncased\",\n",
    "    \"hf-internal-testing/tiny-random-transfo-xl\",\n",
    "    \"xlm-mlm-en-2048\",\n",
    "    \"xlm-roberta-base\",\n",
    "    \"xlnet-base-cased\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset imdb (/home/wgilliam/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba4ea24e09144266b8925c469664691e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at /home/wgilliam/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-bb082f8a90ea273a.arrow\n",
      "Loading cached shuffled indices for dataset at /home/wgilliam/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-5a941c558a0690b2.arrow\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "raw_datasets = load_dataset(\"imdb\", split=[\"train\", \"test\"])\n",
    "raw_datasets[0] = raw_datasets[0].add_column(\"is_valid\", [False] * len(raw_datasets[0]))\n",
    "raw_datasets[1] = raw_datasets[1].add_column(\"is_valid\", [True] * len(raw_datasets[1]))\n",
    "\n",
    "final_ds = concatenate_datasets([raw_datasets[0].shuffle().select(range(1000)), raw_datasets[1].shuffle().select(range(200))])\n",
    "imdb_df = pd.DataFrame(final_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== hf-internal-testing/tiny-albert ===\n",
      "\n",
      "architecture:\talbert\n",
      "tokenizer:\tAlbertTokenizerFast\n",
      "model:\t\tAlbertForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>warner brothers tampered considerably with american history in \"big trail\" director raoul walsh's first</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>movie title - tartbr /br /date of review - 5/26/02b</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== hf-internal-testing/tiny-random-bart ===\n",
      "\n",
      "architecture:\tbart\n",
      "tokenizer:\tBartTokenizerFast\n",
      "model:\t\tBartForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Warner Brothers tampered considerably with American history in \"Big Trail\"</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>First off, the editing of this film consisted of one major flaw which I don't underst</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== hf-internal-testing/tiny-bert ===\n",
      "\n",
      "architecture:\tbert\n",
      "tokenizer:\tBertTokenizerFast\n",
      "model:\t\tBertForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>warner brothers tampered considerably with american history in \" big trail \" director raoul walsh's first - rate western \" they died with their boots on</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>movie title - tart &lt; br / &gt; &lt; br / &gt; date of review - 5 / 26 / 02 &lt; br / &gt; &lt; br / &gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== google/bigbird-roberta-base ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\tbig_bird\n",
      "tokenizer:\tBigBirdTokenizerFast\n",
      "model:\t\tBigBirdForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Warner Brothers tampered considerably with American history in \"Big Trail\" director Raoul Walsh's first-rate western \"They Died with Their Boots On,\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Movie Title - Tart&lt;br /&gt;&lt;br /&gt;Date of review - 5/26/02&lt;br /&gt;&lt;br /&gt;Year of movie - 2001</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== google/bigbird-pegasus-large-arxiv ===\n",
      "\n",
      "architecture:\tbigbird_pegasus\n",
      "tokenizer:\tPegasusTokenizerFast\n",
      "model:\t\tBigBirdPegasusForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Warner Brothers tampered considerably with American history in \"Big Trail\" director Raoul Walsh's first-rate western \"They Died with Their Boots On,\" a somewhat</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Movie Title - Tartbr /&gt;br /&gt;Date of review - 5/26/02br /&gt;br /&gt;Year of movie - 2001br</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== hf-internal-testing/tiny-random-ctrl ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/miniconda3/envs/blurr/lib/python3.9/site-packages/transformers/models/ctrl/modeling_ctrl.py:45: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  angle_rates = 1 / torch.pow(10000, (2 * (i // 2)) / d_model_size)\n",
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\tctrl\n",
      "tokenizer:\tCTRLTokenizer\n",
      "model:\t\tCTRLForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Warner Brothers tampered considerably with American history in \"Big Trail\" director Raoul Walsh's first-rate western \"They Died with Their Boots On,\" a somewhat inaccurate but wholly exhilarating biography of cavalry officer</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Movie Title - Tart&lt;br /&gt;&lt;br /&gt;Date of review - 5/26/02&lt;br /&gt;&lt;br /&gt;Year of movie -</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== camembert-base ===\n",
      "\n",
      "architecture:\tcamembert\n",
      "tokenizer:\tCamembertTokenizerFast\n",
      "model:\t\tCamembertForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Warner Brothers tampered considerably with American history in \"Big Trail\" director Raoul Walsh's first-</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>As a serious horror fan, I get that certain marketing ploys are used to sell movies, esp</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== hf-internal-testing/tiny-random-canine ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using unk_token, but it is not set yet.\n",
      "Using unk_token, but it is not set yet.\n",
      "Using unk_token, but it is not set yet.\n",
      "Using unk_token, but it is not set yet.\n",
      "Using unk_token, but it is not set yet.\n",
      "Using unk_token, but it is not set yet.\n",
      "Using unk_token, but it is not set yet.\n",
      "Using unk_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\tcanine\n",
      "tokenizer:\tCanineTokenizer\n",
      "model:\t\tCanineForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Warner Brothers tampered consi</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Movie Title - Tart&lt;br /&gt;&lt;br /&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== YituTech/conv-bert-base ===\n",
      "\n",
      "architecture:\tconvbert\n",
      "tokenizer:\tConvBertTokenizerFast\n",
      "model:\t\tConvBertForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>warner brothers tampered considerably with american history in \" big trail \" director raoul walsh's first - rate western \" they died with their boots on</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>recent years have seen a number of biopics of famous singers, and \" ray \", the story of ray charles, has much in common with</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== hf-internal-testing/tiny-deberta ===\n",
      "\n",
      "architecture:\tdeberta\n",
      "tokenizer:\tDebertaTokenizerFast\n",
      "model:\t\tDebertaForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/500 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== hf-internal-testing/tiny-random-deberta-v2 ===\n",
      "\n",
      "architecture:\tdeberta_v2\n",
      "tokenizer:\tDebertaV2Tokenizer\n",
      "model:\t\tDebertaV2ForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Warner Brothers tampered considerably with American history in \"Big Trail\" director Raoul Walsh's first-rate western \"They Died with Their Boots On,\" a</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Movie Title - Tart&lt;br /&gt;&lt;br /&gt;Date of review - 5/26/02&lt;br /&gt;&lt;br /&gt;Year of movie - 2001&lt;br /&gt;&lt;br</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== hf-internal-testing/tiny-random-distilbert ===\n",
      "\n",
      "architecture:\tdistilbert\n",
      "tokenizer:\tDistilBertTokenizerFast\n",
      "model:\t\tDistilBertForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>warner brothers tampered consider</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>recent years have seen a number of bi</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== hf-internal-testing/tiny-electra ===\n",
      "\n",
      "architecture:\telectra\n",
      "tokenizer:\tElectraTokenizerFast\n",
      "model:\t\tElectraForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>warner brothers tampered considerably with american history in \" big trail \" director raoul wal</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the monkees, surprisingly, are a big favorite of mine. yes, they might have</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== google/fnet-base ===\n",
      "\n",
      "architecture:\tfnet\n",
      "tokenizer:\tFNetTokenizerFast\n",
      "model:\t\tFNetForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/500 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== hf-internal-testing/tiny-random-flaubert ===\n",
      "\n",
      "architecture:\tflaubert\n",
      "tokenizer:\tFlaubertTokenizer\n",
      "model:\t\tFlaubertForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Warner Brothers tampered considerably with American history in \" Big Trail \" director Raoul Walsh' s first-rate western \" Th</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>As a serious horror fan, I get that certain marketing ploys are used to sell movies, especially the really</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== hf-internal-testing/tiny-random-funnel ===\n",
      "\n",
      "architecture:\tfunnel\n",
      "tokenizer:\tFunnelTokenizerFast\n",
      "model:\t\tFunnelForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>warner brothers tampered consider</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>movie title - tart &lt; br / &gt; &lt; br / &gt; date o</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== hf-internal-testing/tiny-random-gpt2 ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\tgpt2\n",
      "tokenizer:\tGPT2TokenizerFast\n",
      "model:\t\tGPT2ForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Warner Brothers tampered considerably with American history in \"Big Trail\" director</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Movie Title - Tart&lt;br /&gt;&lt;br /&gt;Date of review - 5/26/</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== anton-l/gpt-j-tiny-random ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\tgptj\n",
      "tokenizer:\tGPT2TokenizerFast\n",
      "model:\t\tGPTJForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Warner Brothers tampered considerably with American history in \"Big Trail\" director Raoul Walsh's first-rate western \"They Died with Their Boots On,\" a</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>As a serious horror fan, I get that certain marketing ploys are used to sell movies, especially the really bad ones. So I wouldn't call it naive</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== hf-internal-testing/tiny-random-gpt_neo ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\tgpt_neo\n",
      "tokenizer:\tGPT2TokenizerFast\n",
      "model:\t\tGPTNeoForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Warner Brothers tampered considerably with American history in \"Big Trail\" director</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Movie Title - Tart&lt;br /&gt;&lt;br /&gt;Date of review - 5/26/</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== kssteven/ibert-roberta-base ===\n",
      "\n",
      "architecture:\tibert\n",
      "tokenizer:\tRobertaTokenizer\n",
      "model:\t\tIBertForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Warner Brothers tampered considerably with American history in \"Big Trail\" director Raoul Walsh's first-rate western \"They Died with Their Boots On,\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Recent years have seen a number of biopics of famous singers, and \"Ray\", the story of Ray Charles, has much in common with \"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== hf-internal-testing/tiny-random-led ===\n",
      "\n",
      "architecture:\tled\n",
      "tokenizer:\tLEDTokenizerFast\n",
      "model:\t\tLEDForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Warner Brothers tampered considerably with American history in \"Big Trail\"</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Movie Title - Tart&lt;br /&gt;&lt;br /&gt;Date of review - 5/2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== hf-internal-testing/tiny-random-longformer ===\n",
      "\n",
      "architecture:\tlongformer\n",
      "tokenizer:\tLongformerTokenizerFast\n",
      "model:\t\tLongformerForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Warner Brothers tampered considerably with American history in \"Big Trail\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Recent years have seen a number of biopics of famous singers, and \"Ray\", the story</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== hf-internal-testing/tiny-random-mbart ===\n",
      "\n",
      "architecture:\tmbart\n",
      "tokenizer:\tMBartTokenizerFast\n",
      "model:\t\tMBartForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Warner Brothers tampered considerably with American history in \"Big T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>As a serious horror fan, I get that certain marketing ploys are used to sell mo</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== hf-internal-testing/tiny-random-mpnet ===\n",
      "\n",
      "architecture:\tmpnet\n",
      "tokenizer:\tMPNetTokenizerFast\n",
      "model:\t\tMPNetForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>warner brothers tampered consider</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>movie title - tart &lt; br / &gt; &lt; br / &gt; date o</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== hf-internal-testing/tiny-random-mobilebert ===\n",
      "\n",
      "architecture:\tmobilebert\n",
      "tokenizer:\tMobileBertTokenizerFast\n",
      "model:\t\tMobileBertForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>warner brothers tampered consider</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>recent years have seen a number of bi</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== openai-gpt ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\topenai\n",
      "tokenizer:\tOpenAIGPTTokenizerFast\n",
      "model:\t\tOpenAIGPTForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>warner brothers tampered considerably with american history in \" big trail \" director raoul walsh's first - rate western \" they died with their boots on, \" a somewhat</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>recent years have seen a number of biopics of famous singers, and \" ray \", the story of ray charles, has much in common with \" walk</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== google/reformer-crime-and-punishment ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\treformer\n",
      "tokenizer:\tReformerTokenizerFast\n",
      "model:\t\tReformerForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/500 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== google/rembert ===\n",
      "\n",
      "architecture:\trembert\n",
      "tokenizer:\tRemBertTokenizerFast\n",
      "model:\t\tRemBertForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Warner Brothers tampered considerably with American history in \"Big Trail\" director Raoul Walsh's first-rate western \"They Died with Their Boots On</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Movie Title - Tart&lt;br /&gt;&lt;br /&gt;Date of review - 5/26/02&lt;br /&gt;&lt;br /&gt;Year of movie - 2001&lt;br /&gt;&lt;br</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== junnyu/roformer_chinese_sim_char_ft_small ===\n",
      "\n",
      "architecture:\troformer\n",
      "tokenizer:\tRoFormerTokenizerFast\n",
      "model:\t\tRoFormerForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>warner brothers tampered considerably with american history in \" big trail \" director raoul w</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>recent years have seen a number of biopics of famous singers, and \" ray \", the story of ray</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== roberta-base ===\n",
      "\n",
      "architecture:\troberta\n",
      "tokenizer:\tRobertaTokenizerFast\n",
      "model:\t\tRobertaForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Warner Brothers tampered considerably with American history in \"Big Trail\" director Raoul Walsh's first-rate western \"They Died with Their Boots On,\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Movie Title - Tart&lt;br /&gt;&lt;br /&gt;Date of review - 5/26/02&lt;br /&gt;&lt;br /&gt;Year of movie - 2001</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== squeezebert/squeezebert-uncased ===\n",
      "\n",
      "architecture:\tsqueezebert\n",
      "tokenizer:\tSqueezeBertTokenizerFast\n",
      "model:\t\tSqueezeBertForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>warner brothers tampered considerably with american history in \" big trail \" director raoul walsh's first - rate western \" they died with their boots on</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>first off, the editing of this film consisted of one major flaw which i don't understand how was missed - you consistently see the overhead microphones</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== hf-internal-testing/tiny-random-transfo-xl ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\ttransfo_xl\n",
      "tokenizer:\tTransfoXLTokenizer\n",
      "model:\t\tTransfoXLForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Warner Brothers tampered considerably with American history in \"Big Trail\" director Raoul Walsh's first-rate western \"They Died with Their Boots On,\" a somewhat inaccurate</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Recent years have seen a number of biopics of famous singers, and \"Ray,\" the story of Ray Charles, has much in common with \"Walk the Line</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== xlm-mlm-en-2048 ===\n",
      "\n",
      "architecture:\txlm\n",
      "tokenizer:\tXLMTokenizer\n",
      "model:\t\tXLMForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>warner brothers tampered considerably with american history in \" big trail \" director raoul walsh's first-rate western \" they died with their boots on, \"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>recent years have seen a number of biopics of famous singers, and \" ray, \" the story of ray charles, has much in common with \"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== xlm-roberta-base ===\n",
      "\n",
      "architecture:\txlm_roberta\n",
      "tokenizer:\tXLMRobertaTokenizerFast\n",
      "model:\t\tXLMRobertaForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Warner Brothers tampered considerably with American history in \"Big Trail\" director Raoul Walsh's first-rate western \"They Die</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Recent years have seen a number of biopics of famous singers, and \"Ray\", the story of Ray Charles, has much in common with</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== xlnet-base-cased ===\n",
      "\n",
      "architecture:\txlnet\n",
      "tokenizer:\tXLNetTokenizerFast\n",
      "model:\t\tXLNetForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Warner Brothers tampered considerably with American history in \"Big Trail\" director Raoul Walsh's first-rate western \"They Died with</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Recent years have seen a number of biopics of famous singers, and \"Ray\", the story of Ray Charles, has much in common</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide\n",
    "from transformers import RobertaTokenizer\n",
    "\n",
    "model_cls = AutoModelForSequenceClassification\n",
    "bsz = 2\n",
    "seq_sz = 32\n",
    "\n",
    "test_results = []\n",
    "for model_name in pretrained_model_names:\n",
    "    error = None\n",
    "\n",
    "    print(f\"=== {model_name} ===\\n\")\n",
    "\n",
    "    # 1. get/configure our Hugging Face objects\n",
    "    tok_class = RobertaTokenizer if (\"/ibert\" in model_name) else None\n",
    "\n",
    "    hf_arch, hf_config, hf_tokenizer, hf_model = get_hf_objects(\n",
    "        model_name, model_cls=model_cls, tokenizer_cls=tok_class, config_kwargs={\"num_labels\": 2}\n",
    "    )\n",
    "\n",
    "    print(f\"architecture:\\t{hf_arch}\\ntokenizer:\\t{type(hf_tokenizer).__name__}\\nmodel:\\t\\t{type(hf_model).__name__}\\n\")\n",
    "\n",
    "    # not all architectures include a native pad_token (e.g., gpt2, ctrl, etc...), so we add one here\n",
    "    if hf_tokenizer.pad_token is None:\n",
    "        hf_tokenizer.add_special_tokens({\"pad_token\": \"<pad>\"})\n",
    "        hf_config.pad_token_id = hf_tokenizer.get_vocab()[\"<pad>\"]\n",
    "        hf_model.resize_token_embeddings(len(hf_tokenizer))\n",
    "\n",
    "    try:\n",
    "        learn = None\n",
    "\n",
    "        # 2. get our DataLoaders\n",
    "        blocks = (TextBlock(hf_arch, hf_config, hf_tokenizer, hf_model, max_length=seq_sz, padding=\"max_length\"), CategoryBlock)\n",
    "\n",
    "        dblock = DataBlock(blocks=blocks, get_x=ColReader(\"text\"), get_y=ColReader(\"label\"), splitter=ColSplitter(col=\"is_valid\"))\n",
    "\n",
    "        dls = dblock.dataloaders(imdb_df, bs=bsz)\n",
    "\n",
    "        # 3. configure our Learner\n",
    "        model = BaseModelWrapper(hf_model)\n",
    "        learn = Learner(\n",
    "            dls,\n",
    "            model,\n",
    "            opt_func=partial(Adam),\n",
    "            loss_func=CrossEntropyLossFlat(),\n",
    "            metrics=[accuracy],\n",
    "            cbs=[BaseModelCallback],\n",
    "            splitter=blurr_splitter,\n",
    "        )\n",
    "\n",
    "        learn.freeze()\n",
    "\n",
    "        b = dls.one_batch()\n",
    "\n",
    "        # 4. train\n",
    "        print(\"*** TESTING DataLoaders ***\")\n",
    "        test_eq(len(b), bsz)\n",
    "        test_eq(len(b[0][\"input_ids\"]), bsz)\n",
    "        test_eq(b[0][\"input_ids\"].shape, torch.Size([bsz, seq_sz]))\n",
    "        test_eq(len(b[1]), bsz)\n",
    "\n",
    "        #         print('*** TESTING One pass through the model ***')\n",
    "        #         preds = learn.model(b[0])\n",
    "        #         test_eq(len(preds[0]), bsz)\n",
    "        #         test_eq(preds[0].shape, torch.Size([bsz, 2]))\n",
    "\n",
    "        print(\"*** TESTING Training/Results ***\")\n",
    "        learn.fit_one_cycle(1, lr_max=1e-3, cbs=ShortEpochCallback(pct=0.2, short_valid=True))\n",
    "\n",
    "        test_results.append((hf_arch, type(hf_tokenizer).__name__, type(hf_model).__name__, \"PASSED\", \"\"))\n",
    "        learn.show_results(learner=learn, max_n=2, trunc_at=250)\n",
    "    except Exception as err:\n",
    "        test_results.append((hf_arch, type(hf_tokenizer).__name__, type(hf_model).__name__, \"FAILED\", err))\n",
    "    finally:\n",
    "        # cleanup\n",
    "        if learn:\n",
    "            del learn\n",
    "        torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arch</th>\n",
       "      <th>tokenizer</th>\n",
       "      <th>model</th>\n",
       "      <th>result</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>albert</td>\n",
       "      <td>AlbertTokenizerFast</td>\n",
       "      <td>AlbertForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bart</td>\n",
       "      <td>BartTokenizerFast</td>\n",
       "      <td>BartForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bert</td>\n",
       "      <td>BertTokenizerFast</td>\n",
       "      <td>BertForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>big_bird</td>\n",
       "      <td>BigBirdTokenizerFast</td>\n",
       "      <td>BigBirdForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bigbird_pegasus</td>\n",
       "      <td>PegasusTokenizerFast</td>\n",
       "      <td>BigBirdPegasusForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ctrl</td>\n",
       "      <td>CTRLTokenizer</td>\n",
       "      <td>CTRLForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>camembert</td>\n",
       "      <td>CamembertTokenizerFast</td>\n",
       "      <td>CamembertForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>canine</td>\n",
       "      <td>CanineTokenizer</td>\n",
       "      <td>CanineForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>convbert</td>\n",
       "      <td>ConvBertTokenizerFast</td>\n",
       "      <td>ConvBertForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>deberta</td>\n",
       "      <td>DebertaTokenizerFast</td>\n",
       "      <td>DebertaForSequenceClassification</td>\n",
       "      <td>FAILED</td>\n",
       "      <td>mat1 and mat2 shapes cannot be multiplied (2x32 and 768x768)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>deberta_v2</td>\n",
       "      <td>DebertaV2Tokenizer</td>\n",
       "      <td>DebertaV2ForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>distilbert</td>\n",
       "      <td>DistilBertTokenizerFast</td>\n",
       "      <td>DistilBertForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>electra</td>\n",
       "      <td>ElectraTokenizerFast</td>\n",
       "      <td>ElectraForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>fnet</td>\n",
       "      <td>FNetTokenizerFast</td>\n",
       "      <td>FNetForSequenceClassification</td>\n",
       "      <td>FAILED</td>\n",
       "      <td>forward() got an unexpected keyword argument 'output_attentions'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>flaubert</td>\n",
       "      <td>FlaubertTokenizer</td>\n",
       "      <td>FlaubertForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>funnel</td>\n",
       "      <td>FunnelTokenizerFast</td>\n",
       "      <td>FunnelForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>GPT2TokenizerFast</td>\n",
       "      <td>GPT2ForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>gptj</td>\n",
       "      <td>GPT2TokenizerFast</td>\n",
       "      <td>GPTJForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>gpt_neo</td>\n",
       "      <td>GPT2TokenizerFast</td>\n",
       "      <td>GPTNeoForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ibert</td>\n",
       "      <td>RobertaTokenizer</td>\n",
       "      <td>IBertForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>led</td>\n",
       "      <td>LEDTokenizerFast</td>\n",
       "      <td>LEDForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>longformer</td>\n",
       "      <td>LongformerTokenizerFast</td>\n",
       "      <td>LongformerForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>mbart</td>\n",
       "      <td>MBartTokenizerFast</td>\n",
       "      <td>MBartForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>mpnet</td>\n",
       "      <td>MPNetTokenizerFast</td>\n",
       "      <td>MPNetForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>mobilebert</td>\n",
       "      <td>MobileBertTokenizerFast</td>\n",
       "      <td>MobileBertForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>openai</td>\n",
       "      <td>OpenAIGPTTokenizerFast</td>\n",
       "      <td>OpenAIGPTForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>reformer</td>\n",
       "      <td>ReformerTokenizerFast</td>\n",
       "      <td>ReformerForSequenceClassification</td>\n",
       "      <td>FAILED</td>\n",
       "      <td>If training, make sure that config.axial_pos_shape factors: (512, 1024) multiply to sequence length. Got prod((512, 1024)) != sequence_length: 32. You might want to consider padding your sequence length to 524288 or changing config.axial_pos_shape.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>rembert</td>\n",
       "      <td>RemBertTokenizerFast</td>\n",
       "      <td>RemBertForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>roformer</td>\n",
       "      <td>RoFormerTokenizerFast</td>\n",
       "      <td>RoFormerForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>roberta</td>\n",
       "      <td>RobertaTokenizerFast</td>\n",
       "      <td>RobertaForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>squeezebert</td>\n",
       "      <td>SqueezeBertTokenizerFast</td>\n",
       "      <td>SqueezeBertForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>transfo_xl</td>\n",
       "      <td>TransfoXLTokenizer</td>\n",
       "      <td>TransfoXLForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>xlm</td>\n",
       "      <td>XLMTokenizer</td>\n",
       "      <td>XLMForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>xlm_roberta</td>\n",
       "      <td>XLMRobertaTokenizerFast</td>\n",
       "      <td>XLMRobertaForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>xlnet</td>\n",
       "      <td>XLNetTokenizerFast</td>\n",
       "      <td>XLNetForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide_input\n",
    "test_results_df = pd.DataFrame(test_results, columns=[\"arch\", \"tokenizer\", \"model\", \"result\", \"error\"])\n",
    "display_df(test_results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_callbacks.ipynb.\n",
      "Converted 00_utils.ipynb.\n",
      "Converted 01_text-callbacks.ipynb.\n",
      "Converted 01_text-utils.ipynb.\n",
      "Converted 11_text-data-core.ipynb.\n",
      "Converted 11_text-modeling-core.ipynb.\n",
      "Converted 12_text-data-language-modeling.ipynb.\n",
      "Converted 12_text-modeling-language-modeling.ipynb.\n",
      "Converted 13_text-data-token-classification.ipynb.\n",
      "Converted 13_text-modeling-token-classification.ipynb.\n",
      "Converted 14_text-data-question-answering.ipynb.\n",
      "Converted 14_text-modeling-question-answering.ipynb.\n",
      "Converted 20_text-data-seq2seq-core.ipynb.\n",
      "Converted 20_text-modeling-seq2seq-core.ipynb.\n",
      "Converted 21_text-data-seq2seq-summarization.ipynb.\n",
      "Converted 21_text-modeling-seq2seq-summarization.ipynb.\n",
      "Converted 22_text-data-seq2seq-translation.ipynb.\n",
      "Converted 22_text-modeling-seq2seq-translation.ipynb.\n",
      "Converted 99a_text-examples-high-level-api.ipynb.\n",
      "Converted 99b_text-examples-glue.ipynb.\n",
      "Converted 99c_text-examples-glue-plain-pytorch.ipynb.\n",
      "Converted 99d_text-examples-multilabel.ipynb.\n",
      "Converted 99e_text-examples-causal-lm-gpt2.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import notebook2script\n",
    "\n",
    "notebook2script()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('blurr')",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
