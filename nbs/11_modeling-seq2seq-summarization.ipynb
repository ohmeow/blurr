{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp modeling.seq2seq.summarization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_slow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modeling.seq2seq.summarization\n",
    "\n",
    "> This module contains custom models, custom splitters, etc... summarization tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import inspect, torch\n",
    "from typing import Callable, Dict, List, Optional, Union\n",
    "\n",
    "from fastai.callback.all import *\n",
    "from fastai.data.block import DataBlock, ColReader, ItemGetter, ColSplitter, RandomSplitter\n",
    "from fastai.data.core import DataLoaders\n",
    "from fastai.imports import *\n",
    "from fastai.learner import *\n",
    "from fastai.torch_core import *\n",
    "from fastai.torch_imports import *\n",
    "from fastcore.all import *\n",
    "from transformers import AutoModelForSeq2SeqLM, PreTrainedModel, logging\n",
    "\n",
    "from blurr.utils import BLURR\n",
    "from blurr.data.seq2seq.core import Seq2SeqBatchTokenizeTransform, Seq2SeqTextBlock, default_text_gen_kwargs\n",
    "from blurr.modeling.core import BaseModelCallback, BaseModelWrapper, Blearner, PreCalculatedCrossEntropyLoss\n",
    "from blurr.modeling.seq2seq.core import Seq2SeqMetricsCallback, blurr_seq2seq_splitter\n",
    "\n",
    "logging.set_verbosity_error()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What we're running with at the time this documentation was generated:\n",
      "torch: 1.10.1+cu111\n",
      "fastai: 2.5.3\n",
      "transformers: 4.16.2\n"
     ]
    }
   ],
   "source": [
    "# hide_input\n",
    "import ast, os, inspect, pdb\n",
    "from functools import reduce\n",
    "\n",
    "from datasets import load_dataset\n",
    "from fastai.losses import CrossEntropyLossFlat\n",
    "from fastai.optimizer import Adam, ranger, OptimWrapper, params\n",
    "from fastcore.test import *\n",
    "from nbdev.showdoc import show_doc\n",
    "from transformers import BartForConditionalGeneration\n",
    "\n",
    "from blurr.utils import print_versions\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "print(\"What we're running with at the time this documentation was generated:\")\n",
    "print_versions(\"torch fastai transformers\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU #1: GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "# cuda\n",
    "torch.cuda.set_device(1)\n",
    "print(f\"Using GPU #{torch.cuda.current_device()}: {torch.cuda.get_device_name()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mid-level API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example\n",
    "\n",
    "The objective of summarization is to generate a concise and accurate representation of a much larger body of text.  For example, we may want to summarize an article in a single sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset cnn_dailymail (/home/wgilliam/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/3cb851bf7cf5826e45d49db2863f627cba583cbc32342df7349dfe6c38060234)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>highlights</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It's official: U.S. President Barack Obama wants lawmakers to weigh in on whether to use military force in Syria. Obama sent a letter to the heads of the House and Senate on Saturday night, hours after announcing that he believes military action against Syrian targets is the right step to take over the alleged use of chemical weapons. The proposed legislation from Obama asks Congress to approve the use of military force \"to deter, disrupt, prevent and degrade the potential for future uses of chemical weapons or other weapons of mass destruction.\" It's a step that is set to turn an internat...</td>\n",
       "      <td>Syrian official: Obama climbed to the top of the tree, \"doesn't know how to get down\"\\nObama sends a letter to the heads of the House and Senate .\\nObama to seek congressional approval on military action against Syria .\\nAim is to determine whether CW were used, not by whom, says U.N. spokesman .</td>\n",
       "      <td>0001d1afc246a7964130f43ae940af6bc6c57f01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(CNN) -- Usain Bolt rounded off the world championships Sunday by claiming his third gold in Moscow as he anchored Jamaica to victory in the men's 4x100m relay. The fastest man in the world charged clear of United States rival Justin Gatlin as the Jamaican quartet of Nesta Carter, Kemar Bailey-Cole, Nickel Ashmeade and Bolt won in 37.36 seconds. The U.S finished second in 37.56 seconds with Canada taking the bronze after Britain were disqualified for a faulty handover. The 26-year-old Bolt has now collected eight gold medals at world championships, equaling the record held by American trio...</td>\n",
       "      <td>Usain Bolt wins third gold of world championship .\\nAnchors Jamaica to 4x100m relay victory .\\nEighth gold at the championships for Bolt .\\nJamaica double up in women's 4x100m relay .</td>\n",
       "      <td>0002095e55fcbd3a2f366d9bf92a95433dc305ef</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   article  \\\n",
       "0  It's official: U.S. President Barack Obama wants lawmakers to weigh in on whether to use military force in Syria. Obama sent a letter to the heads of the House and Senate on Saturday night, hours after announcing that he believes military action against Syrian targets is the right step to take over the alleged use of chemical weapons. The proposed legislation from Obama asks Congress to approve the use of military force \"to deter, disrupt, prevent and degrade the potential for future uses of chemical weapons or other weapons of mass destruction.\" It's a step that is set to turn an internat...   \n",
       "1  (CNN) -- Usain Bolt rounded off the world championships Sunday by claiming his third gold in Moscow as he anchored Jamaica to victory in the men's 4x100m relay. The fastest man in the world charged clear of United States rival Justin Gatlin as the Jamaican quartet of Nesta Carter, Kemar Bailey-Cole, Nickel Ashmeade and Bolt won in 37.36 seconds. The U.S finished second in 37.56 seconds with Canada taking the bronze after Britain were disqualified for a faulty handover. The 26-year-old Bolt has now collected eight gold medals at world championships, equaling the record held by American trio...   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                  highlights  \\\n",
       "0  Syrian official: Obama climbed to the top of the tree, \"doesn't know how to get down\"\\nObama sends a letter to the heads of the House and Senate .\\nObama to seek congressional approval on military action against Syria .\\nAim is to determine whether CW were used, not by whom, says U.N. spokesman .   \n",
       "1                                                                                                                    Usain Bolt wins third gold of world championship .\\nAnchors Jamaica to 4x100m relay victory .\\nEighth gold at the championships for Bolt .\\nJamaica double up in women's 4x100m relay .   \n",
       "\n",
       "                                         id  \n",
       "0  0001d1afc246a7964130f43ae940af6bc6c57f01  \n",
       "1  0002095e55fcbd3a2f366d9bf92a95433dc305ef  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"cnn_dailymail\", \"3.0.0\", split=\"train[:1000]\")\n",
    "cnndm_df = pd.DataFrame(dataset)\n",
    "cnndm_df.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "\n",
    "# pretrained_model_name = \"t5-small\"\n",
    "# hf_arch, hf_config, hf_tokenizer, hf_model = BLURR.get_hf_objects(pretrained_model_name,\n",
    "#                                                                   model_cls=T5ForConditionalGeneration)\n",
    "\n",
    "# pretrained_model_name = \"google/pegasus-cnn_dailymail\"\n",
    "# hf_arch, hf_config, hf_tokenizer, hf_model = BLURR.get_hf_objects(pretrained_model_name,\n",
    "#                                                                   model_cls=PegasusForConditionalGeneration)\n",
    "\n",
    "# pretrained_model_name = \"facebook/bart-large-cnn\"\n",
    "# hf_arch, hf_config, hf_tokenizer, hf_model = BLURR.get_hf_objects(pretrained_model_name,\n",
    "#                                                                   model_cls=BartForConditionalGeneration)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('bart',\n",
       " transformers.models.bart.configuration_bart.BartConfig,\n",
       " transformers.models.bart.tokenization_bart_fast.BartTokenizerFast,\n",
       " transformers.models.bart.modeling_bart.BartForConditionalGeneration)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_model_name = \"sshleifer/distilbart-cnn-6-6\"\n",
    "hf_arch, hf_config, hf_tokenizer, hf_model = BLURR.get_hf_objects(pretrained_model_name, model_cls=BartForConditionalGeneration)\n",
    "\n",
    "hf_arch, type(hf_config), type(hf_tokenizer), type(hf_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_gen_kwargs = {}\n",
    "if hf_arch in [\"bart\", \"t5\"]:\n",
    "    text_gen_kwargs = {**hf_config.task_specific_params[\"summarization\"], **{\"max_length\": 30, \"min_length\": 10}}\n",
    "\n",
    "# not all \"summarization\" parameters are for the model.generate method ... remove them here\n",
    "generate_func_args = list(inspect.signature(hf_model.generate).parameters.keys())\n",
    "for k in text_gen_kwargs.copy():\n",
    "    if k not in generate_func_args:\n",
    "        del text_gen_kwargs[k]\n",
    "\n",
    "if hf_arch == \"mbart\":\n",
    "    text_gen_kwargs[\"decoder_start_token_id\"] = hf_tokenizer.get_vocab()[\"en_XX\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_kwargs = {}\n",
    "if hf_arch == \"mbart\":\n",
    "    tok_kwargs[\"src_lang\"], tok_kwargs[\"tgt_lang\"] = \"en_XX\", \"en_XX\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_tokenize_tfm = Seq2SeqBatchTokenizeTransform(\n",
    "    hf_arch,\n",
    "    hf_config,\n",
    "    hf_tokenizer,\n",
    "    hf_model,\n",
    "    max_length=256,\n",
    "    max_target_length=130,\n",
    "    tok_kwargs=tok_kwargs,\n",
    "    text_gen_kwargs=text_gen_kwargs,\n",
    ")\n",
    "\n",
    "blocks = (Seq2SeqTextBlock(batch_tokenize_tfm=batch_tokenize_tfm), noop)\n",
    "\n",
    "dblock = DataBlock(blocks=blocks, get_x=ColReader(\"article\"), get_y=ColReader(\"highlights\"), splitter=RandomSplitter())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = dblock.dataloaders(cnndm_df, bs=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = dls.one_batch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, torch.Size([2, 256]), torch.Size([2, 67]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b), b[0][\"input_ids\"].shape, b[1].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;s&gt; (CNN) -- When Ji Yeqing awakened, she was already in the recovery room. Chinese authorities had dragged her out of her home and down four flights of stairs, she said, restraining and beating her husband as he tried to come to her aid. They whisked her into a clinic, held her down on a bed and forced her to undergo an abortion. Her offense? Becoming pregnant with a second child, in violation of China's one-child policy. \"After the abortion, I felt empty, as if something was scooped out of me,\" Ji told a congressional panel in September. \"My husband and I had been so excited for our new baby. Now suddenly all that hope and joy and excitement disappeared.... I was very depressed and despondent. For a long time, whenever I thought about my lost child, I would cry.\" As she lay unconscious, she said, an IUD to prevent future pregnancies was inserted. The issue of forced abortions -- and in some cases, forced sterilizations -- in China has seized the spotlight in recent days with news of escaped activist Chen Guangcheng. Chen, a blind, self-taught lawyer, rose to fame in the late 1990s because of his advocacy for what he calls victims&lt;/s&gt;</td>\n",
       "      <td>China's one-child policy results in forced abortions and sterilizations, activists say.\\nWomen tell of emotional and physical consequences from the procedures.\\nActivist Chen Guangcheng works to advocate for victims of such practices.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;s&gt; (CNN) -- Sitting incongruously among the hangars and laboratories of NASA's Ames Research Center in Silicon Valley is the squat facade of an old McDonald's. You won't get a burger there, though -- its cash registers and soft-serve machines have given way to old tape drives and modern computers run by a rogue team of hacker engineers who've rechristened the place McMoon's. These self-described techno-archaeologists have been on a mission to recover and digitize forgotten photos taken in the '60s by a quintet of scuttled lunar satellites. The Lunar Orbiter Image Recovery Project (LOIRP) has since 2007 brought some 2,000 pictures back from 1,500 analog data tapes. They contain the first high-resolution photographs ever taken from behind the lunar horizon, including the first photo of an earthrise (first slide above). Thanks to the technical savvy and DIY engineering of the team at LOIRP, it's being seen at a higher resolution than was ever previously possible. \"We're reaching back to a capability that existed but couldn't be touched back when it was created,\" says Keith Cowing, co-lead and founding member at LOIRP. \"It's like having a DVD in&lt;/s&gt;</td>\n",
       "      <td>NASA-funded project has recovered 2,000 analog moon pictures.\\nThe images were taken by the five Lunar Orbiter images between 1966 and 1967.\\nProject uses old and modern technology to produce high-res copies of the originals.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch(dataloaders=dls, max_n=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2seq_metrics = {\n",
    "    \"rouge\": {\n",
    "        \"compute_kwargs\": {\"rouge_types\": [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"], \"use_stemmer\": True},\n",
    "        \"returns\": [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"],\n",
    "    },\n",
    "    \"bertscore\": {\"compute_kwargs\": {\"lang\": \"en\"}, \"returns\": [\"precision\", \"recall\", \"f1\"]},\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BaseModelWrapper(hf_model)\n",
    "learn_cbs = [BaseModelCallback]\n",
    "fit_cbs = [Seq2SeqMetricsCallback(custom_metrics=seq2seq_metrics)]\n",
    "\n",
    "learn = Learner(\n",
    "    dls,\n",
    "    model,\n",
    "    opt_func=partial(Adam),\n",
    "    loss_func=CrossEntropyLossFlat(),  # PreCalculatedLoss()\n",
    "    cbs=learn_cbs,\n",
    "    splitter=partial(blurr_seq2seq_splitter, arch=hf_arch),\n",
    ")\n",
    "\n",
    "# learn = learn.to_native_fp16() #.to_fp16()\n",
    "learn.freeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide_output\n",
    "# learn.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, torch.Size([]), torch.Size([2, 54, 50264]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = dls.one_batch()\n",
    "preds = learn.model(b[0])\n",
    "\n",
    "len(preds), preds[\"loss\"].shape, preds[\"logits\"].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3, torch.Size([2, 256]), 2, torch.Size([2, 54]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b), len(b[0]), b[0][\"input_ids\"].shape, len(b[1]), b[1].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(len(learn.opt.param_groups))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(minimum=8.317637839354575e-05, steep=6.309573450380412e-07, valley=9.120108734350652e-05, slide=9.120108734350652e-05)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find(suggest_funcs=[minimum, steep, valley, slide])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "      <th>bertscore_precision</th>\n",
       "      <th>bertscore_recall</th>\n",
       "      <th>bertscore_f1</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.245033</td>\n",
       "      <td>2.073924</td>\n",
       "      <td>0.307972</td>\n",
       "      <td>0.138422</td>\n",
       "      <td>0.236137</td>\n",
       "      <td>0.287112</td>\n",
       "      <td>0.889125</td>\n",
       "      <td>0.862924</td>\n",
       "      <td>0.875704</td>\n",
       "      <td>01:15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, lr_max=4e-5, cbs=fit_cbs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Showing results\n",
    "\n",
    "And here we create a `@typedispatch`ed implementation of `Learner.show_results`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Few question that there was a major chemical attack in Syria last week, and the United States has made clear that it blames the government of President Bashar al-Assad. Now, the question is how President Barack Obama will respond. For almost two years, Obama has avoided direct military involvement in Syria's civil war, only escalating aid to rebel fighters in June after suspected smaller-scale chemical weapons attacks by Syrian government forces. However, last week's attack on a Damascus suburb</td>\n",
       "      <td>U.S. evidence includes satellite imagery, official says.\\nObama is considering how to respond to Syrian chemical attack.\\nOfficial: Obama could be presented with options within days.\\nA U.S. strike \"can't just be one and done,\" a Middle East analyst sa</td>\n",
       "      <td>[ President Barack Obama has avoided direct military involvement in Syria's civil war .\\nLast week's attack on a Damascus suburb obliterated the \",  NEW: Specter died of complications from non-Hodgkin's lymphoma, his family says .\\nSpecter]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, input_trunc_at=500, target_trunc_at=250)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction\n",
    "\n",
    "We add here `Learner.blurr_summarize` method to bring the results inline with the format returned via Hugging Face's pipeline method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_article = \"\"\"\n",
    "About 10 men armed with pistols and small machine guns raided a casino in Switzerland and made off \n",
    "into France with several hundred thousand Swiss francs in the early hours of Sunday morning, police said. \n",
    "The men, dressed in black clothes and black ski masks, split into two groups during the raid on the Grand Casino \n",
    "Basel, Chief Inspector Peter Gill told CNN. One group tried to break into the casino's vault on the lower level \n",
    "but could not get in, but they did rob the cashier of the money that was not secured, he said. The second group \n",
    "of armed robbers entered the upper level where the roulette and blackjack tables are located and robbed the \n",
    "cashier there, he said. As the thieves were leaving the casino, a woman driving by and unaware of what was \n",
    "occurring unknowingly blocked the armed robbers' vehicles. A gunman pulled the woman from her vehicle, beat \n",
    "her, and took off for the French border. The other gunmen followed into France, which is only about 100 \n",
    "meters (yards) from the casino, Gill said. There were about 600 people in the casino at the time of the robbery. \n",
    "There were no serious injuries, although one guest on the Casino floor was kicked in the head by one of the \n",
    "robbers when he moved, the police officer said. Swiss authorities are working closely with French authorities, \n",
    "Gill said. The robbers spoke French and drove vehicles with French lRicense plates. CNN's Andreena Narayan \n",
    "contributed to this report.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_texts': [\" Police: 10 men armed with pistols and small machine guns raided a Swiss casino .\\nThey made off with several hundred thousand Swiss francs in the early hours of Sunday morning .\\nThe men, dressed in black clothes and black ski masks, split into two groups during the raid .\\nOne group tried to break into the casino's vault on the lower level but could not get\",\n",
       "   ' Police: 10 men armed with pistols and small machine guns raided a Swiss casino .\\nThey made off with several hundred thousand Swiss francs in the early hours of Sunday morning .\\nThe men, dressed in black clothes and black ski masks, split into two groups during the raid .\\nOne group tried to break into the vault on the lower level but could not get in .',\n",
       "   ' Police: 10 men armed with pistols and small machine guns raided a Swiss casino .\\nThey made off with several hundred thousand Swiss francs in the early hours of Sunday morning .\\nThe men, dressed in black clothes and black ski masks, split into two groups during the raid on the Grand Casino .']}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = learn.blurr_generate(test_article, key=\"summary_texts\", num_return_sequences=3)\n",
    "outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@patch\n",
    "def blurr_summarize(self: Learner, inp, **kwargs):\n",
    "    preds = self.blurr_generate(inp, key=\"summary_texts\", **kwargs)\n",
    "    return preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_texts': [\" Police: 10 men armed with pistols and small machine guns raided a Swiss casino .\\nThey made off with several hundred thousand Swiss francs in the early hours of Sunday morning .\\nThe men, dressed in black clothes and black ski masks, split into two groups during the raid .\\nOne group tried to break into the casino's vault on the lower level but could not get\",\n",
       "   ' Police: 10 men armed with pistols and small machine guns raided a Swiss casino .\\nThey made off with several hundred thousand Swiss francs in the early hours of Sunday morning .\\nThe men, dressed in black clothes and black ski masks, split into two groups during the raid .\\nOne group tried to break into the vault on the lower level but could not get in .',\n",
       "   ' Police: 10 men armed with pistols and small machine guns raided a Swiss casino .\\nThey made off with several hundred thousand Swiss francs in the early hours of Sunday morning .\\nThe men, dressed in black clothes and black ski masks, split into two groups during the raid on the Grand Casino .']}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.blurr_summarize(test_article, num_return_sequences=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference\n",
    "\n",
    "Using fast.ai `Learner.export` and `load_learner`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_fname = \"summarize_export\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.metrics = None\n",
    "learn.export(fname=f\"{export_fname}.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_texts': ' Police: 10 men armed with pistols and small machine guns raided a Swiss casino .\\nThey made off with several hundred thousand Swiss'}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_learn = load_learner(fname=f\"{export_fname}.pkl\")\n",
    "inf_learn.blurr_summarize(test_article)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "try:\n",
    "    del learn\n",
    "    del inf_learn\n",
    "    torch.cuda.empty_cache()\n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High-level API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `BlearnerForSummarization`\n",
    "\n",
    "We also introduce a task specific `Blearner` that get you your DataBlock, DataLoaders, and BLearner in one line of code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@delegates(Blearner.__init__)\n",
    "class BlearnerForSummarization(Blearner):\n",
    "    def __init__(self, dls: DataLoaders, hf_model: PreTrainedModel, **kwargs):\n",
    "        super().__init__(dls, hf_model, **kwargs)\n",
    "\n",
    "    def predict(self, text, **kwargs):\n",
    "        return self.blurr_summarize(text, **kwargs)\n",
    "\n",
    "    @classmethod\n",
    "    def get_model_cls(cls):\n",
    "        return AutoModelForSeq2SeqLM\n",
    "\n",
    "    @classmethod\n",
    "    def _add_t5_prefix(cls, inp):\n",
    "        return f\"summarize: {inp}\"\n",
    "\n",
    "    @classmethod\n",
    "    def get_metrics_cb(self):\n",
    "        seq2seq_metrics = {\n",
    "            \"rouge\": {\n",
    "                \"compute_kwargs\": {\"rouge_types\": [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"], \"use_stemmer\": True},\n",
    "                \"returns\": [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"],\n",
    "            },\n",
    "            \"bertscore\": {\"compute_kwargs\": {\"lang\": \"en\"}, \"returns\": [\"precision\", \"recall\", \"f1\"]},\n",
    "        }\n",
    "\n",
    "        return Seq2SeqMetricsCallback(custom_metrics=seq2seq_metrics)\n",
    "\n",
    "    @classmethod\n",
    "    def from_data(\n",
    "        cls,\n",
    "        # Your raw dataset. Supports DataFrames, Hugging Face Datasets, as well as file paths\n",
    "        # to .csv, .xlsx, .xls, and .jsonl files\n",
    "        data: Union[pd.DataFrame, Path, str, List[Dict]],\n",
    "        # The name or path of the pretrained model you want to fine-tune\n",
    "        pretrained_model_name_or_path: Optional[Union[str, os.PathLike]],\n",
    "        # The attribute in your dataset that contains your raw text\n",
    "        text_attr: str = \"text\",\n",
    "        # The attribute in your dataset that contains your target (summarized) text\n",
    "        summary_attr: str = \"summary\",\n",
    "        # The max length of your raw text to consider for summarization\n",
    "        max_length: Union[int, str] = None,\n",
    "        # The max length of your targets (sumamrized) text\n",
    "        max_target_length: Union[int, str] = None,\n",
    "        # A function that will split your Dataset into a training and validation set\n",
    "        # See [here](https://docs.fast.ai/data.transforms.html#Split) for a list of fast.ai splitters\n",
    "        dblock_splitter: Optional[Callable] = None,\n",
    "        # Any additional keyword arguments applied during tokenization\n",
    "        hf_tok_kwargs: dict = {},\n",
    "        # If you want to override your Blurr transform's `text_gen_kwargs`, do that here\n",
    "        text_gen_kwargs: dict = {},\n",
    "        # Any kwargs to pass to your `DataLoaders`\n",
    "        dl_kwargs: dict = {},\n",
    "        # Any kwargs to pass to your task specific `Blearner`\n",
    "        learner_kwargs: dict = {},\n",
    "    ):\n",
    "        # if we get a path/str then we're loading something like a .csv file\n",
    "        if isinstance(data, Path) or isinstance(data, str):\n",
    "            content_type = mimetypes.guess_type(data)[0]\n",
    "            if content_type == \"application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\":\n",
    "                data = pd.read_excel(data)\n",
    "            elif content_type == \"text/csv\":\n",
    "                data = pd.read_csv(data)\n",
    "            elif content_type == \"application/json\":\n",
    "                data = pd.read_json(data, orient=\"records\")\n",
    "            else:\n",
    "                raise ValueError(\"'data' must be a .xlsx, .xls, .csv, or .jsonl file\")\n",
    "\n",
    "            data = pd.read_csv(data)\n",
    "\n",
    "        # infer our datablock splitter if None\n",
    "        if dblock_splitter is None:\n",
    "            dblock_splitter = ColSplitter() if hasattr(data, \"is_valid\") else RandomSplitter()\n",
    "\n",
    "        # we need to find the architecture to ensure \"mbart\" specific tokenizer kwargs are included\n",
    "        model_cls = cls.get_model_cls()\n",
    "        model = model_cls.from_pretrained(pretrained_model_name_or_path)\n",
    "        hf_arch = BLURR.get_model_architecture(type(model).__name__)\n",
    "\n",
    "        if hf_arch == \"mbart\":\n",
    "            hf_tok_kwargs = {**{\"src_lang\": \"en_XX\", \"tgt_lang\": \"en_XX\"}, **hf_tok_kwargs}\n",
    "\n",
    "        # get our hf objects\n",
    "        hf_arch, hf_config, hf_tokenizer, hf_model = BLURR.get_hf_objects(\n",
    "            pretrained_model_name_or_path, model_cls=model_cls, tokenizer_kwargs=hf_tok_kwargs\n",
    "        )\n",
    "\n",
    "        # update text generation kwargs\n",
    "        text_gen_kwargs = {**text_gen_kwargs, **default_text_gen_kwargs(hf_config, hf_model, task=\"summarization\")}\n",
    "\n",
    "        # not all \"summarization\" parameters are for the model.generate method ... remove them here\n",
    "        generate_func_args = list(inspect.signature(hf_model.generate).parameters.keys())\n",
    "        for k in text_gen_kwargs.copy():\n",
    "            if k not in generate_func_args:\n",
    "                del text_gen_kwargs[k]\n",
    "\n",
    "        # update our text generation kwargs for mbart\n",
    "        if hf_arch == \"mbart\":\n",
    "            text_gen_kwargs = {**{\"decoder_start_token_id\": \"en_XX\"}, **text_gen_kwargs}\n",
    "\n",
    "        # define getters\n",
    "        get_x = Pipeline(funcs=[ItemGetter(text_attr)])\n",
    "        get_y = ItemGetter(summary_attr)\n",
    "\n",
    "        if hf_arch == \"t5\":\n",
    "            get_x.add(cls._add_t5_prefix)\n",
    "\n",
    "        # define our DataBlock and DataLoaders\n",
    "        batch_tokenize_tfm = Seq2SeqBatchTokenizeTransform(\n",
    "            hf_arch,\n",
    "            hf_config,\n",
    "            hf_tokenizer,\n",
    "            hf_model,\n",
    "            max_length=max_length,\n",
    "            max_target_length=max_target_length,\n",
    "            text_gen_kwargs=text_gen_kwargs,\n",
    "        )\n",
    "\n",
    "        blocks = (Seq2SeqTextBlock(batch_tokenize_tfm=batch_tokenize_tfm), noop)\n",
    "        dblock = DataBlock(blocks=blocks, get_x=get_x, get_y=get_y, splitter=dblock_splitter)\n",
    "\n",
    "        dls = dblock.dataloaders(data, **dl_kwargs.copy())\n",
    "\n",
    "        # return BLearner instance\n",
    "        learner_kwargs[\"splitter\"] = learner_kwargs.pop(\"splitter\", partial(blurr_seq2seq_splitter, arch=hf_arch))\n",
    "        learner_kwargs[\"loss_func\"] = learner_kwargs.pop(\"loss_func\", PreCalculatedCrossEntropyLoss())\n",
    "\n",
    "        return cls(dls, hf_model, **learner_kwargs.copy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = BlearnerForSummarization.from_data(\n",
    "    cnndm_df,\n",
    "    \"sshleifer/distilbart-cnn-6-6\",\n",
    "    text_attr=\"article\",\n",
    "    summary_attr=\"highlights\",\n",
    "    max_length=256,\n",
    "    max_target_length=130,\n",
    "    dblock_splitter=RandomSplitter(),\n",
    "    dl_kwargs={\"bs\": 2},\n",
    ").to_fp16()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "      <th>bertscore_precision</th>\n",
       "      <th>bertscore_recall</th>\n",
       "      <th>bertscore_f1</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.144733</td>\n",
       "      <td>2.176281</td>\n",
       "      <td>0.362477</td>\n",
       "      <td>0.142510</td>\n",
       "      <td>0.243238</td>\n",
       "      <td>0.337849</td>\n",
       "      <td>0.876255</td>\n",
       "      <td>0.887124</td>\n",
       "      <td>0.881589</td>\n",
       "      <td>01:52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, lr_max=4e-5, cbs=[BlearnerForSummarization.get_metrics_cb()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(CNN) -- Gabriel Garca Mrquez, the influential, Nobel Prize-winning author of \"One Hundred Years of Solitude\" and \"Love in the Time of Cholera,\" has died, his family and officials said. He was 87. The literary giant was treated in April for infections and dehydration at a Mexican hospital. Garca Mrquez, a native of Colombia, is widely credited with helping to popularize \"magical realism,\" a genre \"in which the fantastic and the realistic are combined in a richly composed world of imaginatio</td>\n",
       "      <td>NEW: Colombia's President declares three days of national mourning.\\nThe 87-year-old is widely credited with helping to popularize \"magical realism\"\\nGarca Mrquez stands as one of the most honored authors on Earth.\\nThe Colombian author died in Mexic</td>\n",
       "      <td>[ Gabriel Garca Mrquez, 87, has died, his family and officials say .\\nHe is credited with helping to popularize \"magical realism,\" a genre \"in which the fantastic and the realistic are combined in a richly composed world of imagination\"\\nHe was sometimes called the most significant Spanish-language author since Miguel de Cervantes .\\n,  Christopher Jordan Dorner, a 270-pound former Navy lieutenant, is a suspect in the double slayings .\\nHe has professed his venom against LAPD officers he claims ruined his life .\\nAuthorities believe he followed through on his threats by shooting a Riverside, California, police officer and two others .]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, input_trunc_at=500, target_trunc_at=250)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_article = \"\"\"\n",
    "About 10 men armed with pistols and small machine guns raided a casino in Switzerland and made off \n",
    "into France with several hundred thousand Swiss francs in the early hours of Sunday morning, police said. \n",
    "The men, dressed in black clothes and black ski masks, split into two groups during the raid on the Grand Casino \n",
    "Basel, Chief Inspector Peter Gill told CNN. One group tried to break into the casino's vault on the lower level \n",
    "but could not get in, but they did rob the cashier of the money that was not secured, he said. The second group \n",
    "of armed robbers entered the upper level where the roulette and blackjack tables are located and robbed the \n",
    "cashier there, he said. As the thieves were leaving the casino, a woman driving by and unaware of what was \n",
    "occurring unknowingly blocked the armed robbers' vehicles. A gunman pulled the woman from her vehicle, beat \n",
    "her, and took off for the French border. The other gunmen followed into France, which is only about 100 \n",
    "meters (yards) from the casino, Gill said. There were about 600 people in the casino at the time of the robbery. \n",
    "There were no serious injuries, although one guest on the Casino floor was kicked in the head by one of the \n",
    "robbers when he moved, the police officer said. Swiss authorities are working closely with French authorities, \n",
    "Gill said. The robbers spoke French and drove vehicles with French lRicense plates. CNN's Andreena Narayan \n",
    "contributed to this report.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_texts': [\" The Grand Casino Basel in Switzerland was robbed Sunday morning .\\nAbout 10 men armed with pistols and small machine guns raided a casino and made off .\\nThe men, dressed in black clothes and black ski masks, split into two groups during the raid .\\nOne group tried to break into the casino's vault on the lower level but could not get in .\\n\",\n",
       "   \" The Grand Casino Basel in Switzerland was robbed Sunday morning .\\nAbout 10 men armed with pistols and small machine guns raided a casino in Switzerland .\\nThe men, dressed in black clothes and black ski masks, split into two groups during the raid .\\nOne group tried to break into the casino's vault on the lower level but could not get in, police say .\",\n",
       "   \" The Grand Casino Basel in Switzerland was robbed Sunday morning .\\nAbout 10 men armed with pistols and small machine guns raided a casino and made off .\\nThe men, dressed in black clothes and black ski masks, split into two groups during the raid .\\nOne group tried to break into the casino's vault on the lower level but could not get in, police say\"]}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.predict(test_article, num_return_sequences=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_texts': \" The Grand Casino Basel in Switzerland was robbed Sunday morning .\\nAbout 10 men armed with pistols and small machine guns raided a casino and made off .\\nThe men, dressed in black clothes and black ski masks, split into two groups during the raid .\\nOne group tried to break into the casino's vault on the lower level but could not get in .\\n\"}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "export_fname = \"summarize_export\"\n",
    "\n",
    "learn.metrics = None\n",
    "learn = learn.to_fp32()\n",
    "learn.export(fname=f\"{export_fname}.pkl\")\n",
    "\n",
    "inf_learn = load_learner(fname=f\"{export_fname}.pkl\")\n",
    "inf_learn.blurr_summarize(test_article)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "try:\n",
    "    del learn\n",
    "    del inf_learn\n",
    "    torch.cuda.empty_cache()\n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests\n",
    "\n",
    "The purpose of the following tests is to ensure as much as possible, that the core training code works for the pretrained **summarization models** below.  These tests are excluded from the CI workflow because of how long they would take to run and the amount of data that would be required to download.\n",
    "\n",
    "**Note**: Feel free to modify the code below to test whatever pretrained summarization models you are working with ... and if any of your pretrained summarization models fail, please submit a github issue *(or a PR if you'd like to fix it yourself)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BartForConditionalGeneration',\n",
       " 'BigBirdPegasusForConditionalGeneration',\n",
       " 'BlenderbotForConditionalGeneration',\n",
       " 'BlenderbotSmallForConditionalGeneration',\n",
       " 'FSMTForConditionalGeneration',\n",
       " 'LEDForConditionalGeneration',\n",
       " 'M2M100ForConditionalGeneration',\n",
       " 'MBartForConditionalGeneration',\n",
       " 'MT5ForConditionalGeneration',\n",
       " 'PegasusForConditionalGeneration',\n",
       " 'ProphetNetForConditionalGeneration',\n",
       " 'Speech2TextForConditionalGeneration',\n",
       " 'T5ForConditionalGeneration',\n",
       " 'XLMProphetNetForConditionalGeneration']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hide\n",
    "[model_type for model_type in BLURR.get_models(task=\"ConditionalGeneration\") if (not model_type.startswith(\"TF\"))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "pretrained_model_names = [\n",
    "    \"facebook/bart-base\",\n",
    "    #'facebook/blenderbot_small-90M',\n",
    "    \"allenai/led-base-16384\",\n",
    "    \"sshleifer/tiny-mbart\",\n",
    "    \"google/mt5-small\",\n",
    "    \"sshleifer/distill-pegasus-cnn-16-4\",\n",
    "    \"t5-small\",\n",
    "    #'microsoft/prophetnet-large-uncased',\n",
    "    #'microsoft/xprophetnet-large-wiki100-cased', # XLMProphetNet\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset cnn_dailymail (/home/wgilliam/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/3cb851bf7cf5826e45d49db2863f627cba583cbc32342df7349dfe6c38060234)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>highlights</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It's official: U.S. President Barack Obama wants lawmakers to weigh in on whether to use military force in Syria. Obama sent a letter to the heads of the House and Senate on Saturday night, hours after announcing that he believes military action against Syrian targets is the right step to take over the alleged use of chemical weapons. The proposed legislation from Obama asks Congress to approve the use of military force \"to deter, disrupt, prevent and degrade the potential for future uses of chemical weapons or other weapons of mass destruction.\" It's a step that is set to turn an internat...</td>\n",
       "      <td>Syrian official: Obama climbed to the top of the tree, \"doesn't know how to get down\"\\nObama sends a letter to the heads of the House and Senate .\\nObama to seek congressional approval on military action against Syria .\\nAim is to determine whether CW were used, not by whom, says U.N. spokesman .</td>\n",
       "      <td>0001d1afc246a7964130f43ae940af6bc6c57f01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(CNN) -- Usain Bolt rounded off the world championships Sunday by claiming his third gold in Moscow as he anchored Jamaica to victory in the men's 4x100m relay. The fastest man in the world charged clear of United States rival Justin Gatlin as the Jamaican quartet of Nesta Carter, Kemar Bailey-Cole, Nickel Ashmeade and Bolt won in 37.36 seconds. The U.S finished second in 37.56 seconds with Canada taking the bronze after Britain were disqualified for a faulty handover. The 26-year-old Bolt has now collected eight gold medals at world championships, equaling the record held by American trio...</td>\n",
       "      <td>Usain Bolt wins third gold of world championship .\\nAnchors Jamaica to 4x100m relay victory .\\nEighth gold at the championships for Bolt .\\nJamaica double up in women's 4x100m relay .</td>\n",
       "      <td>0002095e55fcbd3a2f366d9bf92a95433dc305ef</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   article  \\\n",
       "0  It's official: U.S. President Barack Obama wants lawmakers to weigh in on whether to use military force in Syria. Obama sent a letter to the heads of the House and Senate on Saturday night, hours after announcing that he believes military action against Syrian targets is the right step to take over the alleged use of chemical weapons. The proposed legislation from Obama asks Congress to approve the use of military force \"to deter, disrupt, prevent and degrade the potential for future uses of chemical weapons or other weapons of mass destruction.\" It's a step that is set to turn an internat...   \n",
       "1  (CNN) -- Usain Bolt rounded off the world championships Sunday by claiming his third gold in Moscow as he anchored Jamaica to victory in the men's 4x100m relay. The fastest man in the world charged clear of United States rival Justin Gatlin as the Jamaican quartet of Nesta Carter, Kemar Bailey-Cole, Nickel Ashmeade and Bolt won in 37.36 seconds. The U.S finished second in 37.56 seconds with Canada taking the bronze after Britain were disqualified for a faulty handover. The 26-year-old Bolt has now collected eight gold medals at world championships, equaling the record held by American trio...   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                  highlights  \\\n",
       "0  Syrian official: Obama climbed to the top of the tree, \"doesn't know how to get down\"\\nObama sends a letter to the heads of the House and Senate .\\nObama to seek congressional approval on military action against Syria .\\nAim is to determine whether CW were used, not by whom, says U.N. spokesman .   \n",
       "1                                                                                                                    Usain Bolt wins third gold of world championship .\\nAnchors Jamaica to 4x100m relay victory .\\nEighth gold at the championships for Bolt .\\nJamaica double up in women's 4x100m relay .   \n",
       "\n",
       "                                         id  \n",
       "0  0001d1afc246a7964130f43ae940af6bc6c57f01  \n",
       "1  0002095e55fcbd3a2f366d9bf92a95433dc305ef  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hide\n",
    "dataset = load_dataset(\"cnn_dailymail\", \"3.0.0\", split=\"train[:1000]\")\n",
    "cnndm_df = pd.DataFrame(dataset)\n",
    "cnndm_df.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== facebook/bart-base ===\n",
      "\n",
      "architecture:\tbart\n",
      "tokenizer:\tBartTokenizerFast\n",
      "model:\t\tBartForConditionalGeneration\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(CNN) -- Gabriel Garca Mrquez, the influential, Nobel Prize-winning author of \"One Hundred Years of Solitude\" and \"Love in the Time of Cholera,\" has died, his family and officials said. He was 87. The literary giant was treated in April for infections</td>\n",
       "      <td>NEW: Colombia's President declares three days of national mourning.\\nThe 87-year-old is widely credited with helping to popularize \"magical realism\"\\nGarca M</td>\n",
       "      <td>[(CNN) -- Gabriel Garca Mrquez, the influential, Nobel Prize-winning author of \"One Hundred Years of Sol,  Los Angeles (CNN) -- A former Los Angeles cop with military training vowed war against other men in blue Thursday, leaving one officer dead]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== allenai/led-base-16384 ===\n",
      "\n",
      "architecture:\tled\n",
      "tokenizer:\tLEDTokenizerFast\n",
      "model:\t\tLEDForConditionalGeneration\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It's official: U.S. President Barack Obama wants lawmakers to weigh in on whether to use military force in Syria. Obama sent a letter to the heads of the House and Senate on Saturday night, hours after announcing that he believes military action against Syrian targets is the right step to take over the alleged use</td>\n",
       "      <td>Syrian official: Obama climbed to the top of the tree, \"doesn't know how to get down\"\\nObama sends a letter to the heads of the House and Senate.\\nObama to</td>\n",
       "      <td>[It's official: U.S. President Barack Obama wants lawmakers to weigh in on whether, Islamabad, Pakistan (CNN) -- The brazen shooting of a defiant teen blogger has stirred]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== sshleifer/tiny-mbart ===\n",
      "\n",
      "architecture:\tmbart\n",
      "tokenizer:\tMBartTokenizerFast\n",
      "model:\t\tMBartForConditionalGeneration\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Washington (CNN) -- In one ill-fated fundraiser, Mitt Romney managed to offend Palestinians, Latinos and some of the same people he's counting on for support if he wants to unseat President Barack Obama. It isn't the first time Romney</td>\n",
       "      <td>GOP presidential candidate Mitt Romney's verbal gaffes have once again stymied his campaign's ability to control the narrative. Democrats were gleeful</td>\n",
       "      <td>[, ]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== google/mt5-small ===\n",
      "\n",
      "architecture:\tmt5\n",
      "tokenizer:\tT5TokenizerFast\n",
      "model:\t\tMT5ForConditionalGeneration\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Los Angeles (CNN) -- A former Los Angeles cop with military training vowed war against other men in blue Thursday, leaving one officer dead days after he allegedly killed two other people to begin a wave of retribution for being fired, police said. The focus of</td>\n",
       "      <td>NEW: With snow coming, authorities continue to hunt for the suspect near Big Bear Lake. Police believe former cop Christopher Jordan Dorner shot three officers,</td>\n",
       "      <td>[&lt;extra_id_0&gt;. &lt;extra_id_10&gt;, &lt;extra_id_0&gt;.]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== sshleifer/distill-pegasus-cnn-16-4 ===\n",
      "\n",
      "architecture:\tpegasus\n",
      "tokenizer:\tPegasusTokenizerFast\n",
      "model:\t\tPegasusForConditionalGeneration\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Washington (CNN) -- New details emerged of what the White House knew about the Internal Revenue Service targeting of conservative groups, with spokesman Jay Carney disclosing Chief of Staff Denis McDonough was among the top officials made aware of the matter late last month. In a new timeline provided by Carney to reporters on Monday, General Counsel Kathryn</td>\n",
       "      <td>A Senate committee holds a hearing Tuesday on the IRS targeting. White House discloses new details of what it knew about the IRS targeting report. White House spokesman says President Obama wasn't told</td>\n",
       "      <td>[Chief of Staff Denis McDonough was among the top officials made aware of the IRS targeting of conservative groups . General Counsel Kathryn Kathryn says the IRS targeted conservative groups late last month ., Global climate change treaty is designed to protect tropical forests . People, companies and governments earn more by logging, mining or farming places . Global climate change treaty is designed to protect tropical forests .]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== t5-small ===\n",
      "\n",
      "architecture:\tt5\n",
      "tokenizer:\tT5TokenizerFast\n",
      "model:\t\tT5ForConditionalGeneration\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>summarize: (CNN) -- When Ji Yeqing awakened, she was already in the recovery room. Chinese authorities had dragged her out of her home and down four flights of stairs, she said, restraining and beating her husband as he tried to come to her aid</td>\n",
       "      <td>China's one-child policy results in forced abortions and sterilizations, activists say. Women tell of emotional and physical consequences from the procedures. Activist Chen Guangchen</td>\n",
       "      <td>[authorities dragged her out of her home and down four flights of stairs . she restraining and beating her husband as he, new details emerge of what the white house knew about the irs targeting of conservative groups . chief of staff denis McDonough]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide\n",
    "model_cls = AutoModelForSeq2SeqLM\n",
    "bsz = 2\n",
    "inp_seq_sz = 64\n",
    "trg_seq_sz = 40\n",
    "\n",
    "test_results = []\n",
    "for model_name in pretrained_model_names:\n",
    "    error = None\n",
    "\n",
    "    print(f\"=== {model_name} ===\\n\")\n",
    "\n",
    "    hf_tok_kwargs = {}\n",
    "    if model_name == \"sshleifer/tiny-mbart\":\n",
    "        hf_tok_kwargs[\"src_lang\"], hf_tok_kwargs[\"tgt_lang\"] = \"en_XX\", \"en_XX\"\n",
    "\n",
    "    hf_arch, hf_config, hf_tokenizer, hf_model = BLURR.get_hf_objects(model_name, model_cls=model_cls, tokenizer_kwargs=hf_tok_kwargs)\n",
    "\n",
    "    print(f\"architecture:\\t{hf_arch}\\ntokenizer:\\t{type(hf_tokenizer).__name__}\\nmodel:\\t\\t{type(hf_model).__name__}\\n\")\n",
    "\n",
    "    # 1. build your DataBlock\n",
    "    text_gen_kwargs = {}\n",
    "    if hf_arch in [\"bart\", \"t5\"]:\n",
    "        text_gen_kwargs = {**hf_config.task_specific_params[\"summarization\"], **{\"max_length\": 30, \"min_length\": 10}}\n",
    "\n",
    "    # not all \"summarization\" parameters are for the model.generate method ... remove them here\n",
    "    generate_func_args = list(inspect.signature(hf_model.generate).parameters.keys())\n",
    "    for k in text_gen_kwargs.copy():\n",
    "        if k not in generate_func_args:\n",
    "            del text_gen_kwargs[k]\n",
    "\n",
    "    if hf_arch == \"mbart\":\n",
    "        text_gen_kwargs[\"decoder_start_token_id\"] = hf_tokenizer.get_vocab()[\"en_XX\"]\n",
    "\n",
    "    def add_t5_prefix(inp):\n",
    "        return f\"summarize: {inp}\" if (hf_arch == \"t5\") else inp\n",
    "\n",
    "    batch_tokenize_tfm = Seq2SeqBatchTokenizeTransform(\n",
    "        hf_arch,\n",
    "        hf_config,\n",
    "        hf_tokenizer,\n",
    "        hf_model,\n",
    "        padding=\"max_length\",\n",
    "        max_length=inp_seq_sz,\n",
    "        max_target_length=trg_seq_sz,\n",
    "        text_gen_kwargs=text_gen_kwargs,\n",
    "    )\n",
    "\n",
    "    blocks = (Seq2SeqTextBlock(batch_tokenize_tfm=batch_tokenize_tfm), noop)\n",
    "    dblock = DataBlock(\n",
    "        blocks=blocks, get_x=Pipeline([ColReader(\"article\"), add_t5_prefix]), get_y=ColReader(\"highlights\"), splitter=RandomSplitter()\n",
    "    )\n",
    "\n",
    "    dls = dblock.dataloaders(cnndm_df, bs=bsz)\n",
    "    b = dls.one_batch()\n",
    "\n",
    "    # 2. build your Learner\n",
    "    seq2seq_metrics = {\n",
    "        \"rouge\": {\n",
    "            \"compute_kwargs\": {\"rouge_types\": [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"], \"use_stemmer\": True},\n",
    "            \"returns\": [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"],\n",
    "        }\n",
    "    }\n",
    "\n",
    "    model = BaseModelWrapper(hf_model)\n",
    "    learn_cbs = [BaseModelCallback]\n",
    "    fit_cbs = [ShortEpochCallback(0.05, short_valid=True), Seq2SeqMetricsCallback(custom_metrics=seq2seq_metrics)]\n",
    "\n",
    "    learn = Learner(\n",
    "        dls,\n",
    "        model,\n",
    "        opt_func=ranger,\n",
    "        loss_func=PreCalculatedCrossEntropyLoss(),\n",
    "        cbs=learn_cbs,\n",
    "        splitter=partial(blurr_seq2seq_splitter, arch=hf_arch),\n",
    "    ).to_fp16()\n",
    "\n",
    "    learn.create_opt()\n",
    "    learn.freeze()\n",
    "\n",
    "    # 3. Run your tests\n",
    "    try:\n",
    "        print(\"*** TESTING DataLoaders ***\\n\")\n",
    "        test_eq(len(b), 2)\n",
    "        test_eq(len(b[0][\"input_ids\"]), bsz)\n",
    "        test_eq(b[0][\"input_ids\"].shape, torch.Size([bsz, inp_seq_sz]))\n",
    "        test_eq(len(b[1]), bsz)\n",
    "\n",
    "        #         print('*** TESTING One pass through the model ***')\n",
    "        #         preds = learn.model(b[0])\n",
    "        #         test_eq(preds[1].shape[0], bsz)\n",
    "        #         test_eq(preds[1].shape[2], hf_config.vocab_size)\n",
    "\n",
    "        print(\"*** TESTING Training/Results ***\")\n",
    "        learn.fit_one_cycle(1, lr_max=1e-3, cbs=fit_cbs)\n",
    "\n",
    "        test_results.append((hf_arch, type(hf_tokenizer).__name__, type(hf_model).__name__, \"PASSED\", \"\"))\n",
    "        learn.show_results(learner=learn, max_n=2, input_trunc_at=500, target_trunc_at=250)\n",
    "    except Exception as err:\n",
    "        test_results.append((hf_arch, type(hf_tokenizer).__name__, type(hf_model).__name__, \"FAILED\", err))\n",
    "    finally:\n",
    "        # cleanup\n",
    "        del learn\n",
    "        torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arch</th>\n",
       "      <th>tokenizer</th>\n",
       "      <th>model_name</th>\n",
       "      <th>result</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bart</td>\n",
       "      <td>BartTokenizerFast</td>\n",
       "      <td>BartForConditionalGeneration</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>led</td>\n",
       "      <td>LEDTokenizerFast</td>\n",
       "      <td>LEDForConditionalGeneration</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mbart</td>\n",
       "      <td>MBartTokenizerFast</td>\n",
       "      <td>MBartForConditionalGeneration</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mt5</td>\n",
       "      <td>T5TokenizerFast</td>\n",
       "      <td>MT5ForConditionalGeneration</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pegasus</td>\n",
       "      <td>PegasusTokenizerFast</td>\n",
       "      <td>PegasusForConditionalGeneration</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>t5</td>\n",
       "      <td>T5TokenizerFast</td>\n",
       "      <td>T5ForConditionalGeneration</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide_input\n",
    "test_results_df = pd.DataFrame(test_results, columns=[\"arch\", \"tokenizer\", \"model_name\", \"result\", \"error\"])\n",
    "display_df(test_results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This module includes the fundamental bits to use Blurr for summarization tasks training and inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_utils.ipynb.\n",
      "Converted 01_data-core.ipynb.\n",
      "Converted 01_modeling-core.ipynb.\n",
      "Converted 02_data-language-modeling.ipynb.\n",
      "Converted 02_modeling-language-modeling.ipynb.\n",
      "Converted 03_data-token-classification.ipynb.\n",
      "Converted 03_modeling-token-classification.ipynb.\n",
      "Converted 04_data-question-answering.ipynb.\n",
      "Converted 04_modeling-question-answering.ipynb.\n",
      "Converted 10_data-seq2seq-core.ipynb.\n",
      "Converted 10_modeling-seq2seq-core.ipynb.\n",
      "Converted 11_data-seq2seq-summarization.ipynb.\n",
      "Converted 11_modeling-seq2seq-summarization.ipynb.\n",
      "Converted 12_data-seq2seq-translation.ipynb.\n",
      "Converted 12_modeling-seq2seq-translation.ipynb.\n",
      "Converted 99a_examples-high-level-api.ipynb.\n",
      "Converted 99b_examples-glue.ipynb.\n",
      "Converted 99c_examples-glue-plain-pytorch.ipynb.\n",
      "Converted 99d_examples-multilabel.ipynb.\n",
      "Converted 99e_examples-causal-lm-gpt2.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import notebook2script\n",
    "\n",
    "notebook2script()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
