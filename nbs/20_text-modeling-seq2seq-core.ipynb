{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp text.modeling.seq2seq.core\n",
    "#|default_cls_lvl 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| nbflags skip_exec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# text.modeling.seq2seq.core\n",
    "\n",
    "> This module contains core custom models, loss functions, etc... for Seq2Seq based tasks (e.g., language modeling, summarization, translation, etc...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "import torch\n",
    "\n",
    "from datasets import load_metric as hf_load_metric\n",
    "from fastai.callback.all import *\n",
    "from fastai.data.block import DataBlock, ColReader, RandomSplitter\n",
    "from fastai.imports import *\n",
    "from fastai.learner import *\n",
    "from fastai.losses import CrossEntropyLossFlat\n",
    "from fastai.torch_core import *\n",
    "from fastai.torch_imports import *\n",
    "from fastcore.all import *\n",
    "from transformers import PreTrainedModel, logging\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "nltk.download(\"wordnet\", quiet=True)  # download punctuation rules\n",
    "\n",
    "from blurr.text.data.core import first_blurr_tfm\n",
    "from blurr.text.data.seq2seq.core import Seq2SeqBatchTokenizeTransform, Seq2SeqTextBlock, Seq2SeqTextInput\n",
    "from blurr.text.modeling.core import BaseModelWrapper, BaseModelCallback\n",
    "from blurr.text.utils import get_hf_objects\n",
    "from blurr.utils import PreCalculatedCrossEntropyLoss\n",
    "\n",
    "logging.set_verbosity_error()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What we're running with at the time this documentation was generated:\n",
      "torch: 1.10.1+cu111\n",
      "fastai: 2.5.6\n",
      "transformers: 4.16.2\n"
     ]
    }
   ],
   "source": [
    "#| echo: false\n",
    "import pdb\n",
    "\n",
    "from datasets import load_dataset\n",
    "from fastai.optimizer import Adam, OptimWrapper, params\n",
    "from fastcore.test import *\n",
    "from nbdev.showdoc import show_doc\n",
    "from transformers import BartForConditionalGeneration\n",
    "\n",
    "from blurr.utils import print_versions\n",
    "from blurr.text.utils import BlurrText\n",
    "\n",
    "NLP = BlurrText()\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "print(\"What we're running with at the time this documentation was generated:\")\n",
    "print_versions(\"torch fastai transformers\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU #1: GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "#|hide\n",
    "#|cuda\n",
    "torch.cuda.set_device(1)\n",
    "print(f\"Using GPU #{torch.cuda.current_device()}: {torch.cuda.get_device_name()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mid-level API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `blurr_seq2seq_splitter` -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "def blurr_seq2seq_splitter(\n",
    "    # A Hugging Face model\n",
    "    m: PreTrainedModel,\n",
    "    # The name of the architecture you are working with (e.g., bart, fsmt, pegasus, etc...)\n",
    "    arch: str,\n",
    "):\n",
    "    \"\"\"Custom param splitter for summarization models\"\"\"\n",
    "    model = m.hf_model if (hasattr(m, \"hf_model\")) else m\n",
    "\n",
    "    if arch in [\"bart\", \"blenderbot\", \"blenderbot_small\", \"fsmt\", \"marian\", \"mbart\", \"pegasus\"]:\n",
    "        embeds_modules = [\n",
    "            model.model.encoder.embed_positions,\n",
    "            model.model.encoder.embed_tokens,\n",
    "            model.model.decoder.embed_positions,\n",
    "            model.model.decoder.embed_tokens,\n",
    "        ]\n",
    "        if arch != \"fsmt\":\n",
    "            embeds_modules.insert(0, model.model.shared)\n",
    "\n",
    "        embeds = nn.Sequential(*embeds_modules)\n",
    "        groups = L(embeds, model.model.encoder, model.model.decoder)\n",
    "        return groups.map(params).filter(lambda el: len(el) > 0)\n",
    "\n",
    "    if arch in [\"led\"]:\n",
    "        embeds_modules = [\n",
    "            model.led.encoder.embed_positions,\n",
    "            model.led.encoder.embed_tokens,\n",
    "            model.led.decoder.embed_positions,\n",
    "            model.led.decoder.embed_tokens,\n",
    "        ]\n",
    "\n",
    "        embeds = nn.Sequential(*embeds_modules)\n",
    "        groups = L(embeds, model.led.encoder, model.led.decoder)\n",
    "        return groups.map(params).filter(lambda el: len(el) > 0)\n",
    "\n",
    "    if arch in [\"mt5\", \"t5\"]:\n",
    "        embeds = nn.Sequential(model.shared, model.encoder.embed_tokens, model.decoder.embed_tokens)\n",
    "\n",
    "        groups = L(embeds, model.encoder, model.decoder)\n",
    "        return groups.map(params).filter(lambda el: len(el) > 0)\n",
    "\n",
    "    if arch in [\"prophetnet\", \"xlm_prophetnet\"]:\n",
    "        embeds = nn.Sequential(\n",
    "            model.prophetnet.word_embeddings,\n",
    "            model.prophetnet.encoder.word_embeddings,\n",
    "            model.prophetnet.encoder.position_embeddings,\n",
    "            model.prophetnet.decoder.word_embeddings,\n",
    "            model.prophetnet.decoder.position_embeddings,\n",
    "            model.prophetnet.decoder.ngram_embeddings,\n",
    "        )\n",
    "\n",
    "        groups = L(embeds, model.prophetnet.encoder.layers, model.prophetnet.decoder.layers, model.lm_head)\n",
    "        return groups.map(params).filter(lambda el: len(el) > 0)\n",
    "\n",
    "    raise ValueError(f\"seq2seq_splitter does not support this architecutre: {arch}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add a custom param splitter to give us a bit more depth in applying discriminative learning rates for Seq2Seq tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"blurr_seq2seq_splitter\" class=\"doc_header\"><code>blurr_seq2seq_splitter</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>blurr_seq2seq_splitter</code>(**`m`**:`PreTrainedModel`, **`arch`**:`str`)\n",
       "\n",
       "Custom param splitter for summarization models\n",
       "\n",
       "||Type|Default|Details|\n",
       "|---|---|---|---|\n",
       "|**`m`**|`PreTrainedModel`||A Hugging Face model|\n",
       "|**`arch`**|`str`||The name of the architecture you are working with (e.g., bart, fsmt, pegasus, etc...)|\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(blurr_seq2seq_splitter, title_level=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Seq2SeqMetricsCallback` -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class Seq2SeqMetricsCallback(Callback):\n",
    "    \"\"\"A callback that adds seq2seq metrics\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        # A dictionary of seq2seq metrics we want to use. See below and the various task specific seq2seq docs\n",
    "        # for examples of how to configure this per task\n",
    "        custom_metrics: dict = None,\n",
    "        # Calculation of these metrics requires text generation, which is expensive.  You can choose to calculate\n",
    "        # these metrics on every 'epoch', 'other_epoch', or 'last_epoch' instead (default: 'epoch')\n",
    "        calc_every: str = \"epoch\",\n",
    "        # The token ID that should be ignored when calculating the loss\n",
    "        ignore_token_id=CrossEntropyLossFlat().ignore_index,\n",
    "        # Any keyword arguments to pass to the `hf_model.generate` method\n",
    "        text_gen_kwargs: dict = {},\n",
    "        # Keyword arguments to apply to `HF_Seq2SeqMetricsCallback`\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        self.order = Recorder.order - 1\n",
    "\n",
    "        store_attr(self=self, names=\"custom_metrics, calc_every, ignore_token_id, text_gen_kwargs, kwargs\")\n",
    "        self.custom_metric_funcs, self.custom_metric_vals, self.do_calc = {}, {}, True\n",
    "\n",
    "        if custom_metrics is not None:\n",
    "            for metric_name, metric_info_dict in custom_metrics.items():\n",
    "                # self.custom_metric_funcs (tuple): the function to compute the metric and what should be returned,\n",
    "                # if the \"compute_func\" is not defined, we assume it is a Hugging Face metric\n",
    "                if \"compute_func\" in metric_info_dict:\n",
    "                    compute_func = metric_info_dict[\"compute_func\"]\n",
    "                else:\n",
    "                    compute_func = hf_load_metric(metric_name).compute\n",
    "\n",
    "                compute_kwargs = metric_info_dict[\"compute_kwargs\"] if (\"compute_kwargs\" in metric_info_dict) else {}\n",
    "                metric_returns = metric_info_dict[\"returns\"]\n",
    "\n",
    "                self.custom_metric_funcs[metric_name] = (partial(compute_func, **compute_kwargs), metric_returns)\n",
    "\n",
    "                # self.custom_metric_vals (list): all the custom metrics to report as a \"ValueMetric\"\n",
    "                if metric_name == \"rouge\":\n",
    "                    self.custom_metric_vals.update({rouge_type: None for rouge_type in metric_returns})\n",
    "                elif is_listy(metric_returns):\n",
    "                    self.custom_metric_vals.update({f\"{metric_name}_{ret_val}\": None for ret_val in metric_returns})\n",
    "                else:\n",
    "                    self.custom_metric_vals.update({metric_name: None})\n",
    "\n",
    "        self.do_setup = True\n",
    "\n",
    "    def setup(self):\n",
    "        # one time setup code here.\n",
    "        if not self.do_setup:\n",
    "            return\n",
    "\n",
    "        # grab the hf_tokenizer from the BatchTokenizeTransform (used for rouge metrics)\n",
    "        tfm = first_blurr_tfm(self.learn.dls)\n",
    "        self.hf_tokenizer = tfm.hf_tokenizer\n",
    "        self.tok_kwargs = tfm.tok_kwargs\n",
    "\n",
    "        # use before batch tfm's text_gen_kwargs if user doesn't pass in their own kwargs\n",
    "        if len(self.text_gen_kwargs) == 0:\n",
    "            self.text_gen_kwargs = tfm.text_gen_kwargs\n",
    "\n",
    "        # add seq2seq generation specific metrics (rouge, bertscore, bleu, etc...) to learner metrics\n",
    "        metric_keys = list(self.custom_metric_vals.keys())\n",
    "        custom_metrics = L([ValueMetric(partial(self.metric_value, metric_key=k), k) for k in metric_keys])\n",
    "        self.learn.metrics = self.learn.metrics + custom_metrics\n",
    "\n",
    "        self.do_setup = False\n",
    "\n",
    "    def before_fit(self):\n",
    "        self.setup()\n",
    "\n",
    "    # --- epoch begin/after phases ---\n",
    "    def before_epoch(self):\n",
    "        current_epoch_n = self.epoch + 1\n",
    "        if current_epoch_n == self.n_epoch:  # we always calc on last epoch\n",
    "            self.do_calc = True\n",
    "        elif self.calc_every == \"epoch\":\n",
    "            self.do_calc = True\n",
    "        elif self.calc_every == \"other_epoch\" and current_epoch_n % 2 == 0:\n",
    "            self.do_calc = True\n",
    "        else:\n",
    "            self.do_calc = False\n",
    "\n",
    "    # --- batch begin/after phases ---\n",
    "    def after_batch(self):\n",
    "        if self.training or self.learn.y is None or self.custom_metrics is None or not self.do_calc:\n",
    "            return\n",
    "\n",
    "        # grab predicted and reference ids for any metrics that need them\n",
    "        input_ids, attention_mask = self.xb[0][\"input_ids\"], self.xb[0][\"attention_mask\"]\n",
    "        gen_ids = self.learn.model.hf_model.generate(input_ids=input_ids, attention_mask=attention_mask, **self.text_gen_kwargs)\n",
    "\n",
    "        self.generated_ids += gen_ids.tolist()\n",
    "        self.refernce_ids += [seq[seq != self.ignore_token_id].tolist() for seq in self.yb[0]]\n",
    "\n",
    "    # --- validation begin/after phases ---\n",
    "    def before_validate(self):\n",
    "        self.generated_ids, self.refernce_ids = [], []\n",
    "\n",
    "    def after_validate(self):\n",
    "        if self.learn.y is None or self.custom_metrics is None or not self.do_calc:\n",
    "            return\n",
    "\n",
    "        # fetch the generated prediction and reference tokens and texts\n",
    "        gen_toks = [self.hf_tokenizer.convert_ids_to_tokens(ids, skip_special_tokens=True) for ids in self.generated_ids]\n",
    "        ref_toks = [self.hf_tokenizer.convert_ids_to_tokens(ids, skip_special_tokens=True) for ids in self.refernce_ids]\n",
    "\n",
    "        gen_texts = self.hf_tokenizer.batch_decode(self.generated_ids, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "        ref_texts = self.hf_tokenizer.batch_decode(self.refernce_ids, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "\n",
    "        # calculate any seq2seq metrics\n",
    "        for metric_name, metric_info in self.custom_metric_funcs.items():\n",
    "            compute_func, return_val = metric_info\n",
    "\n",
    "            # some metrics work on tokens (bleu), some allow for multiple references (blue, sacrebleu), and most\n",
    "            # work directly on the generated and reference texts; here blurr does the dirty work of getting your\n",
    "            # preds/references formatted for the metric you are using\n",
    "            if metric_name == \"bleu\":\n",
    "                predictions, references = gen_toks, [[toks] for toks in ref_toks]\n",
    "            elif metric_name == \"sacrebleu\":\n",
    "                predictions, references = gen_texts, [[txt] for txt in ref_texts]\n",
    "            elif metric_name == \"rouge\":\n",
    "                predictions = [\"\\n\".join(sent_tokenize(pred.strip())) for pred in gen_texts]\n",
    "                references = [\"\\n\".join(sent_tokenize(ref_text.strip())) for ref_text in ref_texts]\n",
    "            else:\n",
    "                predictions, references = gen_texts, ref_texts\n",
    "\n",
    "            # calls the metrics \"compute\" function\n",
    "            res = compute_func(predictions=predictions, references=references)\n",
    "\n",
    "            # updates the custom_metric_vals with the metric's value\n",
    "            if metric_name == \"rouge\":\n",
    "                for rouge_key, scores in res.items():\n",
    "                    self.custom_metric_vals[rouge_key] = scores.mid.fmeasure\n",
    "            if metric_name == \"bertscore\":\n",
    "                for score_key, score in res.items():\n",
    "                    if f\"{metric_name}_{score_key}\" not in self.custom_metric_vals:\n",
    "                        continue\n",
    "                    self.custom_metric_vals[f\"{metric_name}_{score_key}\"] = np.array(score).mean().item()\n",
    "            elif is_listy(return_val):\n",
    "                for score_key, score in res.items():\n",
    "                    if f\"{metric_name}_{score_key}\" not in self.custom_metric_vals:\n",
    "                        continue\n",
    "                    self.custom_metric_vals[f\"{metric_name}_{score_key}\"] = score\n",
    "            else:\n",
    "                self.custom_metric_vals[metric_name] = res[return_val]\n",
    "\n",
    "    # --- for ValueMetric metrics ---\n",
    "    def metric_value(self, metric_key):\n",
    "        return self.custom_metric_vals[metric_key]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`BLURR` provides a special callback for seq2seq models for calculating a variety of useful metrics that require decoding both given and predicted input_ids to be calculated.  The are:\n",
    "\n",
    "- rouge (e.g., \"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\")\n",
    "- bert_score (e.g., \"precision\", \"recall\", \"f1\")\n",
    "- bleu\n",
    "- bleurt\n",
    "- meteor\n",
    "- sacrebleu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset cnn_dailymail (/home/wgilliam/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/3cb851bf7cf5826e45d49db2863f627cba583cbc32342df7349dfe6c38060234)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>highlights</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It's official: U.S. President Barack Obama wants lawmakers to weigh in on whether to use military force in Syria. Obama sent a letter to the heads of the House and Senate on Saturday night, hours after announcing that he believes military action against Syrian targets is the right step to take over the alleged use of chemical weapons. The proposed legislation from Obama asks Congress to approve the use of military force \"to deter, disrupt, prevent and degrade the potential for future uses of chemical weapons or other weapons of mass destruction.\" It's a step that is set to turn an internat...</td>\n",
       "      <td>Syrian official: Obama climbed to the top of the tree, \"doesn't know how to get down\"\\nObama sends a letter to the heads of the House and Senate .\\nObama to seek congressional approval on military action against Syria .\\nAim is to determine whether CW were used, not by whom, says U.N. spokesman .</td>\n",
       "      <td>0001d1afc246a7964130f43ae940af6bc6c57f01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(CNN) -- Usain Bolt rounded off the world championships Sunday by claiming his third gold in Moscow as he anchored Jamaica to victory in the men's 4x100m relay. The fastest man in the world charged clear of United States rival Justin Gatlin as the Jamaican quartet of Nesta Carter, Kemar Bailey-Cole, Nickel Ashmeade and Bolt won in 37.36 seconds. The U.S finished second in 37.56 seconds with Canada taking the bronze after Britain were disqualified for a faulty handover. The 26-year-old Bolt has now collected eight gold medals at world championships, equaling the record held by American trio...</td>\n",
       "      <td>Usain Bolt wins third gold of world championship .\\nAnchors Jamaica to 4x100m relay victory .\\nEighth gold at the championships for Bolt .\\nJamaica double up in women's 4x100m relay .</td>\n",
       "      <td>0002095e55fcbd3a2f366d9bf92a95433dc305ef</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   article  \\\n",
       "0  It's official: U.S. President Barack Obama wants lawmakers to weigh in on whether to use military force in Syria. Obama sent a letter to the heads of the House and Senate on Saturday night, hours after announcing that he believes military action against Syrian targets is the right step to take over the alleged use of chemical weapons. The proposed legislation from Obama asks Congress to approve the use of military force \"to deter, disrupt, prevent and degrade the potential for future uses of chemical weapons or other weapons of mass destruction.\" It's a step that is set to turn an internat...   \n",
       "1  (CNN) -- Usain Bolt rounded off the world championships Sunday by claiming his third gold in Moscow as he anchored Jamaica to victory in the men's 4x100m relay. The fastest man in the world charged clear of United States rival Justin Gatlin as the Jamaican quartet of Nesta Carter, Kemar Bailey-Cole, Nickel Ashmeade and Bolt won in 37.36 seconds. The U.S finished second in 37.56 seconds with Canada taking the bronze after Britain were disqualified for a faulty handover. The 26-year-old Bolt has now collected eight gold medals at world championships, equaling the record held by American trio...   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                  highlights  \\\n",
       "0  Syrian official: Obama climbed to the top of the tree, \"doesn't know how to get down\"\\nObama sends a letter to the heads of the House and Senate .\\nObama to seek congressional approval on military action against Syria .\\nAim is to determine whether CW were used, not by whom, says U.N. spokesman .   \n",
       "1                                                                                                                    Usain Bolt wins third gold of world championship .\\nAnchors Jamaica to 4x100m relay victory .\\nEighth gold at the championships for Bolt .\\nJamaica double up in women's 4x100m relay .   \n",
       "\n",
       "                                         id  \n",
       "0  0001d1afc246a7964130f43ae940af6bc6c57f01  \n",
       "1  0002095e55fcbd3a2f366d9bf92a95433dc305ef  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"cnn_dailymail\", \"3.0.0\", split=\"train[:1000]\")\n",
    "cnndm_df = pd.DataFrame(dataset)\n",
    "cnndm_df.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('bart',\n",
       " transformers.models.bart.configuration_bart.BartConfig,\n",
       " transformers.models.bart.tokenization_bart_fast.BartTokenizerFast,\n",
       " transformers.models.bart.modeling_bart.BartForConditionalGeneration)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_model_name = \"facebook/bart-large-cnn\"\n",
    "hf_arch, hf_config, hf_tokenizer, hf_model = get_hf_objects(pretrained_model_name, model_cls=BartForConditionalGeneration)\n",
    "hf_arch, type(hf_config), type(hf_tokenizer), type(hf_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_tokenize_tfm = Seq2SeqBatchTokenizeTransform(hf_arch, hf_config, hf_tokenizer, hf_model, max_length=256, max_target_length=130)\n",
    "blocks = (Seq2SeqTextBlock(batch_tokenize_tfm=batch_tokenize_tfm), noop)\n",
    "\n",
    "dblock = DataBlock(blocks=blocks, get_x=ColReader(\"article\"), get_y=ColReader(\"highlights\"), splitter=RandomSplitter())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = dblock.dataloaders(cnndm_df, bs=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = dls.one_batch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, torch.Size([2, 256]), torch.Size([2, 54]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b), b[0][\"input_ids\"].shape, b[1].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;s&gt; (CNN) -- When Ji Yeqing awakened, she was already in the recovery room. Chinese authorities had dragged her out of her home and down four flights of stairs, she said, restraining and beating her husband as he tried to come to her aid. They whisked her into a clinic, held her down on a bed and forced her to undergo an abortion. Her offense? Becoming pregnant with a second child, in violation of China's one-child policy. \"After the abortion, I felt empty, as if something was scooped out of me,\" Ji told a congressional panel in September. \"My husband and I had been so excited for our new baby. Now suddenly all that hope and joy and excitement disappeared.... I was very depressed and despondent. For a long time, whenever I thought about my lost child, I would cry.\" As she lay unconscious, she said, an IUD to prevent future pregnancies was inserted. The issue of forced abortions -- and in some cases, forced sterilizations -- in China has seized the spotlight in recent days with news of escaped activist Chen Guangcheng. Chen, a blind, self-taught lawyer, rose to fame in the late 1990s because of his advocacy for what he calls victims&lt;/s&gt;</td>\n",
       "      <td>China's one-child policy results in forced abortions and sterilizations, activists say.\\nWomen tell of emotional and physical consequences from the procedures.\\nActivist Chen Guangcheng works to advocate for victims of such practices.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;s&gt; Few question that there was a major chemical attack in Syria last week, and the United States has made clear that it blames the government of President Bashar al-Assad. Now, the question is how President Barack Obama will respond. For almost two years, Obama has avoided direct military involvement in Syria's civil war, only escalating aid to rebel fighters in June after suspected smaller-scale chemical weapons attacks by Syrian government forces. However, last week's attack on a Damascus suburb that reportedly killed and wounded more than 3,000 people obliterated the \"red line\" Obama set just over a year ago against the use of Syria's chemical weapons stocks. At the White House, spokesman Jay Carney told reporters Monday that Obama was evaluating \"a response to the clear use on a mass scale with repugnant results of chemical weapons,\" adding that \"there is very little doubt that the Syrian regime... used those weapons.\" Meanwhile, U.S. Secretary of State John Kerry called the attack \"inexcusable\" and \"undeniable,\" and said there was \"a clear reason that the world has banned entirely chemical weapons.\" He said that evidence \"strongly indicates\" chemical weapons were used in Syria and that \"we know the Syrian regime maintains custody\" of such weapons and has&lt;/s&gt;</td>\n",
       "      <td>U.S. evidence includes satellite imagery, official says.\\nObama is considering how to respond to Syrian chemical attack.\\nOfficial: Obama could be presented with options within days.\\nA U.S. strike \"can't just be one and done,\" a Middle East analyst says.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch(dataloaders=dls, max_n=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/wgilliam/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/wgilliam/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/wgilliam/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "seq2seq_metrics = {\n",
    "    \"rouge\": {\n",
    "        \"compute_kwargs\": {\"rouge_types\": [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"], \"use_stemmer\": True},\n",
    "        \"returns\": [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"],\n",
    "    },\n",
    "    \"bertscore\": {\"compute_kwargs\": {\"lang\": \"en\"}, \"returns\": [\"precision\", \"recall\", \"f1\"]},\n",
    "    \"bleu\": {\"returns\": \"bleu\"},\n",
    "    \"meteor\": {\"returns\": \"meteor\"},\n",
    "    \"sacrebleu\": {\"returns\": \"score\"},\n",
    "}\n",
    "\n",
    "model = BaseModelWrapper(hf_model)\n",
    "learn_cbs = [BaseModelCallback]\n",
    "fit_cbs = [Seq2SeqMetricsCallback(custom_metrics=seq2seq_metrics, calc_every=\"other_epoch\")]\n",
    "\n",
    "learn = Learner(\n",
    "    dls,\n",
    "    model,\n",
    "    opt_func=partial(Adam),\n",
    "    loss_func=PreCalculatedCrossEntropyLoss(),  # CrossEntropyLossFlat()\n",
    "    cbs=learn_cbs,\n",
    "    splitter=partial(blurr_seq2seq_splitter, arch=hf_arch),\n",
    ")\n",
    "\n",
    "# learn = learn.to_native_fp16() #.to_fp16()\n",
    "learn.unfreeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, torch.Size([]), torch.Size([2, 58, 50264]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = dls.one_batch()\n",
    "preds = learn.model(b[0])\n",
    "\n",
    "len(preds), preds[\"loss\"].shape, preds[\"logits\"].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, torch.Size([]), torch.Size([2, 69, 50264]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = dls.one_batch()\n",
    "preds = learn.model(b[0])\n",
    "\n",
    "len(preds), preds[\"loss\"].shape, preds[\"logits\"].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(len(learn.opt.param_groups))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(minimum=2.7542287716642023e-05, steep=1.0964781722577754e-06, valley=1.737800812406931e-05, slide=9.999999747378752e-06)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#|slow\n",
    "learn.lr_find(suggest_funcs=[minimum, steep, valley, slide])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "      <th>bertscore_precision</th>\n",
       "      <th>bertscore_recall</th>\n",
       "      <th>bertscore_f1</th>\n",
       "      <th>bleu</th>\n",
       "      <th>meteor</th>\n",
       "      <th>sacrebleu</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.926532</td>\n",
       "      <td>1.814343</td>\n",
       "      <td>0.376596</td>\n",
       "      <td>0.157966</td>\n",
       "      <td>0.260184</td>\n",
       "      <td>0.351594</td>\n",
       "      <td>0.877255</td>\n",
       "      <td>0.890926</td>\n",
       "      <td>0.883944</td>\n",
       "      <td>0.148116</td>\n",
       "      <td>0.350684</td>\n",
       "      <td>11.629698</td>\n",
       "      <td>03:56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#|slow\n",
    "learn.fit_one_cycle(1, lr_max=slice(9e-7, 9e-5), cbs=fit_cbs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction\n",
    "\n",
    "Below we'll add in additional functionality to take advantage of Hugging Face's `PreTrainedModel.generate` model, which can be used to easily implement beam search, top-k/nucleous sampling, etc... so that we get more human sounding results.\n",
    "\n",
    "To make things even easier, for text generation tasks you can simply call the `Learn.blurr_generate` method, optionally passing in whatever text generation kwargs you wish, to accomplish the same as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_article = \"\"\"\n",
    "About 10 men armed with pistols and small machine guns raided a casino in Switzerland and made off \n",
    "into France with several hundred thousand Swiss francs in the early hours of Sunday morning, police said. \n",
    "The men, dressed in black clothes and black ski masks, split into two groups during the raid on the Grand Casino \n",
    "Basel, Chief Inspector Peter Gill told CNN. One group tried to break into the casino's vault on the lower level \n",
    "but could not get in, but they did rob the cashier of the money that was not secured, he said. The second group \n",
    "of armed robbers entered the upper level where the roulette and blackjack tables are located and robbed the \n",
    "cashier there, he said. As the thieves were leaving the casino, a woman driving by and unaware of what was \n",
    "occurring unknowingly blocked the armed robbers' vehicles. A gunman pulled the woman from her vehicle, beat \n",
    "her, and took off for the French border. The other gunmen followed into France, which is only about 100 \n",
    "meters (yards) from the casino, Gill said. There were about 600 people in the casino at the time of the robbery. \n",
    "There were no serious injuries, although one guest on the Casino floor was kicked in the head by one of the \n",
    "robbers when he moved, the police officer said. Swiss authorities are working closely with French authorities, \n",
    "Gill said. The robbers spoke French and drove vehicles with French lRicense plates. CNN's Andreena Narayan \n",
    "contributed to this report.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Target ===\n",
      " A winter storm slams the northeastern United States.\n",
      "The U.S. House of Representatives condemns the Arizona shooting.\n",
      "Massive floods leave vast areas of Australia underwater.\n",
      "Use the Daily Discussion to help students understand today's featured news stories.\n",
      "\n",
      "=== Prediction ===\n",
      " This is a RUSH transcript of today's CNN Student News show.\n",
      "Use the Transcript to help students with reading comprehension and vocabulary.\n",
      "The Story of a problem that won't be solved, even if the solution is clear.\n",
      "A look at the storm system that iced out the southeast.\n",
      "Learn about the problem that will never be solved in Australia.\n",
      "Explore the story and the reasons why a problem won't solve itself.\n"
     ]
    }
   ],
   "source": [
    "b = dls.valid.one_batch()\n",
    "\n",
    "tfm = first_blurr_tfm(dls)\n",
    "\n",
    "b_hf_tokenizer = tfm.hf_tokenizer\n",
    "b_ignore_token_id = tfm.ignore_token_id\n",
    "\n",
    "test_input_ids = b[0][\"input_ids\"][0].unsqueeze(0).to(learn.model.hf_model.device)\n",
    "test_trg_ids = b[1][0].unsqueeze(0).to(learn.model.hf_model.device)\n",
    "test_trg_ids = [trg[trg != b_ignore_token_id] for trg in test_trg_ids]\n",
    "\n",
    "gen_text = learn.model.hf_model.generate(test_input_ids, num_beams=4, max_length=130, min_length=30)\n",
    "\n",
    "print(\"=== Target ===\")\n",
    "print(f\"{b_hf_tokenizer.decode(test_trg_ids[0], skip_special_tokens=True, clean_up_tokenization_spaces=True)}\\n\")\n",
    "\n",
    "print(\"=== Prediction ===\")\n",
    "print(b_hf_tokenizer.decode(gen_text[0], skip_special_tokens=True, clean_up_tokenization_spaces=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_texts': [\" The robbers made off with several hundred thousand Swiss francs in the early hours of Sunday morning .\\nThe men, dressed in black clothes and black ski masks, split into two groups during the raid on the Grand Casino Basel .\\nAs the thieves were leaving the casino, a woman driving by unknowingly blocked the armed robbers' vehicles .\\nA gunman pulled the woman from her vehicle, beat her up, and took off for the French border .\\nThere were about 600 people in the casino at the time of the robbery .\",\n",
       "   \" The robbers made off with several hundred thousand Swiss francs in the early hours of Sunday morning .\\nThe men, dressed in black clothes and black ski masks, split into two groups during the raid on the Grand Casino Basel .\\nAs the thieves were leaving the casino, a woman driving by unknowingly blocked the armed robbers' vehicles .\\nA gunman pulled the woman from her vehicle, beat her up, and took off for the French border .\\nThere were about 600 people in the casino at the time of the raid .\",\n",
       "   \" The robbers made off with several hundred thousand Swiss francs in the early hours of Sunday morning .\\nThe men, dressed in black clothes and black ski masks, split into two groups during the raid on the Grand Casino Basel .\\nAs the thieves were leaving the casino, a woman driving by unknowingly blocked the armed robbers' vehicles .\\nA gunman pulled the woman from her vehicle, beat her up, and took off for the French border .\\nFrench authorities are working closely with Swiss authorities .\"]}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = learn.blurr_generate(test_article, num_return_sequences=3)\n",
    "outputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Showing results\n",
    "\n",
    "Much nicer!!! Now, we can update our @typedispatched `show_results` to use this new method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "@typedispatch\n",
    "def show_results(\n",
    "    # This typedispatched `show_results` will be called for `Seq2SeqTextInput` typed inputs\n",
    "    x: Seq2SeqTextInput,\n",
    "    # Your targets\n",
    "    y,\n",
    "    # Your raw inputs/targets\n",
    "    samples,\n",
    "    # The model's predictions\n",
    "    outs,\n",
    "    # Your `Learner`. This is required so as to get at the Hugging Face objects for decoding them into\n",
    "    # something understandable\n",
    "    learner,\n",
    "    # Your `show_results` context\n",
    "    ctxs=None,\n",
    "    # The maximum number of items to show\n",
    "    max_n=6,\n",
    "    # Any truncation your want applied to your decoded inputs\n",
    "    input_trunc_at=None,\n",
    "    # Any truncation your want applied to your decoded targets\n",
    "    target_trunc_at=None,\n",
    "    # If you want to override your Blurr transform's `text_gen_kwargs`, do that here\n",
    "    text_gen_kwargs={},\n",
    "    # Any other keyword arguments you want applied to `show_results`\n",
    "    **kwargs\n",
    "):\n",
    "    tfm = first_blurr_tfm(learner.dls)\n",
    "    hf_config = tfm.hf_config\n",
    "    hf_tokenizer = tfm.hf_tokenizer\n",
    "    ignore_token_id = tfm.ignore_token_id\n",
    "\n",
    "    if len(text_gen_kwargs) == 0:\n",
    "        text_gen_kwargs = tfm.text_gen_kwargs\n",
    "\n",
    "    gen_text_txts = learner.blurr_generate(x, **text_gen_kwargs)\n",
    "    res = L(\n",
    "        [\n",
    "            (\n",
    "                hf_tokenizer.decode(s[0], skip_special_tokens=True)[:input_trunc_at],\n",
    "                hf_tokenizer.decode(s[1][s[1] != ignore_token_id], skip_special_tokens=True)[:target_trunc_at],\n",
    "                gen_txt[\"generated_texts\"][:target_trunc_at],\n",
    "            )\n",
    "            for s, gen_txt in zip(samples, gen_text_txts)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    display_df(pd.DataFrame(res, columns=[\"text\", \"target\", \"prediction\"])[:max_n])\n",
    "    return ctxs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(CNN Student News) -- January 13, 2011. Download PDF maps related to today's show:.  Arizona  Australia. Transcript. THIS IS A RUSH TRANSCRIPT. THIS COPY MAY NOT BE IN ITS FINAL FORM AND MAY BE UPDATED. CARL AZUZ, CNN STUDENT NEWS ANCHOR: A problem that won't be solved, even if the solution is clear. The story and the reasons, leading off today's broadcast of CNN Student News! My name is Carl Azuz! First Up: Winter Storm Woes. AZUZ: Florida is the only state in the union without snow on the g</td>\n",
       "      <td>A winter storm slams the northeastern United States.\\nThe U.S. House of Representatives condemns the Arizona shooting.\\nMassive floods leave vast areas of Australia underwater.\\nUse the Daily Discussion to help students understand today's featured news</td>\n",
       "      <td>[ This is a RUSH transcript of today's CNN Student News show .\\nUse the Transcript to help students with reading comprehension and vocabulary .\\nThe Story of a problem that won't be solved, even if the solution is clear .\\nA look at the storm system that iced out the southeast .\\nLearn about the problem that will never be solved in Australia .\\nExplore the story and the reasons why a problem won't solve itself .,  The Cotswolds are a slice of picture-postcard England .\\nThe wool trade boomed in these rolling hills in medieval times and today the region is littered with achingly pretty villages .\\nLeading members of the arts and crafts movement were among the first to visit Chipping Campden with its long curving high street .]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, input_trunc_at=500, target_trunc_at=250)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_fname = \"summarize_export\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.metrics = None\n",
    "learn.export(fname=f\"{export_fname}.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_texts': \" The robbers made off with several hundred thousand Swiss francs in the early hours of Sunday morning .\\nThe men, dressed in black clothes and black ski masks, split into two groups during the raid on the Grand Casino Basel .\\nAs the thieves were leaving the casino, a woman driving by unknowingly blocked the armed robbers' vehicles .\\nA gunman pulled the woman from her vehicle, beat her up, and took off for the French border .\\nThere were about 600 people in the casino at the time of the robbery .\"}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_learn = load_learner(fname=f\"{export_fname}.pkl\")\n",
    "inf_learn.blurr_generate(test_article)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_callbacks.ipynb.\n",
      "Converted 00_utils.ipynb.\n",
      "Converted 01_text-callbacks.ipynb.\n",
      "Converted 01_text-utils.ipynb.\n",
      "Converted 11_text-data-core.ipynb.\n",
      "Converted 11_text-modeling-core.ipynb.\n",
      "Converted 12_text-data-language-modeling.ipynb.\n",
      "Converted 12_text-modeling-language-modeling.ipynb.\n",
      "Converted 13_text-data-token-classification.ipynb.\n",
      "Converted 13_text-modeling-token-classification.ipynb.\n",
      "Converted 14_text-data-question-answering.ipynb.\n",
      "Converted 14_text-modeling-question-answering.ipynb.\n",
      "Converted 20_text-data-seq2seq-core.ipynb.\n",
      "Converted 20_text-modeling-seq2seq-core.ipynb.\n",
      "Converted 21_text-data-seq2seq-summarization.ipynb.\n",
      "Converted 21_text-modeling-seq2seq-summarization.ipynb.\n",
      "Converted 22_text-data-seq2seq-translation.ipynb.\n",
      "Converted 22_text-modeling-seq2seq-translation.ipynb.\n",
      "Converted 99a_text-examples-high-level-api.ipynb.\n",
      "Converted 99b_text-examples-glue.ipynb.\n",
      "Converted 99c_text-examples-glue-plain-pytorch.ipynb.\n",
      "Converted 99d_text-examples-multilabel.ipynb.\n",
      "Converted 99e_text-examples-causal-lm-gpt2.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#|hide\n",
    "from nbdev import nbdev_export\n",
    "\n",
    "nbdev_export()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
