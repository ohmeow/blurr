{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp modeling.question_answering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_slow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modeling.question_answering\n",
    "\n",
    "> This module contains custom models, loss functions, custom splitters, etc... for question answering tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import os, ast, inspect\n",
    "from typing import Any, Callable, Dict, List, Optional, Union, Type\n",
    "\n",
    "from fastcore.all import *\n",
    "from fastai.callback.all import *\n",
    "from fastai.data.block import DataBlock, CategoryBlock, ColReader, ItemGetter, ColSplitter, RandomSplitter\n",
    "from fastai.data.core import DataLoader, DataLoaders, TfmdDL\n",
    "from fastai.imports import *\n",
    "from fastai.learner import *\n",
    "from fastai.losses import CrossEntropyLossFlat\n",
    "from fastai.optimizer import Adam, OptimWrapper, params\n",
    "from fastai.torch_core import *\n",
    "from fastai.torch_imports import *\n",
    "from seqeval import metrics as seq_metrics\n",
    "from transformers import AutoModelForQuestionAnswering, PreTrainedModel, logging\n",
    "\n",
    "from blurr.utils import BLURR\n",
    "from blurr.data.core import TextBlock, BlurrDataLoader, first_blurr_tfm\n",
    "from blurr.modeling.core import BaseModelCallback, PreCalculatedLoss, Blearner\n",
    "from blurr.data.question_answering import QAPreprocessor, QATextInput, QABatchTokenizeTransform\n",
    "\n",
    "# metrics we'll use in extractive qa\n",
    "from datasets import load_metric\n",
    "squad_metric = load_metric(\"squad\")\n",
    "\n",
    "logging.set_verbosity_error()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What we're running with at the time this documentation was generated:\n",
      "torch: 1.10.1+cu111\n",
      "fastai: 2.5.3\n",
      "transformers: 4.16.2\n"
     ]
    }
   ],
   "source": [
    "# hide_input\n",
    "import pdb\n",
    "\n",
    "from datasets import load_dataset\n",
    "from fastai.data.external import untar_data, URLs\n",
    "from fastcore.test import *\n",
    "from nbverbose.showdoc import show_doc\n",
    "from transformers import AutoConfig\n",
    "\n",
    "from blurr.utils import print_versions\n",
    "from blurr.modeling.core import BaseModelWrapper, PreCalculatedLoss, blurr_splitter\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "print(\"What we're running with at the time this documentation was generated:\")\n",
    "print_versions(\"torch fastai transformers\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU #1: GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "# cuda\n",
    "torch.cuda.set_device(1)\n",
    "print(f\"Using GPU #{torch.cuda.current_device()}: {torch.cuda.get_device_name()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "We'll use a subset of `squad_v2` to demonstrate how to configure your blurr code for training extractive question answering models. See the `data.question_answering` module if any of this setting up of the `squad_df` below looks unfamiliar to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset squad (/home/wgilliam/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f3f650a30784d8bbde59db451cf6812",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200\n"
     ]
    }
   ],
   "source": [
    "raw_datasets = load_dataset(\"squad\", split=[\"train[:1000]\", \"validation[:200]\"])\n",
    "\n",
    "raw_train_df = pd.DataFrame(raw_datasets[0])\n",
    "raw_valid_df = pd.DataFrame(raw_datasets[1])\n",
    "\n",
    "raw_train_df[\"is_valid\"] = False\n",
    "raw_valid_df[\"is_valid\"] = True\n",
    "\n",
    "squad_df = pd.concat([raw_train_df, raw_valid_df])\n",
    "\n",
    "squad_df[\"ans_start_char_idx\"] = squad_df.answers.apply(lambda v: v[\"answer_start\"][0] if len(v[\"answer_start\"]) > 0 else \"0\")\n",
    "squad_df[\"answer_text\"] = squad_df.answers.apply(lambda v: v[\"text\"][0] if len(v[\"text\"]) > 0 else \"\")\n",
    "squad_df[\"ans_end_char_idx\"] = squad_df[\"ans_start_char_idx\"].astype(int) + squad_df[\"answer_text\"].str.len()\n",
    "\n",
    "print(len(squad_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cls = AutoModelForQuestionAnswering\n",
    "\n",
    "pretrained_model_name = \"bert-large-uncased-whole-word-masking-finetuned-squad\"\n",
    "hf_arch, hf_config, hf_tokenizer, hf_model = BLURR.get_hf_objects(pretrained_model_name, model_cls=model_cls)\n",
    "\n",
    "max_seq_len = 128\n",
    "vocab = dict(enumerate(range(max_seq_len)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "      <th>is_valid</th>\n",
       "      <th>ans_start_char_idx</th>\n",
       "      <th>answer_text</th>\n",
       "      <th>ans_end_char_idx</th>\n",
       "      <th>proc_question</th>\n",
       "      <th>proc_context</th>\n",
       "      <th>ans_start_token_idx</th>\n",
       "      <th>ans_end_token_idx</th>\n",
       "      <th>is_answerable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5733be284776f41900661182</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct...</td>\n",
       "      <td>To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?</td>\n",
       "      <td>{'text': ['Saint Bernadette Soubirous'], 'answer_start': [515]}</td>\n",
       "      <td>False</td>\n",
       "      <td>515</td>\n",
       "      <td>Saint Bernadette Soubirous</td>\n",
       "      <td>541</td>\n",
       "      <td>To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?</td>\n",
       "      <td>Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputed</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id                     title  \\\n",
       "0  5733be284776f41900661182  University_of_Notre_Dame   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   context  \\\n",
       "0  Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct...   \n",
       "\n",
       "                                                                  question  \\\n",
       "0  To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?   \n",
       "\n",
       "                                                           answers  is_valid  \\\n",
       "0  {'text': ['Saint Bernadette Soubirous'], 'answer_start': [515]}     False   \n",
       "\n",
       "   ans_start_char_idx                 answer_text  ans_end_char_idx  \\\n",
       "0                 515  Saint Bernadette Soubirous               541   \n",
       "\n",
       "                                                             proc_question  \\\n",
       "0  To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           proc_context  \\\n",
       "0  Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputed   \n",
       "\n",
       "   ans_start_token_idx  ans_end_token_idx  is_answerable  \n",
       "0                    0                  0          False  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor = QAPreprocessor(\n",
    "    hf_tokenizer, id_attr=\"id\", tok_kwargs={\"return_overflowing_tokens\": True, \"max_length\": max_seq_len, \"stride\": 64}\n",
    ")\n",
    "\n",
    "proc_df = preprocessor.process_df(squad_df)\n",
    "proc_df.head(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_batch_tfm = QABatchTokenizeTransform(hf_arch, hf_config, hf_tokenizer, hf_model, max_length=max_seq_len)\n",
    "\n",
    "blocks = (\n",
    "    TextBlock(batch_tokenize_tfm=before_batch_tfm, input_return_type=QATextInput),\n",
    "    CategoryBlock(vocab=vocab),\n",
    "    CategoryBlock(vocab=vocab),\n",
    ")\n",
    "\n",
    "# since its preprocessed, we include an \"text\" key with the values of our question and context\n",
    "def get_x(item):\n",
    "    return {\"text\": (item.proc_question, item.proc_context), \"id\": item.id}\n",
    "\n",
    "\n",
    "dblock = DataBlock(\n",
    "    blocks=blocks,\n",
    "    get_x=get_x,\n",
    "    get_y=[ItemGetter(\"ans_start_token_idx\"), ItemGetter(\"ans_end_token_idx\")],\n",
    "    splitter=ColSplitter(),\n",
    "    n_inp=1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = dblock.dataloaders(proc_df, bs=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,\n",
       " [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127],\n",
       " [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dls.vocab), dls.vocab[0], dls.vocab[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>found</th>\n",
       "      <th>start/end</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>which nfl team represented the afc at super bowl 50? super bowl 50 was an american football game to determine the champion of the national football league ( nfl ) for the 2015 season. the american football conference ( afc ) champion denver broncos defeated the national football conference ( nfc ) champion carolina panthers 24 â€“ 10 to earn their third super bowl title. the game was played on february 7, 2016, at levi's stadium in the san francisco bay area at santa clara, california. as this was the 50th super bowl, the league emphasized the \" golden anniversary \" with various gold - themed initiatives, as well as temporarily suspending the</td>\n",
       "      <td>True</td>\n",
       "      <td>(46, 48)</td>\n",
       "      <td>denver broncos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>which nfl team represented the afc at super bowl 50? earn their third super bowl title. the game was played on february 7, 2016, at levi's stadium in the san francisco bay area at santa clara, california. as this was the 50th super bowl, the league emphasized the \" golden anniversary \" with various gold - themed initiatives, as well as temporarily suspending the tradition of naming each super bowl game with roman numerals ( under which the game would have been known as \" super bowl l \" ), so that the logo could prominently feature the arabic numerals 50.</td>\n",
       "      <td>False</td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.valid.show_batch(dataloaders=dls, max_n=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mid-level API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `QAModelCallback`\n",
    "\n",
    "Here we create a question/answer specific subclass of `BaseModelCallback` in order to get all the start and end prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class QAModelCallback(BaseModelCallback):\n",
    "    \"\"\"The prediction is a combination start/end logits\"\"\"\n",
    "\n",
    "    def after_pred(self):\n",
    "        super().after_pred()\n",
    "        self.learn.pred = (self.pred.start_logits, self.pred.end_logits)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `QAMetricsCallback`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class QAMetricsCallback(Callback):\n",
    "    def __init__(self, compute_metrics_func, validation_ds, qa_metrics=[\"exact_match\", \"f1\"], **kwargs):\n",
    "        self.run_before = Recorder\n",
    "\n",
    "        store_attr()\n",
    "        self.custom_metrics_dict = {k: None for k in qa_metrics}\n",
    "        self.do_setup = True\n",
    "\n",
    "    def setup(self):\n",
    "        # one time setup code here.\n",
    "        if not self.do_setup:\n",
    "            return\n",
    "\n",
    "        # grab the hf_tokenizer from the TokenClassBatchTokenizeTransform\n",
    "        tfm = first_blurr_tfm(self.learn.dls, tfms=[QABatchTokenizeTransform])\n",
    "        self.hf_tokenizer = tfm.hf_tokenizer\n",
    "        self.tok_kwargs = tfm.tok_kwargs\n",
    "\n",
    "        # add custom question answering specific metrics\n",
    "        custom_metrics = L([ValueMetric(partial(self.metric_value, metric_key=k), k) for k in self.qa_metrics])\n",
    "        self.learn.metrics = self.learn.metrics + custom_metrics\n",
    "\n",
    "        self.do_setup = False\n",
    "\n",
    "    def before_fit(self):\n",
    "        self.setup()\n",
    "\n",
    "    # --- batch before/after phases ---\n",
    "    def before_batch(self):\n",
    "        if self.training or self.learn.y is None:\n",
    "            return\n",
    "\n",
    "        self.batch_inputs = {k: v.cpu().detach().numpy() if isinstance(v, Tensor) else v for k, v in self.x.items()}\n",
    "\n",
    "    def after_batch(self):\n",
    "        if self.training or self.learn.y is None:\n",
    "            return\n",
    "\n",
    "        for i in range(len(self.batch_inputs[\"input_ids\"])):\n",
    "            batch_inps = {k: self.batch_inputs[k][i] for k in self.batch_inputs.keys()}\n",
    "            self.results.append(\n",
    "                {**batch_inps, \"start_logits\": self.pred[0][i].cpu().detach().numpy(), \"end_logits\": self.pred[1][i].cpu().detach().numpy()}\n",
    "            )\n",
    "\n",
    "    # --- validation begin/after phases ---\n",
    "    def before_validate(self):\n",
    "        self.results = []\n",
    "\n",
    "    def after_validate(self):\n",
    "        if len(self.results) < 1:\n",
    "            return\n",
    "\n",
    "        metric_vals_d = self.compute_metrics_func(self.results, self.validation_ds, self.hf_tokenizer, self.tok_kwargs)\n",
    "        for k, v in metric_vals_d.items():\n",
    "            self.custom_metrics_dict[k] = v\n",
    "\n",
    "    # --- for ValueMetric metrics ---\n",
    "    def metric_value(self, metric_key):\n",
    "        return self.custom_metrics_dict[metric_key]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def compute_qa_metrics(results, dataset, hf_tokenizer, tok_kwargs, id_attr=\"id\", n_best=20):\n",
    "    # what is the max length for our inputs?\n",
    "    max_length = tok_kwargs.get(\"max_length\", hf_tokenizer.model_max_length)\n",
    "\n",
    "    # map examples to chunks indicies that are part of the\n",
    "    example_to_chunks = collections.defaultdict(list)\n",
    "    for idx, chunk in enumerate(results):\n",
    "        example_to_chunks[chunk[id_attr]].append(idx)\n",
    "\n",
    "    predicted_answers = []\n",
    "    for item_idx, item in enumerate(dataset):\n",
    "        example_id = item[id_attr]\n",
    "\n",
    "        answers = []\n",
    "        for chunk_idx in example_to_chunks[example_id]:\n",
    "            chunk = results[chunk_idx]\n",
    "            input_ids = chunk[\"input_ids\"]\n",
    "            start_logits = chunk[\"start_logits\"]\n",
    "            end_logits = chunk[\"end_logits\"]\n",
    "\n",
    "            start_indexes = np.argsort(start_logits)[-1 : -n_best - 1 : -1].tolist()\n",
    "            end_indexes = np.argsort(end_logits)[-1 : -n_best - 1 : -1].tolist()\n",
    "\n",
    "            for s_idx, start_index in enumerate(start_indexes):\n",
    "                for e_idx, end_index in enumerate(end_indexes):\n",
    "                    # Skip answers that are not fully in the context\n",
    "                    if start_index == 0 and end_index == 0:\n",
    "                        continue\n",
    "\n",
    "                    # Skip answers with a length that is either < 0 or > max_answer_length\n",
    "                    if end_index < start_index or end_index - start_index + 1 > max_length:\n",
    "                        continue\n",
    "\n",
    "                    answer = {\n",
    "                        \"text\": hf_tokenizer.decode(input_ids[start_index:end_index], skip_special_tokens=True),\n",
    "                        \"logit_score\": start_logits[start_index] + end_logits[end_index],\n",
    "                    }\n",
    "                    answers.append(answer)\n",
    "\n",
    "        # select the answer with the best score\n",
    "        if len(answers) > 0:\n",
    "            best_answer = max(answers, key=lambda x: x[\"logit_score\"])\n",
    "            predicted_answers.append({\"id\": example_id, \"prediction_text\": best_answer[\"text\"]})\n",
    "        else:\n",
    "            predicted_answers.append({\"id\": example_id, \"prediction_text\": \"\"})\n",
    "\n",
    "    ref_answers = [{\"id\": item[\"id\"], \"answers\": item[\"answers\"]} for item_idx, item in enumerate(dataset)]\n",
    "\n",
    "    metric_vals_d = squad_metric.compute(predictions=predicted_answers, references=ref_answers)\n",
    "    return metric_vals_d\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `PreCalculatedQALoss`\n",
    "\n",
    "Hugging Face question answering models will calculate the loss for you when you include both the `start_positions` and `end_positions` in the inputs dictionary.  This is done by the `QABatchTokenizeTransform` when `include_labels` = True (which is the default).  This also requires fastai developers to set their `Learner`'s loss function to the `PreCalculatedQALoss` for training to work properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreCalculatedQALoss(PreCalculatedLoss):\n",
    "    def __init__(self, *args, axis=-1, **kwargs): \n",
    "        super().__init__(nn.CrossEntropyLoss, *args, axis=axis, **kwargs)\n",
    "\n",
    "    def __call__(self, inp, targ, targ2, **kwargs):\n",
    "        return tensor(0.0)\n",
    "\n",
    "    def decodes(self, x):\n",
    "        return x[0].argmax(dim=self.axis), x[1].argmax(dim=self.axis)\n",
    "\n",
    "    def activation(self, x):\n",
    "        return F.softmax(x[0], dim=self.axis), F.softmax(x[1], dim=self.axis)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `MultiTargetLoss`\n",
    "\n",
    "If you want more control over the loss calculation, we provide here a custom loss function you can use in your question answering tasks.\n",
    "\n",
    "In fact, this new loss function can be used in many other multi-modal architectures, with any mix of loss functions.  For example, this can be ammended to include the `is_impossible` task, as well as the start/end token tasks in the SQUAD v2 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class MultiTargetLoss(Module):\n",
    "    \"\"\"Provides the ability to apply different loss functions to multi-modal targets/predictions\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        # The loss function for each target\n",
    "        loss_classes: List[Callable] = [CrossEntropyLossFlat, CrossEntropyLossFlat],\n",
    "        # Any kwargs you want to pass to the loss functions above\n",
    "        loss_classes_kwargs: List[dict] = [{}, {}],\n",
    "        # The weights you want to apply to each loss (default: [1,1])\n",
    "        weights: Union[List[float], List[int]] = [1, 1],\n",
    "        # The `reduction` parameter of the lass function (default: 'mean')\n",
    "        reduction: str = \"mean\",\n",
    "    ):\n",
    "        loss_funcs = [cls(reduction=reduction, **kwargs) for cls, kwargs in zip(loss_classes, loss_classes_kwargs)]\n",
    "        store_attr(self=self, names=\"loss_funcs, weights\")\n",
    "        self._reduction = reduction\n",
    "\n",
    "    # custom loss function must have either a reduction attribute or a reduction argument (like all fastai and\n",
    "    # PyTorch loss functions) so that the framework can change this as needed (e.g., when doing lear.get_preds\n",
    "    # it will set = 'none'). see this forum topic for more info: https://bit.ly/3br2Syz\n",
    "    @property\n",
    "    def reduction(self):\n",
    "        return self._reduction\n",
    "\n",
    "    @reduction.setter\n",
    "    def reduction(self, v):\n",
    "        self._reduction = v\n",
    "        for lf in self.loss_funcs:\n",
    "            lf.reduction = v\n",
    "\n",
    "    def forward(self, outputs, *targets):\n",
    "        loss = 0.0\n",
    "        for i, loss_func, weights, output, target in zip(range(len(outputs)), self.loss_funcs, self.weights, outputs, targets):\n",
    "            loss += weights * loss_func(output, target)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def activation(self, outs):\n",
    "        acts = [self.loss_funcs[i].activation(o) for i, o in enumerate(outs)]\n",
    "        return acts\n",
    "\n",
    "    def decodes(self, outs):\n",
    "        decodes = [self.loss_funcs[i].decodes(o) for i, o in enumerate(outs)]\n",
    "        return decodes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example\n",
    "\n",
    "Notice below how I had to define the loss function *after* creating the `Learner` object.  I'm not sure why, but the `MultiTargetLoss` above prohibits the learner from being exported if I do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BaseModelWrapper(hf_model)\n",
    "learn_cbs = [QAModelCallback]\n",
    "\n",
    "validation_ds = proc_df[proc_df.is_valid == True].to_dict(orient=\"records\")\n",
    "fit_cbs = [QAMetricsCallback(compute_metrics_func=compute_qa_metrics, validation_ds=validation_ds)]\n",
    "\n",
    "learn = Learner(dls, model, opt_func=partial(Adam), cbs=learn_cbs, splitter=blurr_splitter)\n",
    "\n",
    "learn.loss_func = PreCalculatedQALoss() #MultiTargetLoss()\n",
    "learn.create_opt()  # -> will create your layer groups based on your \"splitter\" function\n",
    "learn.freeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide_output\n",
    "# learn.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(len(learn.opt.param_groups))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(minimum=0.0033113110810518267, steep=2.75422871709452e-06, valley=0.001737800776027143, slide=0.0014454397605732083)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find(suggest_funcs=[minimum, steep, valley, slide])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>exact_match</th>\n",
       "      <th>f1</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.706969</td>\n",
       "      <td>0.922961</td>\n",
       "      <td>79.344262</td>\n",
       "      <td>86.014420</td>\n",
       "      <td>01:29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, lr_max=1e-3, cbs=fit_cbs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Showing results\n",
    "\n",
    "And here we create a `@typedispatch`ed implementation of `Learner.show_results` for a more intuitive QA task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@typedispatch\n",
    "def show_results(\n",
    "    # This typedispatched `show_results` will be called for `QuestionAnswerTextInput` typed inputs\n",
    "    x: QATextInput,\n",
    "    # The targets\n",
    "    y,\n",
    "    # Your raw inputs/targets\n",
    "    samples,\n",
    "    # The model's predictions\n",
    "    outs,\n",
    "    # Your `Learner`. This is required so as to get at the Hugging Face objects for decoding them into\n",
    "    # something understandable\n",
    "    learner,\n",
    "    # Whether you want to remove special tokens during decoding/showing the outputs\n",
    "    skip_special_tokens=True,\n",
    "    # Your `show_results` context\n",
    "    ctxs=None,\n",
    "    # The maximum number of items to show\n",
    "    max_n=6,\n",
    "    # Any truncation your want applied to your decoded inputs\n",
    "    trunc_at=None,\n",
    "    # Any other keyword arguments you want applied to `show_results`\n",
    "    **kwargs\n",
    "):\n",
    "    tfm = first_blurr_tfm(learner.dls, tfms=[QABatchTokenizeTransform])\n",
    "    hf_tokenizer = tfm.hf_tokenizer\n",
    "\n",
    "    res = L()\n",
    "    for sample, input_ids, start, end, pred in zip(samples, x, *y, outs):\n",
    "        txt = hf_tokenizer.decode(sample[0], skip_special_tokens=True)[:trunc_at]\n",
    "        found = start.item() != 0 and end.item() != 0\n",
    "        ans_text = hf_tokenizer.decode(input_ids[start:end], skip_special_tokens=False)\n",
    "\n",
    "        pred_ans_toks = hf_tokenizer.convert_ids_to_tokens(input_ids, skip_special_tokens=False)[int(pred[0]) : int(pred[1])]\n",
    "        pred_ans_txt = hf_tokenizer.convert_tokens_to_string(pred_ans_toks)\n",
    "\n",
    "        res.append((txt, found, (start.item(), end.item()), ans_text, (int(pred[0]), int(pred[1])), pred_ans_txt))\n",
    "\n",
    "    display_df(pd.DataFrame(res, columns=[\"text\", \"found\", \"start/end\", \"answer\", \"pred start/end\", \"pred answer\"]))\n",
    "    return ctxs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>found</th>\n",
       "      <th>start/end</th>\n",
       "      <th>answer</th>\n",
       "      <th>pred start/end</th>\n",
       "      <th>pred answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>which nfl team represented the afc at super bowl 50? super bowl 50 was an american football game to determine the champion of the national football league ( nfl ) for the 2015 season. the american football conference ( afc ) champion denver broncos defeated the national football conference ( nfc ) champion carolina panthers 24 â€“ 10 to earn their third super bowl title. the game was played on february 7, 2016, at levi's stadium in the san francisco bay area at santa clara, california. as this was</td>\n",
       "      <td>True</td>\n",
       "      <td>(46, 48)</td>\n",
       "      <td>denver broncos</td>\n",
       "      <td>(46, 48)</td>\n",
       "      <td>denver broncos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>who won super bowl 50? super bowl 50 was an american football game to determine the champion of the national football league ( nfl ) for the 2015 season. the american football conference ( afc ) champion denver broncos defeated the national football conference ( nfc ) champion carolina panthers 24 â€“ 10 to earn their third super bowl title. the game was played on february 7, 2016, at levi's stadium in the san francisco bay area at santa clara, california. as this was the 50th super bowl, the leag</td>\n",
       "      <td>True</td>\n",
       "      <td>(41, 43)</td>\n",
       "      <td>denver broncos</td>\n",
       "      <td>(41, 43)</td>\n",
       "      <td>denver broncos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>when were the finalists announced? the league announced on october 16, 2012, that the two finalists were sun life stadium and levi's stadium. the south florida / miami area has previously hosted the event 10 times ( tied for most with new orleans ), with the most recent one being super bowl xliv in 2010. the san francisco bay area last hosted in 1985 ( super bowl xix ), held at stanford stadium in stanford, california, won by the home team 49ers. the miami bid depended on whether the stadium und</td>\n",
       "      <td>True</td>\n",
       "      <td>(12, 16)</td>\n",
       "      <td>october 16, 2012</td>\n",
       "      <td>(12, 16)</td>\n",
       "      <td>october 16, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>super bowl 50 decided the nfl champion for what season? super bowl 50 was an american football game to determine the champion of the national football league ( nfl ) for the 2015 season. the american football conference ( afc ) champion denver broncos defeated the national football conference ( nfc ) champion carolina panthers 24 â€“ 10 to earn their third super bowl title. the game was played on february 7, 2016, at levi's stadium in the san francisco bay area at santa clara, california. as this</td>\n",
       "      <td>True</td>\n",
       "      <td>(35, 36)</td>\n",
       "      <td>2015</td>\n",
       "      <td>(35, 37)</td>\n",
       "      <td>2015 season</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, skip_special_tokens=True, max_n=4, trunc_at=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>exact_match</th>\n",
       "      <th>f1</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.472573</td>\n",
       "      <td>0.923250</td>\n",
       "      <td>79.344262</td>\n",
       "      <td>85.740596</td>\n",
       "      <td>03:13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, lr_max=slice(1e-9, 1e-7), cbs=fit_cbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.recorder.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>found</th>\n",
       "      <th>start/end</th>\n",
       "      <th>answer</th>\n",
       "      <th>pred start/end</th>\n",
       "      <th>pred answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>which nfl team represented the afc at super bowl 50? super bowl 50 was an american football game to</td>\n",
       "      <td>True</td>\n",
       "      <td>(46, 48)</td>\n",
       "      <td>denver broncos</td>\n",
       "      <td>(46, 48)</td>\n",
       "      <td>denver broncos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what seed was the denver broncos? while the denver broncos became one of four teams to have made eig</td>\n",
       "      <td>False</td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td></td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, max_n=2, trunc_at=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction\n",
    "\n",
    "Note that there is a bug currently in fastai v2 (or with how I'm assembling everything) that currently prevents us from seeing the decoded predictions and probabilities for the \"end\" token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('11', '13'), [11, 13])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_df = pd.DataFrame.from_dict(\n",
    "    [\n",
    "        {\n",
    "            \"id\": -1,\n",
    "            \"proc_question\": \"What did George Lucas make?\",\n",
    "            \"proc_context\": \"George Lucas created Star Wars in 1977. He directed and produced it.\",\n",
    "        }\n",
    "    ],\n",
    "    orient=\"columns\",\n",
    ")\n",
    "\n",
    "results = learn.blurr_predict(inf_df)\n",
    "pred_labels, pred_idxs, probs = results[0]\n",
    "\n",
    "pred_labels, pred_idxs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['star', 'wars']\n"
     ]
    }
   ],
   "source": [
    "for res, (r_idx, r) in zip(results, inf_df.iterrows()):\n",
    "    inp_ids = hf_tokenizer.encode(r[\"proc_question\"], r[\"proc_context\"])\n",
    "    pred_labels, pred_idxs, probs = res\n",
    "    answer = hf_tokenizer.convert_ids_to_tokens(inp_ids, skip_special_tokens=False)[pred_idxs[0] : pred_idxs[1]]\n",
    "    print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_df = pd.DataFrame.from_dict(\n",
    "    [\n",
    "        {\n",
    "            \"id\": -1,\n",
    "            \"proc_question\": \"What did George Lucas make?\",\n",
    "            \"proc_context\": \"George Lucas created Star Wars in 1977. He directed and produced it.\",\n",
    "        },\n",
    "        {\n",
    "            \"id\": -1,\n",
    "            \"proc_question\": \"What year did Star Wars come out?\",\n",
    "            \"proc_context\": \"George Lucas created Star Wars in 1977. He directed and produced it.\",\n",
    "        },\n",
    "        {\n",
    "            \"id\": -1,\n",
    "            \"proc_question\": \"What did George Lucas do?\",\n",
    "            \"proc_context\": \"George Lucas created Star Wars in 1977. He directed and produced it.\",\n",
    "        },\n",
    "    ],\n",
    "    orient=\"columns\",\n",
    ")\n",
    "\n",
    "results = learn.blurr_predict(inf_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['star', 'wars']\n",
      "['1977']\n",
      "['directed', 'and', 'produced', 'it']\n"
     ]
    }
   ],
   "source": [
    "for res, (r_idx, r) in zip(results, inf_df.iterrows()):\n",
    "    inp_ids = hf_tokenizer.encode(r[\"proc_question\"], r[\"proc_context\"])\n",
    "    pred_labels, pred_idxs, probs = res\n",
    "    answer = hf_tokenizer.convert_ids_to_tokens(inp_ids, skip_special_tokens=False)[pred_idxs[0] : pred_idxs[1]]\n",
    "    print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inf_df = pd.DataFrame.from_dict(\n",
    "    [\n",
    "        {\n",
    "            \"id\": -1,\n",
    "            \"proc_question\": \"When was Star Wars made?\",\n",
    "            \"proc_context\": \"George Lucas created Star Wars in 1977. He directed and produced it.\",\n",
    "        },\n",
    "        {\n",
    "            \"id\": -2,\n",
    "            \"proc_question\": \"Who made Star Wars?\",\n",
    "            \"proc_context\": \"George Lucas created Star Wars in 1977. He directed and produced it.\",\n",
    "        },\n",
    "        {\n",
    "            \"id\": -3,\n",
    "            \"proc_question\": \"Who plays Spock in the movie?\",\n",
    "            \"proc_context\": \"George Lucas created Star Wars in 1977. He directed and produced it.\",\n",
    "        },\n",
    "    ],\n",
    "    orient=\"columns\",\n",
    ")\n",
    "\n",
    "test_dl = dls.test_dl(inf_df)\n",
    "probs, _, preds = learn.get_preds(dl=test_dl, with_input=False, with_decoded=True)\n",
    "\n",
    "starts, ends = preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1977']\n",
      "['george', 'lucas']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "for start, end, (r_idx, r) in zip(starts, ends, inf_df.iterrows()):\n",
    "    inp_ids = hf_tokenizer.encode(r[\"proc_question\"], r[\"proc_context\"])\n",
    "    answer = hf_tokenizer.convert_ids_to_tokens(inp_ids, skip_special_tokens=False)[start:end]\n",
    "    print(answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference\n",
    "\n",
    "Note that I had to replace the loss function because of the above-mentioned issue to exporting the model with the `MultiTargetLoss` loss function.  After getting our inference learner, we put it back and we're good to go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_name = \"q_and_a_learn_export\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.loss_func = CrossEntropyLossFlat()\n",
    "learn.export(fname=f\"{export_name}.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_learn = load_learner(fname=f\"{export_name}.pkl\")\n",
    "inf_learn.loss_func = MultiTargetLoss()\n",
    "\n",
    "inf_df = pd.DataFrame.from_dict(\n",
    "    [\n",
    "        {\n",
    "            \"id\": -1,\n",
    "            \"proc_question\": \"When was Star Wars made?\",\n",
    "            \"proc_context\": \"George Lucas created Star Wars in 1977. He directed and produced it.\",\n",
    "        },\n",
    "        {\n",
    "            \"id\": -2,\n",
    "            \"proc_question\": \"Who made Star Wars?\",\n",
    "            \"proc_context\": \"George Lucas created Star Wars in 1977. He directed and produced it.\",\n",
    "        },\n",
    "        {\n",
    "            \"id\": -3,\n",
    "            \"proc_question\": \"Who plays Spock in 1977?\",\n",
    "            \"proc_context\": \"George Lucas created Star Wars in 1977. He directed and produced it.\",\n",
    "        },\n",
    "    ],\n",
    "    orient=\"columns\",\n",
    ")\n",
    "\n",
    "results = inf_learn.blurr_predict(inf_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1977']\n",
      "['george', 'lucas']\n",
      "['george', 'lucas']\n"
     ]
    }
   ],
   "source": [
    "for res, (r_idx, r) in zip(results, inf_df.iterrows()):\n",
    "    inp_ids = hf_tokenizer.encode(r[\"proc_question\"], r[\"proc_context\"])\n",
    "    pred_labels, pred_idxs, probs = res\n",
    "    answer = hf_tokenizer.convert_ids_to_tokens(inp_ids, skip_special_tokens=False)[pred_idxs[0] : pred_idxs[1]]\n",
    "    print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "try:\n",
    "    del learn\n",
    "    del inf_learn\n",
    "    torch.cuda.empty_cache()\n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The High-level API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `BLearnerForQuestionAnswering`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@delegates(Blearner.__init__)\n",
    "class BlearnerForQuestionAnswering(Blearner):\n",
    "    def __init__(self, dls: DataLoaders, hf_model: PreTrainedModel, **kwargs):\n",
    "        kwargs[\"loss_func\"] = kwargs.get(\"loss_func\", MultiTargetLoss())\n",
    "        super().__init__(dls, hf_model, base_model_cb=QAModelCallback, **kwargs)\n",
    "\n",
    "    @classmethod\n",
    "    def get_model_cls(self):\n",
    "        return AutoModelForQuestionAnswering\n",
    "\n",
    "    @classmethod\n",
    "    def _get_x(cls, x, qst, ctx, padding_side=\"right\"):\n",
    "        return (x[qst], x[ctx]) if (padding_side == \"right\") else (x[ctx], x[qst])\n",
    "\n",
    "    @classmethod\n",
    "    def _create_learner(\n",
    "        cls,\n",
    "        # Your raw dataset\n",
    "        data,\n",
    "        # The name or path of the pretrained model you want to fine-tune\n",
    "        pretrained_model_name_or_path: Optional[Union[str, os.PathLike]],\n",
    "        # The maximum sequence length to constrain our data\n",
    "        max_seq_len: int = None,\n",
    "        # The attribute in your dataset that contains the context (where the answer is included) (default: 'context')\n",
    "        context_attr: str = \"context\",\n",
    "        # The attribute in your dataset that contains the question being asked (default: 'question')\n",
    "        question_attr: str = \"question\",\n",
    "        # The attribute in your dataset that contains the actual answer (default: 'answer_text')\n",
    "        answer_text_attr: str = \"answer_text\",\n",
    "        # The attribute in your dataset that contains the tokenized answer start (default: 'tok_answer_start')\n",
    "        tok_ans_start_attr: str = \"ans_start_token_idx\",\n",
    "        # The attribute in your dataset that contains the tokenized answer end(default: 'tok_answer_end')\n",
    "        tok_ans_end_attr: str = \"ans_end_token_idx\",\n",
    "        # A function that will split your Dataset into a training and validation set\n",
    "        # See [here](https://docs.fast.ai/data.transforms.html#Split) for a list of fast.ai splitters\n",
    "        dblock_splitter: Callable = RandomSplitter(),\n",
    "        # Any kwargs to pass to your `DataLoaders`\n",
    "        dl_kwargs={},\n",
    "        # Any kwargs to pass to your task specific `Blearner`\n",
    "        learner_kwargs={},\n",
    "    ):\n",
    "        hf_arch, hf_config, hf_tokenizer, hf_model = BLURR.get_hf_objects(pretrained_model_name_or_path, model_cls=cls.get_model_cls())\n",
    "\n",
    "        # potentially used by our preprocess_func, it is the basis for our CategoryBlock vocab\n",
    "        if max_seq_len is None:\n",
    "            max_seq_len = hf_config.get(\"max_position_embeddings\", 128)\n",
    "\n",
    "        # bits required by our \"before_batch_tfm\" and DataBlock\n",
    "        vocab = list(range(max_seq_len))\n",
    "        padding_side = hf_tokenizer.padding_side\n",
    "        trunc_strat = \"only_second\" if (padding_side == \"right\") else \"only_first\"\n",
    "\n",
    "        before_batch_tfm = QABatchTokenizeTransform(\n",
    "            hf_arch, hf_config, hf_tokenizer, hf_model, max_length=max_seq_len, truncation=trunc_strat\n",
    "        )\n",
    "\n",
    "        # define getters\n",
    "        if isinstance(data, pd.DataFrame):\n",
    "            get_x = partial(cls._get_x, qst=question_attr, ctx=context_attr, padding_side=padding_side)\n",
    "            get_y = [ColReader(tok_ans_start_attr), ColReader(tok_ans_end_attr)]\n",
    "        else:\n",
    "            get_x = partial(cls._get_x, qst=question_attr, ctx=context_attr, padding_side=padding_side)\n",
    "            get_y = [ItemGetter(tok_ans_start_attr), ItemGetter(tok_ans_end_attr)]\n",
    "\n",
    "        # define DataBlock and DataLoaders\n",
    "        blocks = (\n",
    "            TextBlock(batch_tokenize_tfm=before_batch_tfm, input_return_type=QATextInput),\n",
    "            CategoryBlock(vocab=vocab),\n",
    "            CategoryBlock(vocab=vocab),\n",
    "        )\n",
    "\n",
    "        dblock = DataBlock(blocks=blocks, get_x=get_x, get_y=get_y, splitter=dblock_splitter, n_inp=1)\n",
    "\n",
    "        dls = dblock.dataloaders(data, **dl_kwargs.copy())\n",
    "\n",
    "        # return BLearner instance\n",
    "        return cls(dls, hf_model, **learner_kwargs.copy())\n",
    "\n",
    "    @classmethod\n",
    "    def from_dataframe(\n",
    "        cls,\n",
    "        # Your pandas DataFrame\n",
    "        df: pd.DataFrame,\n",
    "        # The name or path of the pretrained model you want to fine-tune\n",
    "        pretrained_model_name_or_path: Optional[Union[str, os.PathLike]],\n",
    "        # The maximum sequence length to constrain our data\n",
    "        max_seq_len: int = None,\n",
    "        # The attribute in your dataset that contains the context (where the answer is included) (default: 'context')\n",
    "        context_attr: str = \"context\",\n",
    "        # The attribute in your dataset that contains the question being asked (default: 'question')\n",
    "        question_attr: str = \"question\",\n",
    "        # The attribute in your dataset that contains the actual answer (default: 'answer_text')\n",
    "        answer_text_attr: str = \"answer_text\",\n",
    "        # The attribute in your dataset that contains the tokenized answer start (default: 'tok_answer_start')\n",
    "        tok_ans_start_attr: str = \"ans_start_token_idx\",\n",
    "        # The attribute in your dataset that contains the tokenized answer end(default: 'tok_answer_end')\n",
    "        tok_ans_end_attr: str = \"ans_end_token_idx\",\n",
    "        # A function that will split your Dataset into a training and validation set\n",
    "        # See [here](https://docs.fast.ai/data.transforms.html#Split) for a list of fast.ai splitters\n",
    "        dblock_splitter: Callable = ColSplitter(),\n",
    "        # Any kwargs to pass to your `DataLoaders`\n",
    "        dl_kwargs={},\n",
    "        # Any kwargs to pass to your task specific `Blearner`\n",
    "        learner_kwargs={},\n",
    "    ):\n",
    "        return cls._create_learner(\n",
    "            df,\n",
    "            pretrained_model_name_or_path,\n",
    "            max_seq_len,\n",
    "            context_attr,\n",
    "            question_attr,\n",
    "            answer_text_attr,\n",
    "            tok_ans_start_attr,\n",
    "            tok_ans_end_attr,\n",
    "            dblock_splitter,\n",
    "            dl_kwargs,\n",
    "            learner_kwargs,\n",
    "        )\n",
    "\n",
    "    @classmethod\n",
    "    def from_csv(\n",
    "        cls,\n",
    "        # The path to your csv file\n",
    "        csv_file: Union[Path, str],\n",
    "        # The name or path of the pretrained model you want to fine-tune\n",
    "        pretrained_model_name_or_path: Optional[Union[str, os.PathLike]],\n",
    "        # The maximum sequence length to constrain our data\n",
    "        max_seq_len: int = None,\n",
    "        # The attribute in your dataset that contains the context (where the answer is included) (default: 'context')\n",
    "        context_attr: str = \"context\",\n",
    "        # The attribute in your dataset that contains the question being asked (default: 'question')\n",
    "        question_attr: str = \"question\",\n",
    "        # The attribute in your dataset that contains the actual answer (default: 'answer_text')\n",
    "        answer_text_attr: str = \"answer_text\",\n",
    "        # The attribute in your dataset that contains the tokenized answer start (default: 'tok_answer_start')\n",
    "        tok_ans_start_attr: str = \"ans_start_token_idx\",\n",
    "        # The attribute in your dataset that contains the tokenized answer end(default: 'tok_answer_end')\n",
    "        tok_ans_end_attr: str = \"ans_end_token_idx\",\n",
    "        # A function that will split your Dataset into a training and validation set\n",
    "        # See [here](https://docs.fast.ai/data.transforms.html#Split) for a list of fast.ai splitters\n",
    "        dblock_splitter: Callable = ColSplitter(),\n",
    "        # Any kwargs to pass to your `DataLoaders`\n",
    "        dl_kwargs={},\n",
    "        # Any kwargs to pass to your task specific `Blearner`\n",
    "        learner_kwargs={},\n",
    "    ):\n",
    "        df = pd.read_csv(csv_file)\n",
    "\n",
    "        return cls.from_dataframe(\n",
    "            df,\n",
    "            pretrained_model_name_or_path,\n",
    "            max_seq_len,\n",
    "            context_attr,\n",
    "            question_attr,\n",
    "            answer_text_attr,\n",
    "            tok_ans_start_attr,\n",
    "            tok_ans_end_attr,\n",
    "            dblock_splitter,\n",
    "            dl_kwargs,\n",
    "            learner_kwargs,\n",
    "        )\n",
    "\n",
    "    @classmethod\n",
    "    def from_dictionaries(\n",
    "        cls,\n",
    "        # A list of dictionaries\n",
    "        ds: List[Dict],\n",
    "        # The name or path of the pretrained model you want to fine-tune\n",
    "        pretrained_model_name_or_path: Optional[Union[str, os.PathLike]],\n",
    "        # The maximum sequence length to constrain our data\n",
    "        max_seq_len: int = None,\n",
    "        # The attribute in your dataset that contains the context (where the answer is included) (default: 'context')\n",
    "        context_attr: str = \"context\",\n",
    "        # The attribute in your dataset that contains the question being asked (default: 'question')\n",
    "        question_attr: str = \"question\",\n",
    "        # The attribute in your dataset that contains the actual answer (default: 'answer_text')\n",
    "        answer_text_attr: str = \"answer_text\",\n",
    "        # The attribute in your dataset that contains the tokenized answer start (default: 'tok_answer_start')\n",
    "        tok_ans_start_attr: str = \"tok_answer_start\",\n",
    "        # The attribute in your dataset that contains the tokenized answer end(default: 'tok_answer_end')\n",
    "        tok_ans_end_attr: str = \"tok_answer_end\",\n",
    "        # A function that will split your Dataset into a training and validation set\n",
    "        # See [here](https://docs.fast.ai/data.transforms.html#Split) for a list of fast.ai splitters\n",
    "        dblock_splitter: Callable = RandomSplitter(),\n",
    "        # Any kwargs to pass to your `DataLoaders`\n",
    "        dl_kwargs={},\n",
    "        # Any kwargs to pass to your task specific `Blearner`\n",
    "        learner_kwargs={},\n",
    "    ):\n",
    "        return cls._create_learner(\n",
    "            ds,\n",
    "            pretrained_model_name_or_path,\n",
    "            max_seq_len,\n",
    "            context_attr,\n",
    "            question_attr,\n",
    "            answer_text_attr,\n",
    "            tok_ans_start_attr,\n",
    "            tok_ans_end_attr,\n",
    "            dblock_splitter,\n",
    "            dl_kwargs,\n",
    "            learner_kwargs,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example\n",
    "\n",
    "`BLearnerForQuestionAnswering` requires a question, context (within which to find the answer to the question), and the start/end indices of where the answer lies in the *tokenized context*. Because those indices vary by tokenizer, we can pass a `preprocess_func` that will take our raw data, perform any preprocessing we want, and return it in a way that will work for extractive QA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset squad (/home/wgilliam/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0d7381978c04cf2b193922a68f16b00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "      <th>is_valid</th>\n",
       "      <th>ans_start_char_idx</th>\n",
       "      <th>answer_text</th>\n",
       "      <th>ans_end_char_idx</th>\n",
       "      <th>proc_question</th>\n",
       "      <th>proc_context</th>\n",
       "      <th>ans_start_token_idx</th>\n",
       "      <th>ans_end_token_idx</th>\n",
       "      <th>is_answerable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5733be284776f41900661182</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct...</td>\n",
       "      <td>To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?</td>\n",
       "      <td>{'text': ['Saint Bernadette Soubirous'], 'answer_start': [515]}</td>\n",
       "      <td>False</td>\n",
       "      <td>515</td>\n",
       "      <td>Saint Bernadette Soubirous</td>\n",
       "      <td>541</td>\n",
       "      <td>To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?</td>\n",
       "      <td>Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputed</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id                     title  \\\n",
       "0  5733be284776f41900661182  University_of_Notre_Dame   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   context  \\\n",
       "0  Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct...   \n",
       "\n",
       "                                                                  question  \\\n",
       "0  To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?   \n",
       "\n",
       "                                                           answers  is_valid  \\\n",
       "0  {'text': ['Saint Bernadette Soubirous'], 'answer_start': [515]}     False   \n",
       "\n",
       "   ans_start_char_idx                 answer_text  ans_end_char_idx  \\\n",
       "0                 515  Saint Bernadette Soubirous               541   \n",
       "\n",
       "                                                             proc_question  \\\n",
       "0  To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           proc_context  \\\n",
       "0  Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputed   \n",
       "\n",
       "   ans_start_token_idx  ans_end_token_idx  is_answerable  \n",
       "0                    0                  0          False  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build our training and validation DataFrames\n",
    "raw_datasets = load_dataset(\"squad\", split=[\"train[:1000]\", \"validation[:200]\"])\n",
    "\n",
    "raw_train_df = pd.DataFrame(raw_datasets[0])\n",
    "raw_valid_df = pd.DataFrame(raw_datasets[1])\n",
    "\n",
    "raw_train_df[\"is_valid\"] = False\n",
    "raw_valid_df[\"is_valid\"] = True\n",
    "\n",
    "# concatenate into a single DataFrame\n",
    "squad_df = pd.concat([raw_train_df, raw_valid_df])\n",
    "\n",
    "# include the required start/end character indicies and full text of the answer\n",
    "squad_df[\"ans_start_char_idx\"] = squad_df.answers.apply(lambda v: v[\"answer_start\"][0] if len(v[\"answer_start\"]) > 0 else \"0\")\n",
    "squad_df[\"answer_text\"] = squad_df.answers.apply(lambda v: v[\"text\"][0] if len(v[\"text\"]) > 0 else \"\")\n",
    "squad_df[\"ans_end_char_idx\"] = squad_df[\"ans_start_char_idx\"].astype(int) + squad_df[\"answer_text\"].str.len()\n",
    "\n",
    "# run our modified DataFrame thru the QAPreprocessor to get the start/end \"token\" indices we want to predict\n",
    "preprocessor = QAPreprocessor(\n",
    "    hf_tokenizer, id_attr=\"id\", tok_kwargs={\"return_overflowing_tokens\": True, \"max_length\": max_seq_len, \"stride\": 64}\n",
    ")\n",
    "\n",
    "proc_df = preprocessor.process_df(squad_df)\n",
    "proc_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define your `Blearner`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model_name = \"bert-large-uncased-whole-word-masking-finetuned-squad\"\n",
    "\n",
    "learn = BlearnerForQuestionAnswering.from_dataframe(\n",
    "    proc_df,\n",
    "    pretrained_model_name,\n",
    "    question_attr=\"proc_question\",\n",
    "    context_attr=\"proc_context\",\n",
    "    max_seq_len=128,\n",
    "    dblock_splitter=RandomSplitter(),\n",
    "    dl_kwargs={\"bs\": 4},\n",
    ").to_fp16()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>found</th>\n",
       "      <th>start/end</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>who was the first record label to give the girls a record deal? ped and danced on the talent show circuit in houston. after seeing the group, r &amp; b producer arne frager brought them to his northern california studio and placed them in star search, the largest talent show on national tv at the time. girl's tyme failed to win, and beyonce later said the song they performed was not good. in 1995 beyonce's father resigned from his job to manage the group. the move reduced beyonce's family's income b</td>\n",
       "      <td>False</td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>where did beyonce perform on january 20, 2009? beyonce further expanded her acting career, starring as blues singer etta james in the 2008 musical biopic, cadillac records. her performance in the film received praise from critics, and she garnered several nominations for her portrayal of james, including a satellite award nomination for best supporting actress, and a naacp image award nomination for outstanding supporting actress. beyonce donated her entire salary from the film to phoenix house,</td>\n",
       "      <td>True</td>\n",
       "      <td>(118, 127)</td>\n",
       "      <td>the first couple's first inaugural ball.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what is the lead single on beyonce's first album? beyonce's first solo recording was a feature on jay z's \"'03 bonnie &amp; clyde \" that was released in october 2002, peaking at number four on the u. s. billboard hot 100 chart. her first solo album dangerously in love was released on june 24, 2003, after michelle williams and kelly rowland had released their solo efforts. the album sold 317, 000 copies in its first week, debuted atop the billboard 200, and has since sold 11 million copies worldwide.</td>\n",
       "      <td>True</td>\n",
       "      <td>(119, 122)</td>\n",
       "      <td>crazy in love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what colors are the official ones used by notre dame in sport competition? the big ten conference's decision to add the sport in 2013 â€“ 14 led to a cascade of conference moves that culminated in the dissolution of the school's former hockey home, the central collegiate hockey association, after the 2012 â€“ 13 season. notre dame moved its hockey team to hockey east. after notre dame joined the acc, the conference announced it would add fencing as a sponsored sport beginning in the 2014 â€“ 15 school</td>\n",
       "      <td>False</td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.dls.show_batch(dataloaders=learn.dls, max_n=4, trunc_at=500)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.136393</td>\n",
       "      <td>1.707264</td>\n",
       "      <td>01:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.608203</td>\n",
       "      <td>1.674571</td>\n",
       "      <td>01:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.418061</td>\n",
       "      <td>1.419467</td>\n",
       "      <td>01:43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(3, lr_max=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>found</th>\n",
       "      <th>start/end</th>\n",
       "      <th>answer</th>\n",
       "      <th>pred start/end</th>\n",
       "      <th>pred answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>in what city did beyonce grow up? beyonce giselle knowles - carter ( / biËËˆjÉ’nseÉª / bee - yon - say ) ( born september 4, 1981 ) is an american singer, songwriter, record producer and actress. born and raised in houston, texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of r &amp; b girl - group destiny's child. managed by her father, mathew knowles, the group became one of the world's best - selling girl groups of all time</td>\n",
       "      <td>True</td>\n",
       "      <td>(56, 57)</td>\n",
       "      <td>houston</td>\n",
       "      <td>(56, 57)</td>\n",
       "      <td>houston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>where does notre dame rank in terms of academic profile among research universities in the us? 750 miles to notre dame, making it arguably the most representative university in the united states. while all entering students begin in the college of the first year of studies, 25 % have indicated they plan to study in the liberal arts or social sciences, 24 % in engineering, 24 % in business, 24 % in science, and 3 % in architecture.</td>\n",
       "      <td>False</td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td></td>\n",
       "      <td>(0, 18)</td>\n",
       "      <td>[CLS] where does notre dame rank in terms of academic profile among research universities in the us?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, skip_special_tokens=True, max_n=2, trunc_at=500)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = learn.to_fp32()\n",
    "learn.loss_func = CrossEntropyLossFlat()\n",
    "learn.export(fname=f\"{export_name}.pkl\")\n",
    "inf_learn = load_learner(fname=f\"{export_name}.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('11', '13'),\n",
       "  [11, 13],\n",
       "  [[0.0007079543429426849,\n",
       "    8.067473231676558e-07,\n",
       "    5.534079718927387e-07,\n",
       "    8.457123499283625e-07,\n",
       "    2.8077411684535036e-07,\n",
       "    5.81091626372654e-07,\n",
       "    1.7419917242023075e-07,\n",
       "    0.0007079735514707863,\n",
       "    0.0014791766880080104,\n",
       "    6.030854274285957e-05,\n",
       "    0.000784024246968329,\n",
       "    0.9956122636795044,\n",
       "    0.00017991878848988563,\n",
       "    2.1950277186988387e-06,\n",
       "    2.5513849323033355e-05,\n",
       "    1.1336352145008277e-05,\n",
       "    0.00021909411589149386,\n",
       "    0.00010652996570570394,\n",
       "    5.1310871640453115e-06,\n",
       "    6.242764357011765e-05,\n",
       "    3.3896149034262635e-06,\n",
       "    7.3925580181821715e-06,\n",
       "    2.1699710487155244e-05,\n",
       "    1.8838925086583913e-07,\n",
       "    2.0140120682299312e-07],\n",
       "   [0.002179279224947095,\n",
       "    1.116457156058459e-06,\n",
       "    7.699113666603807e-07,\n",
       "    2.9620346708725265e-07,\n",
       "    2.592197745343583e-07,\n",
       "    3.241356694161368e-07,\n",
       "    4.4019935785399866e-07,\n",
       "    0.002180153504014015,\n",
       "    4.3814674427267164e-05,\n",
       "    8.098641046672128e-06,\n",
       "    4.62112293462269e-05,\n",
       "    8.819794857117813e-06,\n",
       "    0.0006721687968820333,\n",
       "    0.9737096428871155,\n",
       "    0.0009065067279152572,\n",
       "    0.01919969916343689,\n",
       "    0.00016524842067155987,\n",
       "    3.297585863037966e-05,\n",
       "    4.190401523374021e-05,\n",
       "    2.5468745661783032e-05,\n",
       "    0.00017964236030820757,\n",
       "    0.00031583107193000615,\n",
       "    0.000280783831840381,\n",
       "    2.2294690893431834e-07,\n",
       "    2.653206649938511e-07]]),\n",
       " (('16', '17'),\n",
       "  [16, 17],\n",
       "  [[0.09511341899633408,\n",
       "    0.0007848537061363459,\n",
       "    6.882318848511204e-05,\n",
       "    4.599778912961483e-05,\n",
       "    2.435577698634006e-05,\n",
       "    1.696581966825761e-05,\n",
       "    2.9409846320049837e-05,\n",
       "    4.8054713261080906e-05,\n",
       "    2.61699351540301e-05,\n",
       "    0.09510650485754013,\n",
       "    0.0007383231422863901,\n",
       "    0.0005699516623280942,\n",
       "    0.00026201215223409235,\n",
       "    0.0010273178340867162,\n",
       "    0.0001038041154970415,\n",
       "    0.001836049254052341,\n",
       "    0.798934280872345,\n",
       "    0.0002287096285726875,\n",
       "    8.796820475254208e-05,\n",
       "    9.486112685408443e-05,\n",
       "    3.578210453270003e-05,\n",
       "    0.0001257556868949905,\n",
       "    0.00010541949450271204,\n",
       "    0.0004523831885308027,\n",
       "    0.0041328719817101955],\n",
       "   [0.17774249613285065,\n",
       "    0.0009960610186681151,\n",
       "    0.0005124022136442363,\n",
       "    0.00026806574896909297,\n",
       "    4.266381438355893e-05,\n",
       "    4.542353781289421e-05,\n",
       "    0.00013922831567469984,\n",
       "    8.948934555519372e-05,\n",
       "    0.00011866112618008628,\n",
       "    0.17774207890033722,\n",
       "    0.0016253419453278184,\n",
       "    0.0009638823103159666,\n",
       "    0.002399894641712308,\n",
       "    0.00040112558053806424,\n",
       "    0.0008903659763745964,\n",
       "    0.0019113823072984815,\n",
       "    0.0013857381418347359,\n",
       "    0.6088471412658691,\n",
       "    0.010392600670456886,\n",
       "    0.00132531498093158,\n",
       "    0.00024904386373236775,\n",
       "    0.0006555408472195268,\n",
       "    0.0004080340440850705,\n",
       "    0.0001830809487728402,\n",
       "    0.010664992965757847]]),\n",
       " (('17', '20'),\n",
       "  [17, 20],\n",
       "  [[0.005303214769810438,\n",
       "    8.226604222727474e-06,\n",
       "    6.356154244713252e-06,\n",
       "    3.947254299419001e-06,\n",
       "    1.6088738448161166e-06,\n",
       "    6.648727776337182e-06,\n",
       "    2.327963102288777e-06,\n",
       "    0.005303670186549425,\n",
       "    0.002044239081442356,\n",
       "    0.00011705544602591544,\n",
       "    0.01870202273130417,\n",
       "    0.003897982183843851,\n",
       "    4.277818516129628e-05,\n",
       "    8.98723828868242e-06,\n",
       "    0.00035554220085032284,\n",
       "    0.0003867371124215424,\n",
       "    0.12522518634796143,\n",
       "    0.799724817276001,\n",
       "    0.002024930901825428,\n",
       "    0.036615677177906036,\n",
       "    4.2370258597657084e-05,\n",
       "    9.076434071175754e-05,\n",
       "    8.223564509535208e-05,\n",
       "    1.3544949979404919e-06,\n",
       "    1.4418496903090272e-06],\n",
       "   [0.03082464076578617,\n",
       "    9.402672731084749e-06,\n",
       "    8.072654964053072e-06,\n",
       "    4.2613642108335625e-06,\n",
       "    5.20079674970475e-06,\n",
       "    1.1645217455225065e-05,\n",
       "    5.658930604113266e-06,\n",
       "    0.030836548656225204,\n",
       "    0.0001993828045669943,\n",
       "    4.9531103286426514e-05,\n",
       "    0.00086278683738783,\n",
       "    0.0001433023571735248,\n",
       "    0.00045212722034193575,\n",
       "    0.03430855646729469,\n",
       "    0.00023580722336191684,\n",
       "    0.0025184587575495243,\n",
       "    0.00030328938737511635,\n",
       "    0.00041243163286708295,\n",
       "    0.005335287656635046,\n",
       "    0.0011092134518548846,\n",
       "    0.5307211875915527,\n",
       "    0.3416663706302643,\n",
       "    0.019968891516327858,\n",
       "    4.292681296647061e-06,\n",
       "    3.6906615150655853e-06]])]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_learn = load_learner(fname=f\"{export_name}.pkl\")\n",
    "inf_learn.loss_func = MultiTargetLoss()\n",
    "\n",
    "inf_df = pd.DataFrame.from_dict(\n",
    "    [\n",
    "        {\n",
    "            \"proc_question\": \"What did George Lucas make?\",\n",
    "            \"proc_context\": \"George Lucas created Star Wars in 1977. He directed and produced it.\",\n",
    "        },\n",
    "        {\n",
    "            \"proc_question\": \"What year did Star Wars come out?\",\n",
    "            \"proc_context\": \"George Lucas created Star Wars in 1977. He directed and produced it.\",\n",
    "        },\n",
    "        {\n",
    "            \"proc_question\": \"What did George Lucas do?\",\n",
    "            \"proc_context\": \"George Lucas created Star Wars in 1977. He directed and produced it.\",\n",
    "        },\n",
    "    ],\n",
    "    orient=\"columns\",\n",
    ")\n",
    "\n",
    "inf_learn.blurr_predict(inf_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This module includes all the low, mid, and high-level API bits for extractive Q&A tasks training and inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_utils.ipynb.\n",
      "Converted 01_data-core.ipynb.\n",
      "Converted 01_modeling-core.ipynb.\n",
      "Converted 02_data-language-modeling.ipynb.\n",
      "Converted 02_modeling-language-modeling.ipynb.\n",
      "Converted 03_data-token-classification.ipynb.\n",
      "Converted 03_modeling-token-classification.ipynb.\n",
      "Converted 04_data-question-answering.ipynb.\n",
      "Converted 04_modeling-question-answering.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import notebook2script\n",
    "\n",
    "notebook2script()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
