{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp modeling.question_answering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_slow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modeling.question_answering\n",
    "\n",
    "> This module contains custom models, loss functions, custom splitters, etc... for question answering tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import os, ast, inspect\n",
    "from typing import Any, Callable, Dict, List, Optional, Union, Type\n",
    "\n",
    "from fastcore.all import *\n",
    "from fastai.callback.all import *\n",
    "from fastai.data.block import DataBlock, CategoryBlock, ColReader, ItemGetter, ColSplitter, RandomSplitter\n",
    "from fastai.data.core import DataLoader, DataLoaders, TfmdDL\n",
    "from fastai.imports import *\n",
    "from fastai.learner import *\n",
    "from fastai.losses import CrossEntropyLossFlat\n",
    "from fastai.optimizer import Adam, OptimWrapper, params\n",
    "from fastai.torch_core import *\n",
    "from fastai.torch_imports import *\n",
    "from seqeval import metrics as seq_metrics\n",
    "from transformers import AutoModelForQuestionAnswering, PreTrainedModel, logging\n",
    "\n",
    "from blurr.utils import BLURR\n",
    "from blurr.data.core import TextBlock, BlurrDataLoader, first_blurr_tfm\n",
    "from blurr.modeling.core import BaseModelCallback, PreCalculatedLoss, Blearner\n",
    "from blurr.data.question_answering import QAPreprocessor, QATextInput, QABatchTokenizeTransform\n",
    "\n",
    "# metrics we'll use in extractive qa\n",
    "from datasets import load_metric\n",
    "squad_metric = load_metric(\"squad\")\n",
    "\n",
    "logging.set_verbosity_error()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What we're running with at the time this documentation was generated:\n",
      "torch: 1.10.1+cu111\n",
      "fastai: 2.5.3\n",
      "transformers: 4.16.2\n"
     ]
    }
   ],
   "source": [
    "# hide_input\n",
    "import pdb\n",
    "\n",
    "from datasets import load_dataset\n",
    "from fastai.data.external import untar_data, URLs\n",
    "from fastcore.test import *\n",
    "from nbverbose.showdoc import show_doc\n",
    "from transformers import AutoConfig\n",
    "\n",
    "from blurr.utils import print_versions\n",
    "from blurr.modeling.core import BaseModelWrapper, PreCalculatedLoss, blurr_splitter\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "print(\"What we're running with at the time this documentation was generated:\")\n",
    "print_versions(\"torch fastai transformers\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU #1: GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "# cuda\n",
    "torch.cuda.set_device(1)\n",
    "print(f\"Using GPU #{torch.cuda.current_device()}: {torch.cuda.get_device_name()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "We'll use a subset of `squad_v2` to demonstrate how to configure your blurr code for training extractive question answering models. See the `data.question_answering` module if any of this setting up of the `squad_df` below looks unfamiliar to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset squad (/home/wgilliam/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dac8b05e2f8741069c21cbd8e0b0c76e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200\n"
     ]
    }
   ],
   "source": [
    "raw_datasets = load_dataset(\"squad\", split=[\"train[:1000]\", \"validation[:200]\"])\n",
    "\n",
    "raw_train_df = pd.DataFrame(raw_datasets[0])\n",
    "raw_valid_df = pd.DataFrame(raw_datasets[1])\n",
    "\n",
    "raw_train_df[\"is_valid\"] = False\n",
    "raw_valid_df[\"is_valid\"] = True\n",
    "\n",
    "squad_df = pd.concat([raw_train_df, raw_valid_df])\n",
    "\n",
    "squad_df[\"ans_start_char_idx\"] = squad_df.answers.apply(lambda v: v[\"answer_start\"][0] if len(v[\"answer_start\"]) > 0 else \"0\")\n",
    "squad_df[\"answer_text\"] = squad_df.answers.apply(lambda v: v[\"text\"][0] if len(v[\"text\"]) > 0 else \"\")\n",
    "squad_df[\"ans_end_char_idx\"] = squad_df[\"ans_start_char_idx\"].astype(int) + squad_df[\"answer_text\"].str.len()\n",
    "\n",
    "print(len(squad_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cls = AutoModelForQuestionAnswering\n",
    "\n",
    "pretrained_model_name = \"bert-large-uncased-whole-word-masking-finetuned-squad\"\n",
    "hf_arch, hf_config, hf_tokenizer, hf_model = BLURR.get_hf_objects(pretrained_model_name, model_cls=model_cls)\n",
    "\n",
    "max_seq_len = 128\n",
    "vocab = dict(enumerate(range(max_seq_len)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "      <th>is_valid</th>\n",
       "      <th>ans_start_char_idx</th>\n",
       "      <th>answer_text</th>\n",
       "      <th>ans_end_char_idx</th>\n",
       "      <th>proc_question</th>\n",
       "      <th>proc_context</th>\n",
       "      <th>ans_start_token_idx</th>\n",
       "      <th>ans_end_token_idx</th>\n",
       "      <th>is_answerable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5733be284776f41900661182</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct...</td>\n",
       "      <td>To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?</td>\n",
       "      <td>{'text': ['Saint Bernadette Soubirous'], 'answer_start': [515]}</td>\n",
       "      <td>False</td>\n",
       "      <td>515</td>\n",
       "      <td>Saint Bernadette Soubirous</td>\n",
       "      <td>541</td>\n",
       "      <td>To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?</td>\n",
       "      <td>Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputed</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id                     title  \\\n",
       "0  5733be284776f41900661182  University_of_Notre_Dame   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   context  \\\n",
       "0  Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct...   \n",
       "\n",
       "                                                                  question  \\\n",
       "0  To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?   \n",
       "\n",
       "                                                           answers  is_valid  \\\n",
       "0  {'text': ['Saint Bernadette Soubirous'], 'answer_start': [515]}     False   \n",
       "\n",
       "   ans_start_char_idx                 answer_text  ans_end_char_idx  \\\n",
       "0                 515  Saint Bernadette Soubirous               541   \n",
       "\n",
       "                                                             proc_question  \\\n",
       "0  To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           proc_context  \\\n",
       "0  Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputed   \n",
       "\n",
       "   ans_start_token_idx  ans_end_token_idx  is_answerable  \n",
       "0                    0                  0          False  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor = QAPreprocessor(\n",
    "    hf_tokenizer, id_attr=\"id\", tok_kwargs={\"return_overflowing_tokens\": True, \"max_length\": max_seq_len, \"stride\": 64}\n",
    ")\n",
    "\n",
    "proc_df = preprocessor.process_df(squad_df)\n",
    "proc_df.head(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_batch_tfm = QABatchTokenizeTransform(hf_arch, hf_config, hf_tokenizer, hf_model, max_length=max_seq_len)\n",
    "\n",
    "blocks = (\n",
    "    TextBlock(batch_tokenize_tfm=before_batch_tfm, input_return_type=QATextInput),\n",
    "    CategoryBlock(vocab=vocab),\n",
    "    CategoryBlock(vocab=vocab),\n",
    ")\n",
    "\n",
    "# since its preprocessed, we include an \"text\" key with the values of our question and context\n",
    "def get_x(item):\n",
    "    return {\"text\": (item.proc_question, item.proc_context), \"id\": item.id}\n",
    "\n",
    "\n",
    "dblock = DataBlock(\n",
    "    blocks=blocks,\n",
    "    get_x=get_x,\n",
    "    get_y=[ItemGetter(\"ans_start_token_idx\"), ItemGetter(\"ans_end_token_idx\")],\n",
    "    splitter=ColSplitter(),\n",
    "    n_inp=1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = dblock.dataloaders(proc_df, bs=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,\n",
       " [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127],\n",
       " [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dls.vocab), dls.vocab[0], dls.vocab[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>found</th>\n",
       "      <th>start/end</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>which nfl team represented the afc at super bowl 50? super bowl 50 was an american football game to determine the champion of the national football league ( nfl ) for the 2015 season. the american football conference ( afc ) champion denver broncos defeated the national football conference ( nfc ) champion carolina panthers 24 â€“ 10 to earn their third super bowl title. the game was played on february 7, 2016, at levi's stadium in the san francisco bay area at santa clara, california. as this was the 50th super bowl, the league emphasized the \" golden anniversary \" with various gold - themed initiatives, as well as temporarily suspending the</td>\n",
       "      <td>True</td>\n",
       "      <td>(46, 48)</td>\n",
       "      <td>denver broncos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>which nfl team represented the afc at super bowl 50? earn their third super bowl title. the game was played on february 7, 2016, at levi's stadium in the san francisco bay area at santa clara, california. as this was the 50th super bowl, the league emphasized the \" golden anniversary \" with various gold - themed initiatives, as well as temporarily suspending the tradition of naming each super bowl game with roman numerals ( under which the game would have been known as \" super bowl l \" ), so that the logo could prominently feature the arabic numerals 50.</td>\n",
       "      <td>False</td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.valid.show_batch(dataloaders=dls, max_n=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mid-level API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `QAModelCallback`\n",
    "\n",
    "Here we create a question/answer specific subclass of `BaseModelCallback` in order to get all the start and end prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class QAModelCallback(BaseModelCallback):\n",
    "    \"\"\"The prediction is a combination start/end logits\"\"\"\n",
    "\n",
    "    def after_pred(self):\n",
    "        super().after_pred()\n",
    "        self.learn.pred = (self.pred.start_logits, self.pred.end_logits)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `QAMetricsCallback`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class QAMetricsCallback(Callback):\n",
    "    def __init__(self, compute_metrics_func, validation_ds, qa_metrics=[\"exact_match\", \"f1\"], **kwargs):\n",
    "        self.run_before = Recorder\n",
    "\n",
    "        store_attr()\n",
    "        self.custom_metrics_dict = {k: None for k in qa_metrics}\n",
    "        self.do_setup = True\n",
    "\n",
    "    def setup(self):\n",
    "        # one time setup code here.\n",
    "        if not self.do_setup:\n",
    "            return\n",
    "\n",
    "        # grab the hf_tokenizer from the TokenClassBatchTokenizeTransform\n",
    "        tfm = first_blurr_tfm(self.learn.dls, tfms=[QABatchTokenizeTransform])\n",
    "        self.hf_tokenizer = tfm.hf_tokenizer\n",
    "        self.tok_kwargs = tfm.tok_kwargs\n",
    "\n",
    "        # add custom question answering specific metrics\n",
    "        custom_metrics = L([ValueMetric(partial(self.metric_value, metric_key=k), k) for k in self.qa_metrics])\n",
    "        self.learn.metrics = self.learn.metrics + custom_metrics\n",
    "\n",
    "        self.do_setup = False\n",
    "\n",
    "    def before_fit(self):\n",
    "        self.setup()\n",
    "\n",
    "    # --- batch before/after phases ---\n",
    "    def before_batch(self):\n",
    "        if self.training or self.learn.y is None:\n",
    "            return\n",
    "\n",
    "        self.batch_inputs = {k: v.cpu().detach().numpy() if isinstance(v, Tensor) else v for k, v in self.x.items()}\n",
    "\n",
    "    def after_batch(self):\n",
    "        if self.training or self.learn.y is None:\n",
    "            return\n",
    "\n",
    "        for i in range(len(self.batch_inputs[\"input_ids\"])):\n",
    "            batch_inps = {k: self.batch_inputs[k][i] for k in self.batch_inputs.keys()}\n",
    "            self.results.append(\n",
    "                {**batch_inps, \"start_logits\": self.pred[0][i].cpu().detach().numpy(), \"end_logits\": self.pred[1][i].cpu().detach().numpy()}\n",
    "            )\n",
    "\n",
    "    # --- validation begin/after phases ---\n",
    "    def before_validate(self):\n",
    "        self.results = []\n",
    "\n",
    "    def after_validate(self):\n",
    "        if len(self.results) < 1:\n",
    "            return\n",
    "\n",
    "        metric_vals_d = self.compute_metrics_func(self.results, self.validation_ds, self.hf_tokenizer, self.tok_kwargs)\n",
    "        for k, v in metric_vals_d.items():\n",
    "            self.custom_metrics_dict[k] = v\n",
    "\n",
    "    # --- for ValueMetric metrics ---\n",
    "    def metric_value(self, metric_key):\n",
    "        return self.custom_metrics_dict[metric_key]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def compute_qa_metrics(results, dataset, hf_tokenizer, tok_kwargs, id_attr=\"id\", n_best=20):\n",
    "    # what is the max length for our inputs?\n",
    "    max_length = tok_kwargs.get(\"max_length\", hf_tokenizer.model_max_length)\n",
    "\n",
    "    # map examples to chunks indicies that are part of the\n",
    "    example_to_chunks = collections.defaultdict(list)\n",
    "    for idx, chunk in enumerate(results):\n",
    "        example_to_chunks[chunk[id_attr]].append(idx)\n",
    "\n",
    "    predicted_answers = []\n",
    "    for item_idx, item in enumerate(dataset):\n",
    "        example_id = item[id_attr]\n",
    "\n",
    "        answers = []\n",
    "        for chunk_idx in example_to_chunks[example_id]:\n",
    "            chunk = results[chunk_idx]\n",
    "            input_ids = chunk[\"input_ids\"]\n",
    "            start_logits = chunk[\"start_logits\"]\n",
    "            end_logits = chunk[\"end_logits\"]\n",
    "\n",
    "            start_indexes = np.argsort(start_logits)[-1 : -n_best - 1 : -1].tolist()\n",
    "            end_indexes = np.argsort(end_logits)[-1 : -n_best - 1 : -1].tolist()\n",
    "\n",
    "            for s_idx, start_index in enumerate(start_indexes):\n",
    "                for e_idx, end_index in enumerate(end_indexes):\n",
    "                    # Skip answers that are not fully in the context\n",
    "                    if start_index == 0 and end_index == 0:\n",
    "                        continue\n",
    "\n",
    "                    # Skip answers with a length that is either < 0 or > max_answer_length\n",
    "                    if end_index < start_index or end_index - start_index + 1 > max_length:\n",
    "                        continue\n",
    "\n",
    "                    answer = {\n",
    "                        \"text\": hf_tokenizer.decode(input_ids[start_index:end_index], skip_special_tokens=True),\n",
    "                        \"logit_score\": start_logits[start_index] + end_logits[end_index],\n",
    "                    }\n",
    "                    answers.append(answer)\n",
    "\n",
    "        # select the answer with the best score\n",
    "        if len(answers) > 0:\n",
    "            best_answer = max(answers, key=lambda x: x[\"logit_score\"])\n",
    "            predicted_answers.append({\"id\": example_id, \"prediction_text\": best_answer[\"text\"]})\n",
    "        else:\n",
    "            predicted_answers.append({\"id\": example_id, \"prediction_text\": \"\"})\n",
    "\n",
    "    ref_answers = [{\"id\": item[\"id\"], \"answers\": item[\"answers\"]} for item_idx, item in enumerate(dataset)]\n",
    "\n",
    "    metric_vals_d = squad_metric.compute(predictions=predicted_answers, references=ref_answers)\n",
    "    return metric_vals_d\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `PreCalculatedQALoss`\n",
    "\n",
    "Hugging Face question answering models will calculate the loss for you when you include both the `start_positions` and `end_positions` in the inputs dictionary.  This is done by the `QABatchTokenizeTransform` when `include_labels` = True (which is the default).  This also requires fastai developers to set their `Learner`'s loss function to the `PreCalculatedQALoss` for training to work properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class PreCalculatedQALoss(PreCalculatedLoss):\n",
    "    def __init__(self, *args, axis=-1, **kwargs): \n",
    "        super().__init__(nn.CrossEntropyLoss, *args, axis=axis, **kwargs)\n",
    "\n",
    "    def __call__(self, inp, targ, targ2, **kwargs):\n",
    "        return tensor(0.0)\n",
    "\n",
    "    def decodes(self, x):\n",
    "        return x[0].argmax(dim=self.axis), x[1].argmax(dim=self.axis)\n",
    "\n",
    "    def activation(self, x):\n",
    "        return F.softmax(x[0], dim=self.axis), F.softmax(x[1], dim=self.axis)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `MultiTargetLoss`\n",
    "\n",
    "If you want more control over the loss calculation, we provide here a custom loss function you can use in your question answering tasks.\n",
    "\n",
    "In fact, this new loss function can be used in many other multi-modal architectures, with any mix of loss functions.  For example, this can be ammended to include the `is_impossible` task, as well as the start/end token tasks in the SQUAD v2 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class MultiTargetLoss(Module):\n",
    "    \"\"\"Provides the ability to apply different loss functions to multi-modal targets/predictions\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        # The loss function for each target\n",
    "        loss_classes: List[Callable] = [CrossEntropyLossFlat, CrossEntropyLossFlat],\n",
    "        # Any kwargs you want to pass to the loss functions above\n",
    "        loss_classes_kwargs: List[dict] = [{}, {}],\n",
    "        # The weights you want to apply to each loss (default: [1,1])\n",
    "        weights: Union[List[float], List[int]] = [1, 1],\n",
    "        # The `reduction` parameter of the lass function (default: 'mean')\n",
    "        reduction: str = \"mean\",\n",
    "    ):\n",
    "        loss_funcs = [cls(reduction=reduction, **kwargs) for cls, kwargs in zip(loss_classes, loss_classes_kwargs)]\n",
    "        store_attr(self=self, names=\"loss_funcs, weights\")\n",
    "        self._reduction = reduction\n",
    "\n",
    "    # custom loss function must have either a reduction attribute or a reduction argument (like all fastai and\n",
    "    # PyTorch loss functions) so that the framework can change this as needed (e.g., when doing lear.get_preds\n",
    "    # it will set = 'none'). see this forum topic for more info: https://bit.ly/3br2Syz\n",
    "    @property\n",
    "    def reduction(self):\n",
    "        return self._reduction\n",
    "\n",
    "    @reduction.setter\n",
    "    def reduction(self, v):\n",
    "        self._reduction = v\n",
    "        for lf in self.loss_funcs:\n",
    "            lf.reduction = v\n",
    "\n",
    "    def forward(self, outputs, *targets):\n",
    "        loss = 0.0\n",
    "        for i, loss_func, weights, output, target in zip(range(len(outputs)), self.loss_funcs, self.weights, outputs, targets):\n",
    "            loss += weights * loss_func(output, target)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def activation(self, outs):\n",
    "        acts = [self.loss_funcs[i].activation(o) for i, o in enumerate(outs)]\n",
    "        return acts\n",
    "\n",
    "    def decodes(self, outs):\n",
    "        decodes = [self.loss_funcs[i].decodes(o) for i, o in enumerate(outs)]\n",
    "        return decodes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example\n",
    "\n",
    "Notice below how I had to define the loss function *after* creating the `Learner` object.  I'm not sure why, but the `MultiTargetLoss` above prohibits the learner from being exported if I do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BaseModelWrapper(hf_model)\n",
    "learn_cbs = [QAModelCallback]\n",
    "\n",
    "validation_ds = proc_df[proc_df.is_valid == True].to_dict(orient=\"records\")\n",
    "fit_cbs = [QAMetricsCallback(compute_metrics_func=compute_qa_metrics, validation_ds=validation_ds)]\n",
    "\n",
    "learn = Learner(dls, model, opt_func=partial(Adam), cbs=learn_cbs, splitter=blurr_splitter)\n",
    "\n",
    "learn.loss_func = PreCalculatedQALoss() #MultiTargetLoss()\n",
    "learn.create_opt()  # -> will create your layer groups based on your \"splitter\" function\n",
    "learn.freeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide_output\n",
    "# learn.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(len(learn.opt.param_groups))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(minimum=0.003981071710586548, steep=1.5848931980144698e-06, valley=0.0010000000474974513, slide=0.001737800776027143)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find(suggest_funcs=[minimum, steep, valley, slide])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>exact_match</th>\n",
       "      <th>f1</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.554987</td>\n",
       "      <td>0.954001</td>\n",
       "      <td>71.803279</td>\n",
       "      <td>81.094988</td>\n",
       "      <td>01:29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, lr_max=1e-3, cbs=fit_cbs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Showing results\n",
    "\n",
    "And here we create a `@typedispatch`ed implementation of `Learner.show_results` for a more intuitive QA task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@typedispatch\n",
    "def show_results(\n",
    "    # This typedispatched `show_results` will be called for `QuestionAnswerTextInput` typed inputs\n",
    "    x: QATextInput,\n",
    "    # The targets\n",
    "    y,\n",
    "    # Your raw inputs/targets\n",
    "    samples,\n",
    "    # The model's predictions\n",
    "    outs,\n",
    "    # Your `Learner`. This is required so as to get at the Hugging Face objects for decoding them into\n",
    "    # something understandable\n",
    "    learner,\n",
    "    # Whether you want to remove special tokens during decoding/showing the outputs\n",
    "    skip_special_tokens=True,\n",
    "    # Your `show_results` context\n",
    "    ctxs=None,\n",
    "    # The maximum number of items to show\n",
    "    max_n=6,\n",
    "    # Any truncation your want applied to your decoded inputs\n",
    "    trunc_at=None,\n",
    "    # Any other keyword arguments you want applied to `show_results`\n",
    "    **kwargs\n",
    "):\n",
    "    tfm = first_blurr_tfm(learner.dls, tfms=[QABatchTokenizeTransform])\n",
    "    hf_tokenizer = tfm.hf_tokenizer\n",
    "\n",
    "    res = L()\n",
    "    for sample, input_ids, start, end, pred in zip(samples, x, *y, outs):\n",
    "        txt = hf_tokenizer.decode(sample[0], skip_special_tokens=True)[:trunc_at]\n",
    "        found = start.item() != 0 and end.item() != 0\n",
    "        ans_text = hf_tokenizer.decode(input_ids[start:end], skip_special_tokens=False)\n",
    "\n",
    "        pred_ans_toks = hf_tokenizer.convert_ids_to_tokens(input_ids, skip_special_tokens=False)[int(pred[0]) : int(pred[1])]\n",
    "        pred_ans_txt = hf_tokenizer.convert_tokens_to_string(pred_ans_toks)\n",
    "\n",
    "        res.append((txt, found, (start.item(), end.item()), ans_text, (int(pred[0]), int(pred[1])), pred_ans_txt))\n",
    "\n",
    "    display_df(pd.DataFrame(res, columns=[\"text\", \"found\", \"start/end\", \"answer\", \"pred start/end\", \"pred answer\"]))\n",
    "    return ctxs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>found</th>\n",
       "      <th>start/end</th>\n",
       "      <th>answer</th>\n",
       "      <th>pred start/end</th>\n",
       "      <th>pred answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>which nfl team represented the afc at super bowl 50? super bowl 50 was an american football game to determine the champion of the national football league ( nfl ) for the 2015 season. the american football conference ( afc ) champion denver broncos defeated the national football conference ( nfc ) champion carolina panthers 24 â€“ 10 to earn their third super bowl title. the game was played on february 7, 2016, at levi's stadium in the san francisco bay area at santa clara, california. as this was</td>\n",
       "      <td>True</td>\n",
       "      <td>(46, 48)</td>\n",
       "      <td>denver broncos</td>\n",
       "      <td>(46, 48)</td>\n",
       "      <td>denver broncos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>who did denver beat in the 2015 afc championship game? the panthers finished the regular season with a 15 â€“ 1 record, and quarterback cam newton was named the nfl most valuable player ( mvp ). they defeated the arizona cardinals 49 â€“ 15 in the nfc championship game and advanced to their second super bowl appearance since the franchise was founded in 1995. the broncos finished the regular season with a 12 â€“ 4 record, and denied the new england patriots a chance to defend their title from super bo</td>\n",
       "      <td>True</td>\n",
       "      <td>(86, 89)</td>\n",
       "      <td>new england patriots</td>\n",
       "      <td>(86, 89)</td>\n",
       "      <td>new england patriots</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>when did levi's stadium open to the public? on may 21, 2013, nfl owners at their spring meetings in boston voted and awarded the game to levi's stadium. the $ 1. 2 billion stadium opened in 2014. it is the first super bowl held in the san francisco bay area since super bowl xix in 1985, and the first in california since super bowl xxxvii took place in san diego in 2003.</td>\n",
       "      <td>True</td>\n",
       "      <td>(47, 48)</td>\n",
       "      <td>2014</td>\n",
       "      <td>(47, 48)</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>when was the last time san francisco hosted a super bowl? the league announced on october 16, 2012, that the two finalists were sun life stadium and levi's stadium. the south florida / miami area has previously hosted the event 10 times ( tied for most with new orleans ), with the most recent one being super bowl xliv in 2010. the san francisco bay area last hosted in 1985 ( super bowl xix ), held at stanford stadium in stanford, california, won by the home team 49ers. the miami bid depended on</td>\n",
       "      <td>True</td>\n",
       "      <td>(80, 81)</td>\n",
       "      <td>1985</td>\n",
       "      <td>(80, 81)</td>\n",
       "      <td>1985</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, skip_special_tokens=True, max_n=4, trunc_at=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>exact_match</th>\n",
       "      <th>f1</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.477511</td>\n",
       "      <td>0.953044</td>\n",
       "      <td>71.803279</td>\n",
       "      <td>81.094988</td>\n",
       "      <td>03:13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, lr_max=slice(1e-9, 1e-7), cbs=fit_cbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.recorder.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>found</th>\n",
       "      <th>start/end</th>\n",
       "      <th>answer</th>\n",
       "      <th>pred start/end</th>\n",
       "      <th>pred answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>which nfl team represented the afc at super bowl 50? super bowl 50 was an american football game to</td>\n",
       "      <td>True</td>\n",
       "      <td>(46, 48)</td>\n",
       "      <td>denver broncos</td>\n",
       "      <td>(46, 48)</td>\n",
       "      <td>denver broncos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>who was the 2015 nfl mvp? the panthers finished the regular season with a 15 â€“ 1 record, and quarter</td>\n",
       "      <td>True</td>\n",
       "      <td>(24, 26)</td>\n",
       "      <td>cam newton</td>\n",
       "      <td>(24, 26)</td>\n",
       "      <td>cam newton</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, max_n=2, trunc_at=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction\n",
    "\n",
    "Note that there is a bug currently in fastai v2 (or with how I'm assembling everything) that currently prevents us from seeing the decoded predictions and probabilities for the \"end\" token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@patch\n",
    "def blurr_predict_answers(\n",
    "    self: Learner,\n",
    "    # The str (or list of strings) you want to get token classification predictions for\n",
    "    question_contexts: Union[dict, List[dict]],\n",
    "    # If using a slow tokenizer, users will need to prove a `slow_word_ids_func` that accepts a\n",
    "    # tokenizzer, example index, and a batch encoding as arguments and in turn returnes the\n",
    "    # equavlient of fast tokenizer's `word_ids``\n",
    "    slow_word_ids_func: Optional[Callable] = None,\n",
    "):\n",
    "    if not is_listy(question_contexts):\n",
    "        question_contexts = [question_contexts]\n",
    "\n",
    "    tfm = first_blurr_tfm(self.dls, tfms=[QABatchTokenizeTransform])\n",
    "    hf_tokenizer = tfm.hf_tokenizer\n",
    "    tok_kwargs = tfm.tok_kwargs\n",
    "    tok_kwargs[\"truncation\"] = \"only_second\" if hf_tokenizer.padding_side == \"right\" else \"only_first\"\n",
    "\n",
    "    results = []\n",
    "    for qc in question_contexts:\n",
    "        inps = [qc[\"question\"], qc[\"context\"]] if hf_tokenizer.padding_side == \"right\" else [qc[\"context\"], qc[\"question\"]]\n",
    "\n",
    "        inputs = hf_tokenizer(*inps, max_length=tfm.max_length, padding=tfm.padding, return_tensors=\"pt\", **tok_kwargs)\n",
    "        inputs_offsets = inputs[\"offset_mapping\"]\n",
    "        inputs_input_ids = inputs[\"input_ids\"]\n",
    "\n",
    "        # run inputs through model\n",
    "        model_inputs = {k: v.to(self.model.hf_model.device) for k, v in inputs.items()}\n",
    "        outputs = self.model(model_inputs)\n",
    "\n",
    "        # fetch start/end token indicies probabilities and predictions\n",
    "        start_prob = F.softmax(outputs.start_logits[0], dim=-1).tolist()\n",
    "        start_pred = outputs.start_logits[0].argmax(dim=-1).tolist()\n",
    "        start_char_idx = inputs_offsets[0][start_pred][0]\n",
    "\n",
    "        end_prob = F.softmax(outputs.end_logits[0], dim=-1).tolist()\n",
    "        end_pred = outputs.end_logits[0].argmax(dim=-1).tolist()\n",
    "        end_char_idx = inputs_offsets[0][end_pred-1][1]\n",
    "\n",
    "        if start_pred != 0 and end_pred != 0:\n",
    "            results.append(\n",
    "                {\n",
    "                    \"answer\": inps[1][start_char_idx : end_char_idx].strip(),\n",
    "                    \"start\": start_char_idx.item(),\n",
    "                    \"end\": end_char_idx.item(),\n",
    "                    \"score\": start_prob[start_pred] * end_prob[end_pred],\n",
    "                }\n",
    "            )\n",
    "        else:\n",
    "            results.append(\n",
    "                {\n",
    "                    \"answer\": None,\n",
    "                    \"start\": start_char_idx.item(),\n",
    "                    \"end\": end_char_idx.item(),\n",
    "                    \"score\": start_prob[start_pred] * end_prob[end_pred],\n",
    "                }\n",
    "            )\n",
    "\n",
    "    # build our results\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'answer': 'Star Wars', 'start': 21, 'end': 30, 'score': 0.9424959541192663}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = \"George Lucas created Star Wars in 1977. He directed and produced it.\"\n",
    "\n",
    "learn.blurr_predict_answers({\"question\": \"What did George Lucas make?\", \"context\": context})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'answer': 'Star Wars', 'start': 21, 'end': 30, 'score': 0.9424959541192663},\n",
       " {'answer': '1977', 'start': 34, 'end': 38, 'score': 0.9323056461264194},\n",
       " {'answer': 'directed and produced it',\n",
       "  'start': 43,\n",
       "  'end': 67,\n",
       "  'score': 0.23746131206370258},\n",
       " {'answer': None, 'start': 0, 'end': 0, 'score': 0.5251253261423976}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = \"George Lucas created Star Wars in 1977. He directed and produced it.\"\n",
    "\n",
    "learn.blurr_predict_answers([\n",
    "    {\"question\": \"What did George Lucas make?\", \"context\": context},\n",
    "    {\"question\": \"What year did Star Wars come out?\", \"context\": context},\n",
    "    {\"question\": \"What did George Lucas do?\", \"context\": context},\n",
    "    {\"question\": \"Who plays Spock in the movie?\", \"context\": context},\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference\n",
    "\n",
    "Note that I had to replace the loss function because of the above-mentioned issue to exporting the model with the `MultiTargetLoss` loss function.  After getting our inference learner, we put it back and we're good to go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_name = \"q_and_a_learn_export\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.loss_func = CrossEntropyLossFlat()\n",
    "learn.export(fname=f\"{export_name}.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'answer': 'Star Wars', 'start': 21, 'end': 30, 'score': 0.9424960787919971},\n",
       " {'answer': '1977', 'start': 34, 'end': 38, 'score': 0.9323058763707586},\n",
       " {'answer': 'directed and produced it',\n",
       "  'start': 43,\n",
       "  'end': 67,\n",
       "  'score': 0.23746180792768712},\n",
       " {'answer': None, 'start': 0, 'end': 0, 'score': 0.5251238122266955}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_learn = load_learner(fname=f\"{export_name}.pkl\")\n",
    "inf_learn.loss_func = MultiTargetLoss()\n",
    "\n",
    "context = \"George Lucas created Star Wars in 1977. He directed and produced it.\"\n",
    "\n",
    "inf_learn.blurr_predict_answers([\n",
    "    {\"question\": \"What did George Lucas make?\", \"context\": context},\n",
    "    {\"question\": \"What year did Star Wars come out?\", \"context\": context},\n",
    "    {\"question\": \"What did George Lucas do?\", \"context\": context},\n",
    "    {\"question\": \"Who plays Spock in the movie?\", \"context\": context},\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "try:\n",
    "    del learn\n",
    "    del inf_learn\n",
    "    torch.cuda.empty_cache()\n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The High-level API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `BLearnerForQuestionAnswering`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@delegates(Blearner.__init__)\n",
    "class BlearnerForQuestionAnswering(Blearner):\n",
    "    def __init__(self, dls: DataLoaders, hf_model: PreTrainedModel, **kwargs):\n",
    "        kwargs[\"loss_func\"] = kwargs.get(\"loss_func\", PreCalculatedQALoss())\n",
    "        super().__init__(dls, hf_model, base_model_cb=QAModelCallback, **kwargs)\n",
    "\n",
    "    @classmethod\n",
    "    def get_model_cls(self):\n",
    "        return AutoModelForQuestionAnswering\n",
    "\n",
    "    @classmethod\n",
    "    def _get_x(cls, x, qst, ctx, padding_side=\"right\"):\n",
    "        return (x[qst], x[ctx]) if (padding_side == \"right\") else (x[ctx], x[qst])\n",
    "\n",
    "    @classmethod\n",
    "    def _create_learner(\n",
    "        cls,\n",
    "        # Your raw dataset\n",
    "        data,\n",
    "        # The name or path of the pretrained model you want to fine-tune\n",
    "        pretrained_model_name_or_path: Optional[Union[str, os.PathLike]],\n",
    "        # The maximum sequence length to constrain our data\n",
    "        max_seq_len: int = None,\n",
    "        # The attribute in your dataset that contains the context (where the answer is included) (default: 'context')\n",
    "        context_attr: str = \"context\",\n",
    "        # The attribute in your dataset that contains the question being asked (default: 'question')\n",
    "        question_attr: str = \"question\",\n",
    "        # The attribute in your dataset that contains the actual answer (default: 'answer_text')\n",
    "        answer_text_attr: str = \"answer_text\",\n",
    "        # The attribute in your dataset that contains the tokenized answer start (default: 'tok_answer_start')\n",
    "        tok_ans_start_attr: str = \"ans_start_token_idx\",\n",
    "        # The attribute in your dataset that contains the tokenized answer end(default: 'tok_answer_end')\n",
    "        tok_ans_end_attr: str = \"ans_end_token_idx\",\n",
    "        # A function that will split your Dataset into a training and validation set\n",
    "        # See [here](https://docs.fast.ai/data.transforms.html#Split) for a list of fast.ai splitters\n",
    "        dblock_splitter: Callable = RandomSplitter(),\n",
    "        # Any kwargs to pass to your `DataLoaders`\n",
    "        dl_kwargs={},\n",
    "        # Any kwargs to pass to your task specific `Blearner`\n",
    "        learner_kwargs={},\n",
    "    ):\n",
    "        hf_arch, hf_config, hf_tokenizer, hf_model = BLURR.get_hf_objects(pretrained_model_name_or_path, model_cls=cls.get_model_cls())\n",
    "\n",
    "        # potentially used by our preprocess_func, it is the basis for our CategoryBlock vocab\n",
    "        if max_seq_len is None:\n",
    "            max_seq_len = hf_config.get(\"max_position_embeddings\", 128)\n",
    "\n",
    "        # bits required by our \"before_batch_tfm\" and DataBlock\n",
    "        vocab = list(range(max_seq_len))\n",
    "        padding_side = hf_tokenizer.padding_side\n",
    "        trunc_strat = \"only_second\" if (padding_side == \"right\") else \"only_first\"\n",
    "\n",
    "        before_batch_tfm = QABatchTokenizeTransform(\n",
    "            hf_arch, hf_config, hf_tokenizer, hf_model, max_length=max_seq_len, truncation=trunc_strat\n",
    "        )\n",
    "\n",
    "        # define getters\n",
    "        if isinstance(data, pd.DataFrame):\n",
    "            get_x = partial(cls._get_x, qst=question_attr, ctx=context_attr, padding_side=padding_side)\n",
    "            get_y = [ColReader(tok_ans_start_attr), ColReader(tok_ans_end_attr)]\n",
    "        else:\n",
    "            get_x = partial(cls._get_x, qst=question_attr, ctx=context_attr, padding_side=padding_side)\n",
    "            get_y = [ItemGetter(tok_ans_start_attr), ItemGetter(tok_ans_end_attr)]\n",
    "\n",
    "        # define DataBlock and DataLoaders\n",
    "        blocks = (\n",
    "            TextBlock(batch_tokenize_tfm=before_batch_tfm, input_return_type=QATextInput),\n",
    "            CategoryBlock(vocab=vocab),\n",
    "            CategoryBlock(vocab=vocab),\n",
    "        )\n",
    "\n",
    "        dblock = DataBlock(blocks=blocks, get_x=get_x, get_y=get_y, splitter=dblock_splitter, n_inp=1)\n",
    "\n",
    "        dls = dblock.dataloaders(data, **dl_kwargs.copy())\n",
    "\n",
    "        # return BLearner instance\n",
    "        return cls(dls, hf_model, **learner_kwargs.copy())\n",
    "\n",
    "    @classmethod\n",
    "    def from_dataframe(\n",
    "        cls,\n",
    "        # Your pandas DataFrame\n",
    "        df: pd.DataFrame,\n",
    "        # The name or path of the pretrained model you want to fine-tune\n",
    "        pretrained_model_name_or_path: Optional[Union[str, os.PathLike]],\n",
    "        # The maximum sequence length to constrain our data\n",
    "        max_seq_len: int = None,\n",
    "        # The attribute in your dataset that contains the context (where the answer is included) (default: 'context')\n",
    "        context_attr: str = \"context\",\n",
    "        # The attribute in your dataset that contains the question being asked (default: 'question')\n",
    "        question_attr: str = \"question\",\n",
    "        # The attribute in your dataset that contains the actual answer (default: 'answer_text')\n",
    "        answer_text_attr: str = \"answer_text\",\n",
    "        # The attribute in your dataset that contains the tokenized answer start (default: 'tok_answer_start')\n",
    "        tok_ans_start_attr: str = \"ans_start_token_idx\",\n",
    "        # The attribute in your dataset that contains the tokenized answer end(default: 'tok_answer_end')\n",
    "        tok_ans_end_attr: str = \"ans_end_token_idx\",\n",
    "        # A function that will split your Dataset into a training and validation set\n",
    "        # See [here](https://docs.fast.ai/data.transforms.html#Split) for a list of fast.ai splitters\n",
    "        dblock_splitter: Callable = ColSplitter(),\n",
    "        # Any kwargs to pass to your `DataLoaders`\n",
    "        dl_kwargs={},\n",
    "        # Any kwargs to pass to your task specific `Blearner`\n",
    "        learner_kwargs={},\n",
    "    ):\n",
    "        return cls._create_learner(\n",
    "            df,\n",
    "            pretrained_model_name_or_path,\n",
    "            max_seq_len,\n",
    "            context_attr,\n",
    "            question_attr,\n",
    "            answer_text_attr,\n",
    "            tok_ans_start_attr,\n",
    "            tok_ans_end_attr,\n",
    "            dblock_splitter,\n",
    "            dl_kwargs,\n",
    "            learner_kwargs,\n",
    "        )\n",
    "\n",
    "    @classmethod\n",
    "    def from_csv(\n",
    "        cls,\n",
    "        # The path to your csv file\n",
    "        csv_file: Union[Path, str],\n",
    "        # The name or path of the pretrained model you want to fine-tune\n",
    "        pretrained_model_name_or_path: Optional[Union[str, os.PathLike]],\n",
    "        # The maximum sequence length to constrain our data\n",
    "        max_seq_len: int = None,\n",
    "        # The attribute in your dataset that contains the context (where the answer is included) (default: 'context')\n",
    "        context_attr: str = \"context\",\n",
    "        # The attribute in your dataset that contains the question being asked (default: 'question')\n",
    "        question_attr: str = \"question\",\n",
    "        # The attribute in your dataset that contains the actual answer (default: 'answer_text')\n",
    "        answer_text_attr: str = \"answer_text\",\n",
    "        # The attribute in your dataset that contains the tokenized answer start (default: 'tok_answer_start')\n",
    "        tok_ans_start_attr: str = \"ans_start_token_idx\",\n",
    "        # The attribute in your dataset that contains the tokenized answer end(default: 'tok_answer_end')\n",
    "        tok_ans_end_attr: str = \"ans_end_token_idx\",\n",
    "        # A function that will split your Dataset into a training and validation set\n",
    "        # See [here](https://docs.fast.ai/data.transforms.html#Split) for a list of fast.ai splitters\n",
    "        dblock_splitter: Callable = ColSplitter(),\n",
    "        # Any kwargs to pass to your `DataLoaders`\n",
    "        dl_kwargs={},\n",
    "        # Any kwargs to pass to your task specific `Blearner`\n",
    "        learner_kwargs={},\n",
    "    ):\n",
    "        df = pd.read_csv(csv_file)\n",
    "\n",
    "        return cls.from_dataframe(\n",
    "            df,\n",
    "            pretrained_model_name_or_path,\n",
    "            max_seq_len,\n",
    "            context_attr,\n",
    "            question_attr,\n",
    "            answer_text_attr,\n",
    "            tok_ans_start_attr,\n",
    "            tok_ans_end_attr,\n",
    "            dblock_splitter,\n",
    "            dl_kwargs,\n",
    "            learner_kwargs,\n",
    "        )\n",
    "\n",
    "    @classmethod\n",
    "    def from_dictionaries(\n",
    "        cls,\n",
    "        # A list of dictionaries\n",
    "        ds: List[Dict],\n",
    "        # The name or path of the pretrained model you want to fine-tune\n",
    "        pretrained_model_name_or_path: Optional[Union[str, os.PathLike]],\n",
    "        # The maximum sequence length to constrain our data\n",
    "        max_seq_len: int = None,\n",
    "        # The attribute in your dataset that contains the context (where the answer is included) (default: 'context')\n",
    "        context_attr: str = \"context\",\n",
    "        # The attribute in your dataset that contains the question being asked (default: 'question')\n",
    "        question_attr: str = \"question\",\n",
    "        # The attribute in your dataset that contains the actual answer (default: 'answer_text')\n",
    "        answer_text_attr: str = \"answer_text\",\n",
    "        # The attribute in your dataset that contains the tokenized answer start (default: 'tok_answer_start')\n",
    "        tok_ans_start_attr: str = \"tok_answer_start\",\n",
    "        # The attribute in your dataset that contains the tokenized answer end(default: 'tok_answer_end')\n",
    "        tok_ans_end_attr: str = \"tok_answer_end\",\n",
    "        # A function that will split your Dataset into a training and validation set\n",
    "        # See [here](https://docs.fast.ai/data.transforms.html#Split) for a list of fast.ai splitters\n",
    "        dblock_splitter: Callable = RandomSplitter(),\n",
    "        # Any kwargs to pass to your `DataLoaders`\n",
    "        dl_kwargs={},\n",
    "        # Any kwargs to pass to your task specific `Blearner`\n",
    "        learner_kwargs={},\n",
    "    ):\n",
    "        return cls._create_learner(\n",
    "            ds,\n",
    "            pretrained_model_name_or_path,\n",
    "            max_seq_len,\n",
    "            context_attr,\n",
    "            question_attr,\n",
    "            answer_text_attr,\n",
    "            tok_ans_start_attr,\n",
    "            tok_ans_end_attr,\n",
    "            dblock_splitter,\n",
    "            dl_kwargs,\n",
    "            learner_kwargs,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example\n",
    "\n",
    "`BLearnerForQuestionAnswering` requires a question, context (within which to find the answer to the question), and the start/end indices of where the answer lies in the *tokenized context*. Because those indices vary by tokenizer, we can pass a `preprocess_func` that will take our raw data, perform any preprocessing we want, and return it in a way that will work for extractive QA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build our training and validation DataFrames\n",
    "raw_datasets = load_dataset(\"squad\", split=[\"train[:1000]\", \"validation[:200]\"])\n",
    "\n",
    "raw_train_df = pd.DataFrame(raw_datasets[0])\n",
    "raw_valid_df = pd.DataFrame(raw_datasets[1])\n",
    "\n",
    "raw_train_df[\"is_valid\"] = False\n",
    "raw_valid_df[\"is_valid\"] = True\n",
    "\n",
    "# concatenate into a single DataFrame\n",
    "squad_df = pd.concat([raw_train_df, raw_valid_df])\n",
    "\n",
    "# include the required start/end character indicies and full text of the answer\n",
    "squad_df[\"ans_start_char_idx\"] = squad_df.answers.apply(lambda v: v[\"answer_start\"][0] if len(v[\"answer_start\"]) > 0 else \"0\")\n",
    "squad_df[\"answer_text\"] = squad_df.answers.apply(lambda v: v[\"text\"][0] if len(v[\"text\"]) > 0 else \"\")\n",
    "squad_df[\"ans_end_char_idx\"] = squad_df[\"ans_start_char_idx\"].astype(int) + squad_df[\"answer_text\"].str.len()\n",
    "\n",
    "# run our modified DataFrame thru the QAPreprocessor to get the start/end \"token\" indices we want to predict\n",
    "preprocessor = QAPreprocessor(\n",
    "    hf_tokenizer, id_attr=\"id\", tok_kwargs={\"return_overflowing_tokens\": True, \"max_length\": max_seq_len, \"stride\": 64}\n",
    ")\n",
    "\n",
    "proc_df = preprocessor.process_df(squad_df)\n",
    "proc_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define your `Blearner`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model_name = \"bert-large-uncased-whole-word-masking-finetuned-squad\"\n",
    "\n",
    "learn = BlearnerForQuestionAnswering.from_dataframe(\n",
    "    proc_df,\n",
    "    pretrained_model_name,\n",
    "    question_attr=\"proc_question\",\n",
    "    context_attr=\"proc_context\",\n",
    "    max_seq_len=128,\n",
    "    dblock_splitter=RandomSplitter(),\n",
    "    dl_kwargs={\"bs\": 4},\n",
    ").to_fp16()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.dls.show_batch(dataloaders=learn.dls, max_n=4, trunc_at=500)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(3, lr_max=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.show_results(learner=learn, skip_special_tokens=True, max_n=2, trunc_at=500)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = learn.to_fp32()\n",
    "learn.loss_func = CrossEntropyLossFlat()\n",
    "learn.export(fname=f\"{export_name}.pkl\")\n",
    "inf_learn = load_learner(fname=f\"{export_name}.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_learn = load_learner(fname=f\"{export_name}.pkl\")\n",
    "inf_learn.loss_func = MultiTargetLoss()\n",
    "\n",
    "inf_df = pd.DataFrame.from_dict(\n",
    "    [\n",
    "        {\n",
    "            \"proc_question\": \"What did George Lucas make?\",\n",
    "            \"proc_context\": \"George Lucas created Star Wars in 1977. He directed and produced it.\",\n",
    "        },\n",
    "        {\n",
    "            \"proc_question\": \"What year did Star Wars come out?\",\n",
    "            \"proc_context\": \"George Lucas created Star Wars in 1977. He directed and produced it.\",\n",
    "        },\n",
    "        {\n",
    "            \"proc_question\": \"What did George Lucas do?\",\n",
    "            \"proc_context\": \"George Lucas created Star Wars in 1977. He directed and produced it.\",\n",
    "        },\n",
    "    ],\n",
    "    orient=\"columns\",\n",
    ")\n",
    "\n",
    "inf_learn.blurr_predict(inf_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This module includes all the low, mid, and high-level API bits for extractive Q&A tasks training and inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.export import notebook2script\n",
    "\n",
    "notebook2script()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
