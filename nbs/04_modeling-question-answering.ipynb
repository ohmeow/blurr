{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp modeling.question_answering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_slow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modeling.question_answering\n",
    "\n",
    "> This module contains custom models, loss functions, custom splitters, etc... for question answering tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import os, ast, inspect\n",
    "from typing import Any, Callable, Dict, List, Optional, Union, Type\n",
    "\n",
    "from fastcore.all import *\n",
    "from fastai.callback.all import *\n",
    "from fastai.data.block import DataBlock, CategoryBlock, ColReader, ItemGetter, ColSplitter, RandomSplitter\n",
    "from fastai.data.core import DataLoader, DataLoaders, TfmdDL\n",
    "from fastai.imports import *\n",
    "from fastai.learner import *\n",
    "from fastai.losses import CrossEntropyLossFlat\n",
    "from fastai.optimizer import Adam, OptimWrapper, params\n",
    "from fastai.torch_core import *\n",
    "from fastai.torch_imports import *\n",
    "from fastprogress.fastprogress import progress_bar, master_bar\n",
    "from seqeval import metrics as seq_metrics\n",
    "from transformers import AutoModelForQuestionAnswering, logging, PretrainedConfig, PreTrainedTokenizerBase, PreTrainedModel\n",
    "\n",
    "from blurr.utils import BLURR\n",
    "from blurr.data.core import TextBlock, BlurrDataLoader, first_blurr_tfm\n",
    "from blurr.modeling.core import BaseModelCallback, PreCalculatedLoss, Blearner\n",
    "from blurr.data.question_answering import QAPreprocessor, QATextInput, QABatchTokenizeTransform\n",
    "\n",
    "# metrics we'll use in extractive qa\n",
    "from datasets import load_metric\n",
    "squad_metric = load_metric(\"squad\")\n",
    "\n",
    "logging.set_verbosity_error()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What we're running with at the time this documentation was generated:\n",
      "torch: 1.10.1+cu111\n",
      "fastai: 2.5.3\n",
      "transformers: 4.16.2\n"
     ]
    }
   ],
   "source": [
    "# hide_input\n",
    "import pdb\n",
    "\n",
    "from datasets import load_dataset\n",
    "from fastai.data.external import untar_data, URLs\n",
    "from fastcore.test import *\n",
    "from nbverbose.showdoc import show_doc\n",
    "from transformers import AutoConfig\n",
    "\n",
    "from blurr.utils import print_versions\n",
    "from blurr.modeling.core import BaseModelWrapper, PreCalculatedLoss, blurr_splitter\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "print(\"What we're running with at the time this documentation was generated:\")\n",
    "print_versions(\"torch fastai transformers\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU #1: GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "# cuda\n",
    "torch.cuda.set_device(1)\n",
    "print(f\"Using GPU #{torch.cuda.current_device()}: {torch.cuda.get_device_name()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "We'll use a subset of `squad_v2` to demonstrate how to configure your blurr code for training extractive question answering models. See the `data.question_answering` module if any of this setting up of the `squad_df` below looks unfamiliar to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset squad (/home/wgilliam/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92807b268bbe4790b6f54d929b385b39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200\n"
     ]
    }
   ],
   "source": [
    "raw_datasets = load_dataset(\"squad\", split=[\"train[:1000]\", \"validation[:200]\"])\n",
    "\n",
    "raw_train_df = pd.DataFrame(raw_datasets[0])\n",
    "raw_valid_df = pd.DataFrame(raw_datasets[1])\n",
    "\n",
    "raw_train_df[\"is_valid\"] = False\n",
    "raw_valid_df[\"is_valid\"] = True\n",
    "\n",
    "squad_df = pd.concat([raw_train_df, raw_valid_df])\n",
    "\n",
    "squad_df[\"ans_start_char_idx\"] = squad_df.answers.apply(lambda v: v[\"answer_start\"][0] if len(v[\"answer_start\"]) > 0 else \"0\")\n",
    "squad_df[\"answer_text\"] = squad_df.answers.apply(lambda v: v[\"text\"][0] if len(v[\"text\"]) > 0 else \"\")\n",
    "squad_df[\"ans_end_char_idx\"] = squad_df[\"ans_start_char_idx\"].astype(int) + squad_df[\"answer_text\"].str.len()\n",
    "\n",
    "print(len(squad_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cls = AutoModelForQuestionAnswering\n",
    "\n",
    "pretrained_model_name = \"bert-large-uncased-whole-word-masking-finetuned-squad\"\n",
    "hf_arch, hf_config, hf_tokenizer, hf_model = BLURR.get_hf_objects(pretrained_model_name, model_cls=model_cls)\n",
    "\n",
    "max_seq_len = 128\n",
    "vocab = dict(enumerate(range(max_seq_len)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "      <th>is_valid</th>\n",
       "      <th>ans_start_char_idx</th>\n",
       "      <th>answer_text</th>\n",
       "      <th>ans_end_char_idx</th>\n",
       "      <th>proc_question</th>\n",
       "      <th>proc_context</th>\n",
       "      <th>ans_start_token_idx</th>\n",
       "      <th>ans_end_token_idx</th>\n",
       "      <th>is_answerable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5733be284776f41900661182</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct...</td>\n",
       "      <td>To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?</td>\n",
       "      <td>{'text': ['Saint Bernadette Soubirous'], 'answer_start': [515]}</td>\n",
       "      <td>False</td>\n",
       "      <td>515</td>\n",
       "      <td>Saint Bernadette Soubirous</td>\n",
       "      <td>541</td>\n",
       "      <td>To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?</td>\n",
       "      <td>Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputed</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id                     title  \\\n",
       "0  5733be284776f41900661182  University_of_Notre_Dame   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   context  \\\n",
       "0  Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct...   \n",
       "\n",
       "                                                                  question  \\\n",
       "0  To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?   \n",
       "\n",
       "                                                           answers  is_valid  \\\n",
       "0  {'text': ['Saint Bernadette Soubirous'], 'answer_start': [515]}     False   \n",
       "\n",
       "   ans_start_char_idx                 answer_text  ans_end_char_idx  \\\n",
       "0                 515  Saint Bernadette Soubirous               541   \n",
       "\n",
       "                                                             proc_question  \\\n",
       "0  To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           proc_context  \\\n",
       "0  Architecturally, the school has a Catholic character. Atop the Main Building's gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputed   \n",
       "\n",
       "   ans_start_token_idx  ans_end_token_idx  is_answerable  \n",
       "0                    0                  0          False  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor = QAPreprocessor(\n",
    "    hf_tokenizer, id_attr=\"id\", tok_kwargs={\"return_overflowing_tokens\": True, \"max_length\": max_seq_len, \"stride\": 64}\n",
    ")\n",
    "\n",
    "proc_df = preprocessor.process_df(squad_df)\n",
    "proc_df.head(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_batch_tfm = QABatchTokenizeTransform(hf_arch, hf_config, hf_tokenizer, hf_model, max_length=max_seq_len)\n",
    "\n",
    "blocks = (\n",
    "    TextBlock(batch_tokenize_tfm=before_batch_tfm, input_return_type=QATextInput),\n",
    "    CategoryBlock(vocab=vocab),\n",
    "    CategoryBlock(vocab=vocab),\n",
    ")\n",
    "\n",
    "# since its preprocessed, we include an \"text\" key with the values of our question and context\n",
    "def get_x(item):\n",
    "    return {\"text\": (item.proc_question, item.proc_context), \"id\": item.id}\n",
    "\n",
    "\n",
    "dblock = DataBlock(\n",
    "    blocks=blocks,\n",
    "    get_x=get_x,\n",
    "    get_y=[ItemGetter(\"ans_start_token_idx\"), ItemGetter(\"ans_end_token_idx\")],\n",
    "    splitter=ColSplitter(),\n",
    "    n_inp=1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = dblock.dataloaders(proc_df, bs=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,\n",
       " [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127],\n",
       " [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dls.vocab), dls.vocab[0], dls.vocab[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>found</th>\n",
       "      <th>start/end</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>which nfl team represented the afc at super bowl 50? super bowl 50 was an american football game to determine the champion of the national football league ( nfl ) for the 2015 season. the american football conference ( afc ) champion denver broncos defeated the national football conference ( nfc ) champion carolina panthers 24 â€“ 10 to earn their third super bowl title. the game was played on february 7, 2016, at levi's stadium in the san francisco bay area at santa clara, california. as this was the 50th super bowl, the league emphasized the \" golden anniversary \" with various gold - themed initiatives, as well as temporarily suspending the</td>\n",
       "      <td>True</td>\n",
       "      <td>(46, 48)</td>\n",
       "      <td>denver broncos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>which nfl team represented the afc at super bowl 50? earn their third super bowl title. the game was played on february 7, 2016, at levi's stadium in the san francisco bay area at santa clara, california. as this was the 50th super bowl, the league emphasized the \" golden anniversary \" with various gold - themed initiatives, as well as temporarily suspending the tradition of naming each super bowl game with roman numerals ( under which the game would have been known as \" super bowl l \" ), so that the logo could prominently feature the arabic numerals 50.</td>\n",
       "      <td>False</td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.valid.show_batch(dataloaders=dls, max_n=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mid-level API\n",
    "\n",
    "Here we create a question/answer specific subclass of `BaseModelCallback` in order to get all the start and end prediction.  We also add here a new loss function that can handle multiple targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `QAModelCallback`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class QAModelCallback(BaseModelCallback):\n",
    "    \"\"\"The prediction is a combination start/end logits\"\"\"\n",
    "\n",
    "    def after_pred(self):\n",
    "        super().after_pred()\n",
    "        self.learn.pred = (self.pred.start_logits, self.pred.end_logits)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `MultiTargetLoss`\n",
    "\n",
    "And here we provide a custom loss function our question answer task, expanding on some techniques learned from here and here.\n",
    "\n",
    "In fact, this new loss function can be used in many other multi-modal architectures, with any mix of loss functions.  For example, this can be ammended to include the `is_impossible` task, as well as the start/end token tasks in the SQUAD v2 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class MultiTargetLoss(Module):\n",
    "    \"\"\"Provides the ability to apply different loss functions to multi-modal targets/predictions\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        # The loss function for each target\n",
    "        loss_classes: List[Callable] = [CrossEntropyLossFlat, CrossEntropyLossFlat],\n",
    "        # Any kwargs you want to pass to the loss functions above\n",
    "        loss_classes_kwargs: List[dict] = [{}, {}],\n",
    "        # The weights you want to apply to each loss (default: [1,1])\n",
    "        weights: Union[List[float], List[int]] = [1, 1],\n",
    "        # The `reduction` parameter of the lass function (default: 'mean')\n",
    "        reduction: str = \"mean\",\n",
    "    ):\n",
    "        loss_funcs = [cls(reduction=reduction, **kwargs) for cls, kwargs in zip(loss_classes, loss_classes_kwargs)]\n",
    "        store_attr(self=self, names=\"loss_funcs, weights\")\n",
    "        self._reduction = reduction\n",
    "\n",
    "    # custom loss function must have either a reduction attribute or a reduction argument (like all fastai and\n",
    "    # PyTorch loss functions) so that the framework can change this as needed (e.g., when doing lear.get_preds\n",
    "    # it will set = 'none'). see this forum topic for more info: https://bit.ly/3br2Syz\n",
    "    @property\n",
    "    def reduction(self):\n",
    "        return self._reduction\n",
    "\n",
    "    @reduction.setter\n",
    "    def reduction(self, v):\n",
    "        self._reduction = v\n",
    "        for lf in self.loss_funcs:\n",
    "            lf.reduction = v\n",
    "\n",
    "    def forward(self, outputs, *targets):\n",
    "        loss = 0.0\n",
    "        for i, loss_func, weights, output, target in zip(range(len(outputs)), self.loss_funcs, self.weights, outputs, targets):\n",
    "            loss += weights * loss_func(output, target)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def activation(self, outs):\n",
    "        acts = [self.loss_funcs[i].activation(o) for i, o in enumerate(outs)]\n",
    "        return acts\n",
    "\n",
    "    def decodes(self, outs):\n",
    "        decodes = [self.loss_funcs[i].decodes(o) for i, o in enumerate(outs)]\n",
    "        return decodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class QAMetricsCallback(Callback):\n",
    "    def __init__(self, compute_metrics_func, validation_ds, qa_metrics=[\"exact_match\", \"f1\"], **kwargs):\n",
    "        self.run_before = Recorder\n",
    "\n",
    "        store_attr()\n",
    "        self.custom_metrics_dict = {k: None for k in qa_metrics}\n",
    "        self.do_setup = True\n",
    "\n",
    "    def setup(self):\n",
    "        # one time setup code here.\n",
    "        if not self.do_setup:\n",
    "            return\n",
    "\n",
    "        # grab the hf_tokenizer from the TokenClassBatchTokenizeTransform\n",
    "        tfm = first_blurr_tfm(self.learn.dls, tfms=[QABatchTokenizeTransform])\n",
    "        self.hf_tokenizer = tfm.hf_tokenizer\n",
    "        self.tok_kwargs = tfm.tok_kwargs\n",
    "\n",
    "        # add custom question answering specific metrics\n",
    "        custom_metrics = L([ValueMetric(partial(self.metric_value, metric_key=k), k) for k in self.qa_metrics])\n",
    "        self.learn.metrics = self.learn.metrics + custom_metrics\n",
    "\n",
    "        self.do_setup = False\n",
    "\n",
    "    def before_fit(self):\n",
    "        self.setup()\n",
    "\n",
    "    # --- batch before/after phases ---\n",
    "    def before_batch(self):\n",
    "        if self.training or self.learn.y is None:\n",
    "            return\n",
    "\n",
    "        self.batch_inputs = {k: v.cpu().detach().numpy() if isinstance(v, Tensor) else v for k, v in self.x.items()}\n",
    "\n",
    "    def after_batch(self):\n",
    "        if self.training or self.learn.y is None:\n",
    "            return\n",
    "\n",
    "        for i in range(len(self.batch_inputs[\"input_ids\"])):\n",
    "            batch_inps = {k: self.batch_inputs[k][i] for k in self.batch_inputs.keys()}\n",
    "            self.results.append(\n",
    "                {**batch_inps, \"start_logits\": self.pred[0][i].cpu().detach().numpy(), \"end_logits\": self.pred[1][i].cpu().detach().numpy()}\n",
    "            )\n",
    "\n",
    "    # --- validation begin/after phases ---\n",
    "    def before_validate(self):\n",
    "        self.results = []\n",
    "\n",
    "    def after_validate(self):\n",
    "        if len(self.results) < 1:\n",
    "            return\n",
    "\n",
    "        metric_vals_d = self.compute_metrics_func(self.results, self.validation_ds, self.hf_tokenizer, self.tok_kwargs)\n",
    "        for k, v in metric_vals_d.items():\n",
    "            self.custom_metrics_dict[k] = v\n",
    "\n",
    "    # --- for ValueMetric metrics ---\n",
    "    def metric_value(self, metric_key):\n",
    "        return self.custom_metrics_dict[metric_key]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def compute_qa_metrics(results, dataset, hf_tokenizer, tok_kwargs, id_attr=\"id\", n_best=20):\n",
    "    # what is the max length for our inputs?\n",
    "    max_length = tok_kwargs.get(\"max_length\", hf_tokenizer.model_max_length)\n",
    "\n",
    "    # map examples to chunks indicies that are part of the\n",
    "    example_to_chunks = collections.defaultdict(list)\n",
    "    for idx, chunk in enumerate(results):\n",
    "        example_to_chunks[chunk[id_attr]].append(idx)\n",
    "\n",
    "    predicted_answers = []\n",
    "    for item_idx, item in enumerate(dataset):\n",
    "        example_id = item[id_attr]\n",
    "\n",
    "        answers = []\n",
    "        for chunk_idx in example_to_chunks[example_id]:\n",
    "            chunk = results[chunk_idx]\n",
    "            input_ids = chunk[\"input_ids\"]\n",
    "            start_logits = chunk[\"start_logits\"]\n",
    "            end_logits = chunk[\"end_logits\"]\n",
    "\n",
    "            start_indexes = np.argsort(start_logits)[-1 : -n_best - 1 : -1].tolist()\n",
    "            end_indexes = np.argsort(end_logits)[-1 : -n_best - 1 : -1].tolist()\n",
    "\n",
    "            for s_idx, start_index in enumerate(start_indexes):\n",
    "                for e_idx, end_index in enumerate(end_indexes):\n",
    "                    # Skip answers that are not fully in the context\n",
    "                    if start_index == 0 and end_index == 0:\n",
    "                        continue\n",
    "\n",
    "                    # Skip answers with a length that is either < 0 or > max_answer_length\n",
    "                    if end_index < start_index or end_index - start_index + 1 > max_length:\n",
    "                        continue\n",
    "\n",
    "                    answer = {\n",
    "                        \"text\": hf_tokenizer.decode(input_ids[start_index:end_index], skip_special_tokens=True),\n",
    "                        \"logit_score\": start_logits[start_index] + end_logits[end_index],\n",
    "                    }\n",
    "                    answers.append(answer)\n",
    "\n",
    "        # select the answer with the best score\n",
    "        if len(answers) > 0:\n",
    "            best_answer = max(answers, key=lambda x: x[\"logit_score\"])\n",
    "            predicted_answers.append({\"id\": example_id, \"prediction_text\": best_answer[\"text\"]})\n",
    "        else:\n",
    "            predicted_answers.append({\"id\": example_id, \"prediction_text\": \"\"})\n",
    "\n",
    "    ref_answers = [{\"id\": item[\"id\"], \"answers\": item[\"answers\"]} for item_idx, item in enumerate(dataset)]\n",
    "\n",
    "    metric_vals_d = squad_metric.compute(predictions=predicted_answers, references=ref_answers)\n",
    "    return metric_vals_d\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "Notice below how I had to define the loss function *after* creating the `Learner` object.  I'm not sure why, but the `MultiTargetLoss` above prohibits the learner from being exported if I do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BaseModelWrapper(hf_model)\n",
    "learn_cbs = [QAModelCallback]\n",
    "\n",
    "validation_ds = proc_df[proc_df.is_valid == True].to_dict(orient=\"records\")\n",
    "fit_cbs = [QAMetricsCallback(compute_metrics_func=compute_qa_metrics, validation_ds=validation_ds)]\n",
    "\n",
    "learn = Learner(dls, model, opt_func=partial(Adam), cbs=learn_cbs, splitter=blurr_splitter)\n",
    "\n",
    "learn.loss_func = MultiTargetLoss()\n",
    "learn.create_opt()  # -> will create your layer groups based on your \"splitter\" function\n",
    "learn.freeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide_output\n",
    "# learn.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(len(learn.opt.param_groups))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(minimum=0.005754399299621582, steep=6.918309736647643e-06, valley=0.0030199517495930195, slide=0.00363078061491251)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find(suggest_funcs=[minimum, steep, valley, slide])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>exact_match</th>\n",
       "      <th>f1</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.468664</td>\n",
       "      <td>2.031207</td>\n",
       "      <td>77.377049</td>\n",
       "      <td>85.522208</td>\n",
       "      <td>01:29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, lr_max=1e-3, cbs=fit_cbs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `show_results`\n",
    "\n",
    "Below we'll add in additional functionality to more intuitively show the results of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@typedispatch\n",
    "def show_results(\n",
    "    # This typedispatched `show_results` will be called for `QuestionAnswerTextInput` typed inputs\n",
    "    x: QATextInput,\n",
    "    # The targets\n",
    "    y,\n",
    "    # Your raw inputs/targets\n",
    "    samples,\n",
    "    # The model's predictions\n",
    "    outs,\n",
    "    # Your `Learner`. This is required so as to get at the Hugging Face objects for decoding them into\n",
    "    # something understandable\n",
    "    learner,\n",
    "    # Whether you want to remove special tokens during decoding/showing the outputs\n",
    "    skip_special_tokens=True,\n",
    "    # Your `show_results` context\n",
    "    ctxs=None,\n",
    "    # The maximum number of items to show\n",
    "    max_n=6,\n",
    "    # Any truncation your want applied to your decoded inputs\n",
    "    trunc_at=None,\n",
    "    # Any other keyword arguments you want applied to `show_results`\n",
    "    **kwargs\n",
    "):\n",
    "    tfm = first_blurr_tfm(learner.dls, tfms=[QABatchTokenizeTransform])\n",
    "    hf_tokenizer = tfm.hf_tokenizer\n",
    "\n",
    "    res = L()\n",
    "    for sample, input_ids, start, end, pred in zip(samples, x, *y, outs):\n",
    "        txt = hf_tokenizer.decode(sample[0], skip_special_tokens=True)[:trunc_at]\n",
    "        found = start.item() != 0 and end.item() != 0\n",
    "        ans_text = hf_tokenizer.decode(input_ids[start:end], skip_special_tokens=False)\n",
    "\n",
    "        pred_ans_toks = hf_tokenizer.convert_ids_to_tokens(input_ids, skip_special_tokens=False)[int(pred[0]) : int(pred[1])]\n",
    "        pred_ans_txt = hf_tokenizer.convert_tokens_to_string(pred_ans_toks)\n",
    "\n",
    "        res.append((txt, found, (start.item(), end.item()), ans_text, (int(pred[0]), int(pred[1])), pred_ans_txt))\n",
    "\n",
    "    display_df(pd.DataFrame(res, columns=[\"text\", \"found\", \"start/end\", \"answer\", \"pred start/end\", \"pred answer\"]))\n",
    "    return ctxs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>found</th>\n",
       "      <th>start/end</th>\n",
       "      <th>answer</th>\n",
       "      <th>pred start/end</th>\n",
       "      <th>pred answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>which nfl team represented the afc at super bowl 50? super bowl 50 was an american football game to determine the champion of the national football league ( nfl ) for the 2015 season. the american football conference ( afc ) champion denver broncos defeated the national football conference ( nfc ) champion carolina panthers 24 â€“ 10 to earn their third super bowl title. the game was played on february 7, 2016, at levi's stadium in the san francisco bay area at santa clara, california. as this was</td>\n",
       "      <td>True</td>\n",
       "      <td>(46, 48)</td>\n",
       "      <td>denver broncos</td>\n",
       "      <td>(46, 48)</td>\n",
       "      <td>denver broncos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>in what venue did super bowl xix take place? the league announced on october 16, 2012, that the two finalists were sun life stadium and levi's stadium. the south florida / miami area has previously hosted the event 10 times ( tied for most with new orleans ), with the most recent one being super bowl xliv in 2010. the san francisco bay area last hosted in 1985 ( super bowl xix ), held at stanford stadium in stanford, california, won by the home team 49ers. the miami bid depended on whether the s</td>\n",
       "      <td>True</td>\n",
       "      <td>(89, 91)</td>\n",
       "      <td>stanford stadium</td>\n",
       "      <td>(89, 91)</td>\n",
       "      <td>stanford stadium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>who is the quarterback for the panthers? founded in 1995. the broncos finished the regular season with a 12 â€“ 4 record, and denied the new england patriots a chance to defend their title from super bowl xlix by defeating them 20 â€“ 18 in the afc championship game. they joined the patriots, dallas cowboys, and pittsburgh steelers as one of four teams that have made eight appearances in the super bowl.</td>\n",
       "      <td>False</td>\n",
       "      <td>(0, 0)</td>\n",
       "      <td></td>\n",
       "      <td>(9, 9)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what day was the game played on? super bowl 50 was an american football game to determine the champion of the national football league ( nfl ) for the 2015 season. the american football conference ( afc ) champion denver broncos defeated the national football conference ( nfc ) champion carolina panthers 24 â€“ 10 to earn their third super bowl title. the game was played on february 7, 2016, at levi's stadium in the san francisco bay area at santa clara, california. as this was the 50th super bowl</td>\n",
       "      <td>True</td>\n",
       "      <td>(72, 76)</td>\n",
       "      <td>february 7, 2016</td>\n",
       "      <td>(72, 74)</td>\n",
       "      <td>february 7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, skip_special_tokens=True, max_n=4, trunc_at=500)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and lets see how `Learner.blurr_predict` works with question/answering tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('11', '13'), [11, 13])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_df = pd.DataFrame.from_dict(\n",
    "    [\n",
    "        {\n",
    "            \"id\": -1,\n",
    "            \"proc_question\": \"What did George Lucas make?\",\n",
    "            \"proc_context\": \"George Lucas created Star Wars in 1977. He directed and produced it.\",\n",
    "        }\n",
    "    ],\n",
    "    orient=\"columns\",\n",
    ")\n",
    "\n",
    "results = learn.blurr_predict(inf_df)\n",
    "pred_labels, pred_idxs, probs = results[0]\n",
    "\n",
    "pred_labels, pred_idxs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['star', 'wars']\n"
     ]
    }
   ],
   "source": [
    "for res, (r_idx, r) in zip(results, inf_df.iterrows()):\n",
    "    inp_ids = hf_tokenizer.encode(r[\"proc_question\"], r[\"proc_context\"])\n",
    "    pred_labels, pred_idxs, probs = res\n",
    "    answer = hf_tokenizer.convert_ids_to_tokens(inp_ids, skip_special_tokens=False)[pred_idxs[0] : pred_idxs[1]]\n",
    "    print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_df = pd.DataFrame.from_dict(\n",
    "    [\n",
    "        {\n",
    "            \"id\": -1,\n",
    "            \"proc_question\": \"What did George Lucas make?\",\n",
    "            \"proc_context\": \"George Lucas created Star Wars in 1977. He directed and produced it.\",\n",
    "        },\n",
    "        {\n",
    "            \"id\": -1,\n",
    "            \"proc_question\": \"What year did Star Wars come out?\",\n",
    "            \"proc_context\": \"George Lucas created Star Wars in 1977. He directed and produced it.\",\n",
    "        },\n",
    "        {\n",
    "            \"id\": -1,\n",
    "            \"proc_question\": \"What did George Lucas do?\",\n",
    "            \"proc_context\": \"George Lucas created Star Wars in 1977. He directed and produced it.\",\n",
    "        },\n",
    "    ],\n",
    "    orient=\"columns\",\n",
    ")\n",
    "\n",
    "results = learn.blurr_predict(inf_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['star', 'wars']\n",
      "['1977']\n",
      "['directed', 'and', 'produced', 'it']\n"
     ]
    }
   ],
   "source": [
    "for res, (r_idx, r) in zip(results, inf_df.iterrows()):\n",
    "    inp_ids = hf_tokenizer.encode(r[\"proc_question\"], r[\"proc_context\"])\n",
    "    pred_labels, pred_idxs, probs = res\n",
    "    answer = hf_tokenizer.convert_ids_to_tokens(inp_ids, skip_special_tokens=False)[pred_idxs[0] : pred_idxs[1]]\n",
    "    print(answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that there is a bug currently in fastai v2 (or with how I'm assembling everything) that currently prevents us from seeing the decoded predictions and probabilities for the \"end\" token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inf_df = pd.DataFrame.from_dict(\n",
    "    [\n",
    "        {\n",
    "            \"id\": -1,\n",
    "            \"proc_question\": \"When was Star Wars made?\",\n",
    "            \"proc_context\": \"George Lucas created Star Wars in 1977. He directed and produced it.\",\n",
    "        },\n",
    "        {\n",
    "            \"id\": -2,\n",
    "            \"proc_question\": \"Who made Star Wars?\",\n",
    "            \"proc_context\": \"George Lucas created Star Wars in 1977. He directed and produced it.\",\n",
    "        },\n",
    "        {\n",
    "            \"id\": -3,\n",
    "            \"proc_question\": \"Who plays Spock in the movie?\",\n",
    "            \"proc_context\": \"George Lucas created Star Wars in 1977. He directed and produced it.\",\n",
    "        },\n",
    "    ],\n",
    "    orient=\"columns\",\n",
    ")\n",
    "\n",
    "test_dl = dls.test_dl(inf_df)\n",
    "probs, _, preds = learn.get_preds(dl=test_dl, with_input=False, with_decoded=True)\n",
    "\n",
    "starts, ends = preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1977']\n",
      "['george', 'lucas']\n",
      "['george', 'lucas']\n"
     ]
    }
   ],
   "source": [
    "for start, end, (r_idx, r) in zip(starts, ends, inf_df.iterrows()):\n",
    "    inp_ids = hf_tokenizer.encode(r[\"proc_question\"], r[\"proc_context\"])\n",
    "    answer = hf_tokenizer.convert_ids_to_tokens(inp_ids, skip_special_tokens=False)[start:end]\n",
    "    print(answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can unfreeze and continue training like normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>exact_match</th>\n",
       "      <th>f1</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.219424</td>\n",
       "      <td>2.027224</td>\n",
       "      <td>77.377049</td>\n",
       "      <td>85.522208</td>\n",
       "      <td>03:13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, lr_max=slice(1e-9, 1e-7), cbs=fit_cbs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.recorder.plot_loss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>found</th>\n",
       "      <th>start/end</th>\n",
       "      <th>answer</th>\n",
       "      <th>pred start/end</th>\n",
       "      <th>pred answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>which nfl team represented the afc at super bowl 50? super bowl 50 was an american football game to</td>\n",
       "      <td>True</td>\n",
       "      <td>(46, 48)</td>\n",
       "      <td>denver broncos</td>\n",
       "      <td>(46, 48)</td>\n",
       "      <td>denver broncos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>if roman numerals were used, what would super bowl 50 have been called? carolina panthers 24 â€“ 10 to</td>\n",
       "      <td>True</td>\n",
       "      <td>(112, 115)</td>\n",
       "      <td>super bowl l</td>\n",
       "      <td>(112, 115)</td>\n",
       "      <td>super bowl l</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, max_n=2, trunc_at=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_df = pd.DataFrame.from_dict(\n",
    "    [\n",
    "        {\n",
    "            \"id\": -1,\n",
    "            \"proc_question\": \"When was Star Wars made?\",\n",
    "            \"proc_context\": \"George Lucas created Star Wars in 1977. He directed and produced it.\",\n",
    "        },\n",
    "        {\n",
    "            \"id\": -2,\n",
    "            \"proc_question\": \"Who made Star Wars?\",\n",
    "            \"proc_context\": \"George Lucas created Star Wars in 1977. He directed and produced it.\",\n",
    "        },\n",
    "        {\n",
    "            \"id\": -3,\n",
    "            \"proc_question\": \"Who plays Spock?\",\n",
    "            \"proc_context\": \"George Lucas created Star Wars in 1977. He directed and produced it.\",\n",
    "        },\n",
    "    ],\n",
    "    orient=\"columns\",\n",
    ")\n",
    "\n",
    "results = learn.blurr_predict(inf_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1977']\n",
      "['george', 'lucas']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "for res, (r_idx, r) in zip(results, inf_df.iterrows()):\n",
    "    inp_ids = hf_tokenizer.encode(r[\"proc_question\"], r[\"proc_context\"])\n",
    "    pred_labels, pred_idxs, probs = res\n",
    "    answer = hf_tokenizer.convert_ids_to_tokens(inp_ids, skip_special_tokens=False)[pred_idxs[0] : pred_idxs[1]]\n",
    "    print(answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference\n",
    "\n",
    "Note that I had to replace the loss function because of the above-mentioned issue to exporting the model with the `MultiTargetLoss` loss function.  After getting our inference learner, we put it back and we're good to go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_name = \"q_and_a_learn_export\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.loss_func = CrossEntropyLossFlat()\n",
    "learn.export(fname=f\"{export_name}.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_learn = load_learner(fname=f\"{export_name}.pkl\")\n",
    "inf_learn.loss_func = MultiTargetLoss()\n",
    "\n",
    "inf_df = pd.DataFrame.from_dict(\n",
    "    [\n",
    "        {\n",
    "            \"id\": -1,\n",
    "            \"proc_question\": \"When was Star Wars made?\",\n",
    "            \"proc_context\": \"George Lucas created Star Wars in 1977. He directed and produced it.\",\n",
    "        },\n",
    "        {\n",
    "            \"id\": -2,\n",
    "            \"proc_question\": \"Who made Star Wars?\",\n",
    "            \"proc_context\": \"George Lucas created Star Wars in 1977. He directed and produced it.\",\n",
    "        },\n",
    "        {\n",
    "            \"id\": -3,\n",
    "            \"proc_question\": \"Who plays Spock in 1977?\",\n",
    "            \"proc_context\": \"George Lucas created Star Wars in 1977. He directed and produced it.\",\n",
    "        },\n",
    "    ],\n",
    "    orient=\"columns\",\n",
    ")\n",
    "\n",
    "results = inf_learn.blurr_predict(inf_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1977']\n",
      "['george', 'lucas']\n",
      "['george', 'lucas']\n"
     ]
    }
   ],
   "source": [
    "for res, (r_idx, r) in zip(results, inf_df.iterrows()):\n",
    "    inp_ids = hf_tokenizer.encode(r[\"proc_question\"], r[\"proc_context\"])\n",
    "    pred_labels, pred_idxs, probs = res\n",
    "    answer = hf_tokenizer.convert_ids_to_tokens(inp_ids, skip_special_tokens=False)[pred_idxs[0] : pred_idxs[1]]\n",
    "    print(answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High-level API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BLearnerForQuestionAnswering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "try:\n",
    "    del learn\n",
    "    del inf_learn\n",
    "    torch.cuda.empty_cache()\n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@delegates(Blearner.__init__)\n",
    "class BlearnerForQuestionAnswering(Blearner):\n",
    "    def __init__(self, dls: DataLoaders, hf_model: PreTrainedModel, **kwargs):\n",
    "        kwargs[\"loss_func\"] = kwargs.get(\"loss_func\", MultiTargetLoss())\n",
    "        super().__init__(dls, hf_model, base_model_cb=QAModelCallback, **kwargs)\n",
    "\n",
    "    @classmethod\n",
    "    def get_model_cls(self):\n",
    "        return AutoModelForQuestionAnswering\n",
    "\n",
    "    @classmethod\n",
    "    def _get_x(cls, x, qst, ctx, padding_side=\"right\"):\n",
    "        return (x[qst], x[ctx]) if (padding_side == \"right\") else (x[ctx], x[qst])\n",
    "\n",
    "    @classmethod\n",
    "    def _create_learner(\n",
    "        cls,\n",
    "        # Your raw dataset\n",
    "        data,\n",
    "        # The name or path of the pretrained model you want to fine-tune\n",
    "        pretrained_model_name_or_path: Optional[Union[str, os.PathLike]],\n",
    "        # A function to perform any preprocessing required for your Dataset\n",
    "        preprocess_func: Callable = None,\n",
    "        # The maximum sequence length to constrain our data\n",
    "        max_seq_len: int = None,\n",
    "        # The attribute in your dataset that contains the context (where the answer is included) (default: 'context')\n",
    "        context_attr: str = \"context\",\n",
    "        # The attribute in your dataset that contains the question being asked (default: 'question')\n",
    "        question_attr: str = \"question\",\n",
    "        # The attribute in your dataset that contains the actual answer (default: 'answer_text')\n",
    "        answer_text_attr: str = \"answer_text\",\n",
    "        # The attribute in your dataset that contains the tokenized answer start (default: 'tok_answer_start')\n",
    "        tok_ans_start_attr: str = \"tok_answer_start\",\n",
    "        # The attribute in your dataset that contains the tokenized answer end(default: 'tok_answer_end')\n",
    "        tok_ans_end_attr: str = \"tok_answer_end\",\n",
    "        # A function that will split your Dataset into a training and validation set\n",
    "        # See [here](https://docs.fast.ai/data.transforms.html#Split) for a list of fast.ai splitters\n",
    "        dblock_splitter: Callable = RandomSplitter(),\n",
    "        # Any kwargs to pass to your `DataLoaders`\n",
    "        dl_kwargs={},\n",
    "        # Any kwargs to pass to your task specific `Blearner`\n",
    "        learner_kwargs={},\n",
    "    ):\n",
    "        hf_arch, hf_config, hf_tokenizer, hf_model = BLURR.get_hf_objects(pretrained_model_name_or_path, model_cls=cls.get_model_cls())\n",
    "\n",
    "        # potentially used by our preprocess_func, it is the basis for our CategoryBlock vocab\n",
    "        if max_seq_len is None:\n",
    "            max_seq_len = hf_config.get(\"max_position_embeddings\", 128)\n",
    "\n",
    "        # client can pass in a function that takes the raw data, hf objects, and max_seq_len ... and\n",
    "        # returns a DataFrame with the expected format\n",
    "        if preprocess_func:\n",
    "            data = preprocess_func(\n",
    "                data,\n",
    "                hf_arch,\n",
    "                hf_config,\n",
    "                hf_tokenizer,\n",
    "                hf_model,\n",
    "                max_seq_len,\n",
    "                context_attr,\n",
    "                question_attr,\n",
    "                answer_text_attr,\n",
    "                tok_ans_start_attr,\n",
    "                tok_ans_end_attr,\n",
    "            )\n",
    "\n",
    "        # bits required by our \"before_batch_tfm\" and DataBlock\n",
    "        vocab = list(range(max_seq_len))\n",
    "        padding_side = hf_tokenizer.padding_side\n",
    "        trunc_strat = \"only_second\" if (padding_side == \"right\") else \"only_first\"\n",
    "\n",
    "        before_batch_tfm = QABatchTokenizeTransform(\n",
    "            hf_arch,\n",
    "            hf_config,\n",
    "            hf_tokenizer,\n",
    "            hf_model,\n",
    "            max_length=max_seq_len,\n",
    "            truncation=trunc_strat,\n",
    "            tok_kwargs={\"return_special_tokens_mask\": True},\n",
    "        )\n",
    "\n",
    "        # define getters\n",
    "        if isinstance(data, pd.DataFrame):\n",
    "            get_x = partial(cls._get_x, qst=question_attr, ctx=context_attr, padding_side=padding_side)\n",
    "            get_y = [ColReader(tok_ans_start_attr), ColReader(tok_ans_end_attr)]\n",
    "        else:\n",
    "            get_x = partial(cls._get_x, qst=question_attr, ctx=context_attr, padding_side=padding_side)\n",
    "            get_y = [ItemGetter(tok_ans_start_attr), ItemGetter(tok_ans_end_attr)]\n",
    "\n",
    "        # define DataBlock and DataLoaders\n",
    "        blocks = (\n",
    "            TextBlock(before_batch_tfm=before_batch_tfm, input_return_type=QATextInput),\n",
    "            CategoryBlock(vocab=vocab),\n",
    "            CategoryBlock(vocab=vocab),\n",
    "        )\n",
    "\n",
    "        dblock = DataBlock(blocks=blocks, get_x=get_x, get_y=get_y, splitter=dblock_splitter, n_inp=1)\n",
    "\n",
    "        dls = dblock.dataloaders(data, **dl_kwargs.copy())\n",
    "\n",
    "        # return BLearner instance\n",
    "        return cls(dls, hf_model, **learner_kwargs.copy())\n",
    "\n",
    "    @classmethod\n",
    "    def from_dataframe(\n",
    "        cls,\n",
    "        # Your pandas DataFrame\n",
    "        df: pd.DataFrame,\n",
    "        # The name or path of the pretrained model you want to fine-tune\n",
    "        pretrained_model_name_or_path: Optional[Union[str, os.PathLike]],\n",
    "        # A function to perform any preprocessing required for your Dataset\n",
    "        preprocess_func: Callable = None,\n",
    "        # The maximum sequence length to constrain our data\n",
    "        max_seq_len: int = None,\n",
    "        # The attribute in your dataset that contains the context (where the answer is included) (default: 'context')\n",
    "        context_attr: str = \"context\",\n",
    "        # The attribute in your dataset that contains the question being asked (default: 'question')\n",
    "        question_attr: str = \"question\",\n",
    "        # The attribute in your dataset that contains the actual answer (default: 'answer_text')\n",
    "        answer_text_attr: str = \"answer_text\",\n",
    "        # The attribute in your dataset that contains the tokenized answer start (default: 'tok_answer_start')\n",
    "        tok_ans_start_attr: str = \"tok_answer_start\",\n",
    "        # The attribute in your dataset that contains the tokenized answer end(default: 'tok_answer_end')\n",
    "        tok_ans_end_attr: str = \"tok_answer_end\",\n",
    "        # A function that will split your Dataset into a training and validation set\n",
    "        # See [here](https://docs.fast.ai/data.transforms.html#Split) for a list of fast.ai splitters\n",
    "        dblock_splitter: Callable = ColSplitter(),\n",
    "        # Any kwargs to pass to your `DataLoaders`\n",
    "        dl_kwargs={},\n",
    "        # Any kwargs to pass to your task specific `Blearner`\n",
    "        learner_kwargs={},\n",
    "    ):\n",
    "        return cls._create_learner(\n",
    "            df,\n",
    "            pretrained_model_name_or_path,\n",
    "            preprocess_func,\n",
    "            max_seq_len,\n",
    "            context_attr,\n",
    "            question_attr,\n",
    "            answer_text_attr,\n",
    "            tok_ans_start_attr,\n",
    "            tok_ans_end_attr,\n",
    "            dblock_splitter,\n",
    "            dl_kwargs,\n",
    "            learner_kwargs,\n",
    "        )\n",
    "\n",
    "    @classmethod\n",
    "    def from_csv(\n",
    "        cls,\n",
    "        # The path to your csv file\n",
    "        csv_file: Union[Path, str],\n",
    "        # The name or path of the pretrained model you want to fine-tune\n",
    "        pretrained_model_name_or_path: Optional[Union[str, os.PathLike]],\n",
    "        # A function to perform any preprocessing required for your Dataset\n",
    "        preprocess_func: Callable = None,\n",
    "        # The maximum sequence length to constrain our data\n",
    "        max_seq_len: int = None,\n",
    "        # The attribute in your dataset that contains the context (where the answer is included) (default: 'context')\n",
    "        context_attr: str = \"context\",\n",
    "        # The attribute in your dataset that contains the question being asked (default: 'question')\n",
    "        question_attr: str = \"question\",\n",
    "        # The attribute in your dataset that contains the actual answer (default: 'answer_text')\n",
    "        answer_text_attr: str = \"answer_text\",\n",
    "        # The attribute in your dataset that contains the tokenized answer start (default: 'tok_answer_start')\n",
    "        tok_ans_start_attr: str = \"tok_answer_start\",\n",
    "        # The attribute in your dataset that contains the tokenized answer end(default: 'tok_answer_end')\n",
    "        tok_ans_end_attr: str = \"tok_answer_end\",\n",
    "        # A function that will split your Dataset into a training and validation set\n",
    "        # See [here](https://docs.fast.ai/data.transforms.html#Split) for a list of fast.ai splitters\n",
    "        dblock_splitter: Callable = ColSplitter(),\n",
    "        # Any kwargs to pass to your `DataLoaders`\n",
    "        dl_kwargs={},\n",
    "        # Any kwargs to pass to your task specific `Blearner`\n",
    "        learner_kwargs={},\n",
    "    ):\n",
    "        df = pd.read_csv(csv_file)\n",
    "\n",
    "        return cls.from_dataframe(\n",
    "            df,\n",
    "            pretrained_model_name_or_path,\n",
    "            preprocess_func,\n",
    "            max_seq_len,\n",
    "            context_attr,\n",
    "            question_attr,\n",
    "            answer_text_attr,\n",
    "            tok_ans_start_attr,\n",
    "            tok_ans_end_attr,\n",
    "            dblock_splitter,\n",
    "            dl_kwargs,\n",
    "            learner_kwargs,\n",
    "        )\n",
    "\n",
    "    @classmethod\n",
    "    def from_dictionaries(\n",
    "        cls,\n",
    "        # A list of dictionaries\n",
    "        ds: List[Dict],\n",
    "        # The name or path of the pretrained model you want to fine-tune\n",
    "        pretrained_model_name_or_path: Optional[Union[str, os.PathLike]],\n",
    "        # A function to perform any preprocessing required for your Dataset\n",
    "        preprocess_func: Callable = None,\n",
    "        # The maximum sequence length to constrain our data\n",
    "        max_seq_len: int = None,\n",
    "        # The attribute in your dataset that contains the context (where the answer is included) (default: 'context')\n",
    "        context_attr: str = \"context\",\n",
    "        # The attribute in your dataset that contains the question being asked (default: 'question')\n",
    "        question_attr: str = \"question\",\n",
    "        # The attribute in your dataset that contains the actual answer (default: 'answer_text')\n",
    "        answer_text_attr: str = \"answer_text\",\n",
    "        # The attribute in your dataset that contains the tokenized answer start (default: 'tok_answer_start')\n",
    "        tok_ans_start_attr: str = \"tok_answer_start\",\n",
    "        # The attribute in your dataset that contains the tokenized answer end(default: 'tok_answer_end')\n",
    "        tok_ans_end_attr: str = \"tok_answer_end\",\n",
    "        # A function that will split your Dataset into a training and validation set\n",
    "        # See [here](https://docs.fast.ai/data.transforms.html#Split) for a list of fast.ai splitters\n",
    "        dblock_splitter: Callable = RandomSplitter(),\n",
    "        # Any kwargs to pass to your `DataLoaders`\n",
    "        dl_kwargs={},\n",
    "        # Any kwargs to pass to your task specific `Blearner`\n",
    "        learner_kwargs={},\n",
    "    ):\n",
    "        return cls._create_learner(\n",
    "            ds,\n",
    "            pretrained_model_name_or_path,\n",
    "            preprocess_func,\n",
    "            max_seq_len,\n",
    "            context_attr,\n",
    "            question_attr,\n",
    "            answer_text_attr,\n",
    "            tok_ans_start_attr,\n",
    "            tok_ans_end_attr,\n",
    "            dblock_splitter,\n",
    "            dl_kwargs,\n",
    "            learner_kwargs,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`BLearnerForQuestionAnswering` requires a question, context (within which to find the answer to the question), and the start/end indices of where the answer lies in the *tokenized context*. Because those indices vary by tokenizer, we can pass a `preprocess_func` that will take our raw data, perform any preprocessing we want, and return it in a way that will work for extractive QA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_df(\n",
    "    df,\n",
    "    hf_arch,\n",
    "    hf_config,\n",
    "    hf_tokenizer,\n",
    "    hf_model,\n",
    "    max_seq_len,\n",
    "    context_attr,\n",
    "    question_attr,\n",
    "    answer_text_attr,\n",
    "    tok_ans_start_attr,\n",
    "    tok_ans_end_attr,\n",
    "):\n",
    "\n",
    "    df = df.apply(\n",
    "        partial(\n",
    "            pre_process_squad,\n",
    "            hf_arch=hf_arch,\n",
    "            hf_tokenizer=hf_tokenizer,\n",
    "            ctx_attr=context_attr,\n",
    "            qst_attr=question_attr,\n",
    "            ans_attr=answer_text_attr,\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    df = df[(df.tokenized_input_len < max_seq_len) & (df.is_impossible == False)]\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's re-grab the raw data and use the high-level API to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pre_process_squad' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_85956/1385352515.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpretrained_model_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"bert-large-uncased-whole-word-masking-finetuned-squad\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m learn = BlearnerForQuestionAnswering.from_dataframe(\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0msquad_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained_model_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreprocess_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_seq_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdblock_splitter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRandomSplitter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"bs\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m ).to_fp16()\n",
      "\u001b[0;32m/tmp/ipykernel_85956/270255788.py\u001b[0m in \u001b[0;36mfrom_dataframe\u001b[0;34m(cls, df, pretrained_model_name_or_path, preprocess_func, max_seq_len, context_attr, question_attr, answer_text_attr, tok_ans_start_attr, tok_ans_end_attr, dblock_splitter, dl_kwargs, learner_kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mlearner_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     ):\n\u001b[0;32m--> 134\u001b[0;31m         return cls._create_learner(\n\u001b[0m\u001b[1;32m    135\u001b[0m             \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_85956/270255788.py\u001b[0m in \u001b[0;36m_create_learner\u001b[0;34m(cls, data, pretrained_model_name_or_path, preprocess_func, max_seq_len, context_attr, question_attr, answer_text_attr, tok_ans_start_attr, tok_ans_end_attr, dblock_splitter, dl_kwargs, learner_kwargs)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;31m# returns a DataFrame with the expected format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpreprocess_func\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m             data = preprocess_func(\n\u001b[0m\u001b[1;32m     55\u001b[0m                 \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mhf_arch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_85956/2808603010.py\u001b[0m in \u001b[0;36mpreprocess_df\u001b[0;34m(df, hf_arch, hf_config, hf_tokenizer, hf_model, max_seq_len, context_attr, question_attr, answer_text_attr, tok_ans_start_attr, tok_ans_end_attr)\u001b[0m\n\u001b[1;32m     15\u001b[0m     df = df.apply(\n\u001b[1;32m     16\u001b[0m         partial(\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mpre_process_squad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0mhf_arch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhf_arch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mhf_tokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhf_tokenizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pre_process_squad' is not defined"
     ]
    }
   ],
   "source": [
    "squad_df = pd.read_csv(\"./squad_sample.csv\")\n",
    "\n",
    "pretrained_model_name = \"bert-large-uncased-whole-word-masking-finetuned-squad\"\n",
    "\n",
    "learn = BlearnerForQuestionAnswering.from_dataframe(\n",
    "    squad_df, pretrained_model_name, preprocess_func=preprocess_df, max_seq_len=128, dblock_splitter=RandomSplitter(), dl_kwargs={\"bs\": 4}\n",
    ").to_fp16()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.dls.show_batch(dataloaders=learn.dls, max_n=2, trunc_at=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(3, lr_max=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.show_results(learner=learn, skip_special_tokens=True, max_n=2, trunc_at=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.loss_func = CrossEntropyLossFlat()\n",
    "learn.export(fname=f\"{export_name}.pkl\")\n",
    "inf_learn = load_learner(fname=f\"{export_name}.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_learn = load_learner(fname=f\"{export_name}.pkl\")\n",
    "inf_learn.loss_func = MultiTargetLoss()\n",
    "\n",
    "inf_df = pd.DataFrame.from_dict(\n",
    "    [\n",
    "        {\"question\": \"What did George Lucas make?\", \"context\": \"George Lucas created Star Wars in 1977. He directed and produced it.\"},\n",
    "        {\n",
    "            \"question\": \"What year did Star Wars come out?\",\n",
    "            \"context\": \"George Lucas created Star Wars in 1977. He directed and produced it.\",\n",
    "        },\n",
    "        {\"question\": \"What did George Lucas do?\", \"context\": \"George Lucas created Star Wars in 1977. He directed and produced it.\"},\n",
    "    ],\n",
    "    orient=\"columns\",\n",
    ")\n",
    "\n",
    "inf_learn.blurr_predict(inf_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This module includes all the low, mid, and high-level API bits for extractive Q&A tasks training and inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_utils.ipynb.\n",
      "Converted 01_data-core.ipynb.\n",
      "Converted 01_modeling-core.ipynb.\n",
      "Converted 02_data-language-modeling.ipynb.\n",
      "Converted 02_modeling-language-modeling.ipynb.\n",
      "Converted 03_data-token-classification.ipynb.\n",
      "Converted 03_modeling-token-classification.ipynb.\n",
      "Converted 04_data-question-answering.ipynb.\n",
      "Converted 04_modeling-question-answering.ipynb.\n",
      "Converted 10_data-seq2seq-core.ipynb.\n",
      "Converted 10_modeling-seq2seq-core.ipynb.\n",
      "Converted 11_data-seq2seq-summarization.ipynb.\n",
      "Converted 11_modeling-seq2seq-summarization.ipynb.\n",
      "Converted 12_data-seq2seq-translation.ipynb.\n",
      "Converted 12_modeling-seq2seq-translation.ipynb.\n",
      "Converted 99a_examples-high-level-api.ipynb.\n",
      "Converted 99b_examples-glue.ipynb.\n",
      "Converted 99c_examples-glue-plain-pytorch.ipynb.\n",
      "Converted 99d_examples-multilabel.ipynb.\n",
      "Converted 99e_examples-causal-lm-gpt2.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import notebook2script\n",
    "\n",
    "notebook2script()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
