{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp modeling.core\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_slow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modeling.core\n",
    "\n",
    "> This module contains core custom models, loss functions, and a default layer group splitter for use in applying discriminiative learning rates to your Hugging Face models trained via fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import os, inspect\n",
    "from typing import Any, Callable, Dict, List, Optional, Union, Type\n",
    "\n",
    "from fastcore.all import *\n",
    "from fastai.callback.all import *\n",
    "from fastai.data.block import DataBlock, ColReader, CategoryBlock, MultiCategoryBlock, ColSplitter, RandomSplitter\n",
    "from fastai.data.core import DataLoader, DataLoaders, TfmdDL\n",
    "from fastai.imports import *\n",
    "from fastai.learner import *\n",
    "from fastai.losses import CrossEntropyLossFlat\n",
    "from fastai.optimizer import Adam, OptimWrapper, params\n",
    "from fastai.metrics import accuracy, F1Score, accuracy_multi, F1ScoreMulti\n",
    "from fastai.torch_core import *\n",
    "from fastai.torch_imports import *\n",
    "from fastprogress.fastprogress import progress_bar, master_bar\n",
    "from transformers import AutoModelForSequenceClassification, logging, PretrainedConfig, PreTrainedTokenizerBase, PreTrainedModel\n",
    "\n",
    "from blurr.utils import BLURR, set_seed\n",
    "from blurr.data.core import HF_TextBlock, HF_BaseInput, first_blurr_tfm\n",
    "\n",
    "logging.set_verbosity_error()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What we're running with at the time this documentation was generated:\n",
      "torch: 1.10.1+cu111\n",
      "fastai: 2.5.3\n",
      "transformers: 4.15.0\n"
     ]
    }
   ],
   "source": [
    "# hide_input\n",
    "import pdb\n",
    "\n",
    "from datasets import concatenate_datasets, load_dataset\n",
    "from fastai.data.external import untar_data, URLs\n",
    "from fastcore.test import *\n",
    "from nbverbose.showdoc import show_doc\n",
    "\n",
    "from blurr.utils import print_versions\n",
    "from blurr.data.core import BlurrDataLoader\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "print(\"What we're running with at the time this documentation was generated:\")\n",
    "print_versions(\"torch fastai transformers\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU #1: GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "# cuda\n",
    "torch.cuda.set_device(1)\n",
    "print(f\"Using GPU #{torch.cuda.current_device()}: {torch.cuda.get_device_name()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base splitter, model wrapper, and model callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def hf_splitter(m: Module):\n",
    "    \"\"\"Splits the Hugging Face model based on various model architecture conventions\"\"\"\n",
    "    model = m.hf_model if (hasattr(m, \"hf_model\")) else m\n",
    "    root_modules = list(model.named_children())\n",
    "    top_module_name, top_module = root_modules[0]\n",
    "\n",
    "    groups = L([m for m_name, m in list(top_module.named_children())])\n",
    "    groups += L([m for m_name, m in root_modules[1:]])\n",
    "\n",
    "    return groups.map(params).filter(lambda el: len(el) > 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"hf_splitter\" class=\"doc_header\"><code>hf_splitter</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>hf_splitter</code>(**`m`**:`Module`)\n",
       "\n",
       "Splits the Hugging Face model based on various model architecture conventions\n",
       "\n",
       "**Parameters:**\n",
       "\n",
       "\n",
       " - **`m`** : *`<class 'fastai.torch_core.Module'>`*\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(hf_splitter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class HF_BaseModelWrapper(Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        # Your Hugging Face model\n",
    "        hf_model: PreTrainedModel,\n",
    "        # If True, hidden_states will be returned and accessed from Learner\n",
    "        output_hidden_states: bool = False,\n",
    "        # If True, attentions will be returned and accessed from Learner\n",
    "        output_attentions: bool = False,\n",
    "        # Any additional keyword arguments you want passed into your models forward method\n",
    "        hf_model_kwargs={},\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        store_attr(self=self, names=\"output_hidden_states, output_attentions, hf_model_kwargs\")\n",
    "        self.hf_model = hf_model.cuda() if torch.cuda.is_available() else hf_model\n",
    "\n",
    "        self.hf_model_fwd_args = list(inspect.signature(self.hf_model.forward).parameters.keys())\n",
    "\n",
    "    def forward(self, x):\n",
    "        for k in list(x):\n",
    "            if k not in self.hf_model_fwd_args:\n",
    "                del x[k]\n",
    "\n",
    "        return self.hf_model(\n",
    "            **x,\n",
    "            output_hidden_states=self.output_hidden_states,\n",
    "            output_attentions=self.output_attentions,\n",
    "            return_dict=True,\n",
    "            **self.hf_model_kwargs\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `HF_BaseModelWrapper` includes some nifty code for just passing in the things your model needs, as not all transformer architectures require/use the same information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class HF_PreCalculatedLoss:\n",
    "    def __call__(self, inp, targ, **kwargs):\n",
    "        return tensor(0.0)\n",
    "\n",
    "    def decodes(self, x):\n",
    "        return x.argmax(dim=-1)\n",
    "\n",
    "    def activation(self, x):\n",
    "        return F.softmax(x, dim=-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to let your Hugging Face model calculate the loss for you, make sure you include the `labels` argument in your inputs and use `HF_PreCalculatedLoss` as your loss function. Even though we don't really need a loss function per se, we have to provide a custom loss class/function for fastai to function properly (e.g. one with a `decodes` and `activation` methods).  Why?  Because these methods will get called in methods like `show_results` to get the actual predictions.\n",
    "\n",
    "**Note**: The Hugging Face models ***will always*** calculate the loss for you ***if*** you pass a `labels` dictionary along with your other inputs (so only include it if that is what you intend to happen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class HF_BaseModelCallback(Callback):\n",
    "    def before_batch(self):\n",
    "        self.hf_loss = None\n",
    "\n",
    "    def after_pred(self):\n",
    "        model_outputs = self.pred\n",
    "        self.learn.blurr_model_outputs = {}\n",
    "\n",
    "        for k, v in model_outputs.items():\n",
    "            # if the \"labels\" are included, we are training with target labels in which case the loss is returned\n",
    "            if k == \"loss\" and isinstance(self.learn.loss_func, HF_PreCalculatedLoss):\n",
    "                self.hf_loss = to_float(v)\n",
    "            # the logits represent the prediction\n",
    "            elif k == \"logits\":\n",
    "                self.learn.pred = v\n",
    "            # add any other things included in model_outputs as blurr_{model_output_key}\n",
    "            else:\n",
    "                self.learn.blurr_model_outputs[k] = v\n",
    "\n",
    "    def after_loss(self):\n",
    "        # if we already have the loss from the model, update the Learner's loss to be it\n",
    "        if self.hf_loss is not None:\n",
    "            self.learn.loss_grad = self.hf_loss\n",
    "            self.learn.loss = self.learn.loss_grad.clone()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a `Callback` for handling what is returned from the Hugging Face model. The return type is (`ModelOutput`)[https://huggingface.co/transformers/main_classes/output.html#transformers.file_utils.ModelOutput] which makes it easy to return all the goodies we asked for.\n",
    "\n",
    "Note that your `Learner`'s loss will be set for you only if the Hugging Face model returns one *and* you are using the `HF_PreCalculatedLoss` loss function.  \n",
    "\n",
    "Also note that anything else you asked the model to return (for example, last hidden state, etc..) will be available for you via the `blurr_model_outputs` property attached to your `Learner`. For example, assuming you are using BERT for a classification task ... if you have told your `HF_BaseModelWrapper` instance to return attentions, you'd be able to access them via `learn.blurr_model_outputs['attentions']`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence classification\n",
    "\n",
    "Below demonstrates how to setup your `blurr` pipeline for a sequence classification task (e.g., a model that requires a single text input) using the mid, high, and low-level API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the mid-level API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset imdb (/home/wgilliam/.cache/huggingface/datasets/imdb/plain_text/1.0.0/4ea52f2e58a08dbc12c2bd52d0d92b30b88c00230b4522801b3636782f625c5b)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>is_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>While the original 1932 version, with Preston Foster, was good, there's no remake more worthy than this 1959 one, or more impossible to find anywhere, just as I strongly suspect Mickey Rooney to have had something to do with that. Never could a mere performance have ever been so masterfully brilliant, or a script more thought-provoking, as well as an improvement upon the original. Many years after the last of my several viewings of this film, in 1970, I read an article in which Mickey Rooney was recounting a visit he'd made to death row, and which had apparently very drastically eliminated...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Ironically the most talked-about American film in the 2008 New York Film Festival is 98% in Spanish. The extra-long film's controversy began at the Cannes Festival. There were love-hate notices, and considerable doubts about commercial prospects. As consolation the star, Benicio Del Toro, got the Best Actor award there. I'm talking about Steven Soderbergh's 'Che,' of course. That's the name it's going by in this version, shown in New York as at Cannes in two 2-hour-plus segments without opening title or end credits. 'Che' is certainly appropriate since Ernesto \"Che\" Guevara is in almost ev...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Bingo is the game, bullshit is the name. Rarely has the screen been smeared with such a blown-up hodgepodge of half-baked conspiracy theories, puritan prudery, and new-age gibberish. The bulk of the story is set at Viciente, a Cristian resort in the Peruvian jungle. Think Tolkien's Rivendell meets Star Trek's Planet Baku, inhabited by dimwitted followers of a not-so-mysterious, but surprisingly narrow-minded cult of love and peace. Thanks to gruesome acting and tacky production design (the rainbow-colored visualization of the mysterious all-healing \"energy\" is particularly hideous), \"The C...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>There are so many reasons as to why I rate the sopranos so highly, one of its biggest triumphs being the cast and character building. Each character unfolds more and more each series. Also each series has an array of different 'small time characters' as well as the main. A good example of a character (who was only in three episodes) who you can feel for is David the compulsive gambler played brilliantly by Robert Patrick. Every little detail builds the perfect TV series. The show revolves round mob boss Tony Soprano (James Gandolfini) who attempts to balance his life of crime with his role...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>I thought watching employment videos on corporate compliance was tedious. This movie went nowhere fast. What could have been a somewhat cheesy half hour twilight zone episode turned into a seemingly endless waste of film on people parking their cars, a picture of some dude's swimming pool (he really needs to answer his phone by the way) a dot matrix printer doing its job, and Heuy and Louey sitting in a yellow lighted control room repeating \"T minus 10 and counting\" as if something exciting is going to happen. It doesn't so don't get your hopes up. The best thing about this movie is to see...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  \\\n",
       "0      1   \n",
       "1      1   \n",
       "2      0   \n",
       "3      1   \n",
       "4      0   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      text  \\\n",
       "0  While the original 1932 version, with Preston Foster, was good, there's no remake more worthy than this 1959 one, or more impossible to find anywhere, just as I strongly suspect Mickey Rooney to have had something to do with that. Never could a mere performance have ever been so masterfully brilliant, or a script more thought-provoking, as well as an improvement upon the original. Many years after the last of my several viewings of this film, in 1970, I read an article in which Mickey Rooney was recounting a visit he'd made to death row, and which had apparently very drastically eliminated...   \n",
       "1  Ironically the most talked-about American film in the 2008 New York Film Festival is 98% in Spanish. The extra-long film's controversy began at the Cannes Festival. There were love-hate notices, and considerable doubts about commercial prospects. As consolation the star, Benicio Del Toro, got the Best Actor award there. I'm talking about Steven Soderbergh's 'Che,' of course. That's the name it's going by in this version, shown in New York as at Cannes in two 2-hour-plus segments without opening title or end credits. 'Che' is certainly appropriate since Ernesto \"Che\" Guevara is in almost ev...   \n",
       "2  Bingo is the game, bullshit is the name. Rarely has the screen been smeared with such a blown-up hodgepodge of half-baked conspiracy theories, puritan prudery, and new-age gibberish. The bulk of the story is set at Viciente, a Cristian resort in the Peruvian jungle. Think Tolkien's Rivendell meets Star Trek's Planet Baku, inhabited by dimwitted followers of a not-so-mysterious, but surprisingly narrow-minded cult of love and peace. Thanks to gruesome acting and tacky production design (the rainbow-colored visualization of the mysterious all-healing \"energy\" is particularly hideous), \"The C...   \n",
       "3  There are so many reasons as to why I rate the sopranos so highly, one of its biggest triumphs being the cast and character building. Each character unfolds more and more each series. Also each series has an array of different 'small time characters' as well as the main. A good example of a character (who was only in three episodes) who you can feel for is David the compulsive gambler played brilliantly by Robert Patrick. Every little detail builds the perfect TV series. The show revolves round mob boss Tony Soprano (James Gandolfini) who attempts to balance his life of crime with his role...   \n",
       "4  I thought watching employment videos on corporate compliance was tedious. This movie went nowhere fast. What could have been a somewhat cheesy half hour twilight zone episode turned into a seemingly endless waste of film on people parking their cars, a picture of some dude's swimming pool (he really needs to answer his phone by the way) a dot matrix printer doing its job, and Heuy and Louey sitting in a yellow lighted control room repeating \"T minus 10 and counting\" as if something exciting is going to happen. It doesn't so don't get your hopes up. The best thing about this movie is to see...   \n",
       "\n",
       "   is_valid  \n",
       "0     False  \n",
       "1     False  \n",
       "2     False  \n",
       "3     False  \n",
       "4     False  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets = load_dataset(\"imdb\", split=['train', 'test'])\n",
    "raw_datasets[0] = raw_datasets[0].add_column('is_valid', [False] * len(raw_datasets[0]))\n",
    "raw_datasets[1] = raw_datasets[1].add_column('is_valid', [True] * len(raw_datasets[1]))\n",
    "\n",
    "final_ds = concatenate_datasets([raw_datasets[0].shuffle().select(range(1000)), raw_datasets[1].shuffle().select(range(200))])\n",
    "imdb_df = pd.DataFrame(final_ds)\n",
    "imdb_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neg', 'pos']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = raw_datasets[0].features['label'].names\n",
    "labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide_output\n",
    "model_cls = AutoModelForSequenceClassification\n",
    "\n",
    "pretrained_model_name = \"distilroberta-base\"  # \"distilbert-base-uncased\" \"bert-base-uncased\"\n",
    "hf_arch, hf_config, hf_tokenizer, hf_model = BLURR.get_hf_objects(pretrained_model_name, model_cls=model_cls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single input\n",
    "set_seed()\n",
    "blocks = (HF_TextBlock(hf_arch, hf_config, hf_tokenizer, hf_model, before_batch_kwargs={\"labels\": labels}), CategoryBlock)\n",
    "dblock = DataBlock(blocks=blocks, get_x=ColReader(\"text\"), get_y=ColReader(\"label\"), splitter=RandomSplitter(seed=42))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "# dblock.summary(imdb_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = dblock.dataloaders(imdb_df, bs=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dls.show_batch(dataloaders=dls, max_n=2, trunc_at=500)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training\n",
    "\n",
    "We'll also add in custom summary methods for blurr learners/models that work with dictionary inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed()\n",
    "\n",
    "model = HF_BaseModelWrapper(hf_model)\n",
    "learn = Learner(\n",
    "    dls,\n",
    "    model,\n",
    "    opt_func=partial(OptimWrapper, opt=torch.optim.Adam),\n",
    "    loss_func=CrossEntropyLossFlat(),\n",
    "    metrics=[accuracy],\n",
    "    cbs=[HF_BaseModelCallback],\n",
    "    splitter=hf_splitter,\n",
    ")\n",
    "\n",
    "learn.freeze()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.to_fp16()` requires a GPU so had to remove for tests to run on github.  Let's check that we can get predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide_output\n",
    "# learn.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(learn.opt.param_groups))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(minimum=3.981071640737355e-05, steep=0.0003311311302240938, valley=6.30957365501672e-05, slide=0.001737800776027143)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find(suggest_funcs=[minimum, steep, valley, slide])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.365132</td>\n",
       "      <td>0.285754</td>\n",
       "      <td>0.879167</td>\n",
       "      <td>00:19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_seed()\n",
    "learn.fit_one_cycle(1, lr_max=1e-3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "epoch\ttrain_loss\tvalid_loss\taccuracy\ttime\n",
    "0\t0.324516\t0.294210\t0.885000\t00:11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Showing results\n",
    "\n",
    "And here we create a @typedispatched implementation of `Learner.show_results`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@typedispatch\n",
    "def show_results(\n",
    "    # This typedispatched `show_results` will be called for `HF_BaseInput` typed inputs\n",
    "    x: HF_BaseInput,\n",
    "    # Your targets\n",
    "    y,\n",
    "    # Your raw inputs/targets\n",
    "    samples,\n",
    "    # The model's predictions\n",
    "    outs,\n",
    "    # Your `Learner`. This is required so as to get at the Hugging Face objects for decoding them into\n",
    "    # something understandable\n",
    "    learner,\n",
    "    # Your `show_results` context\n",
    "    ctxs=None,\n",
    "    # The maximum number of items to show\n",
    "    max_n=6,\n",
    "    # Any truncation your want applied to your decoded inputs\n",
    "    trunc_at=None,\n",
    "    # Any other keyword arguments you want applied to `show_results`\n",
    "    **kwargs,\n",
    "):\n",
    "    # grab our tokenizer\n",
    "    tfm = first_blurr_tfm(learner.dls)\n",
    "    hf_tokenizer = tfm.hf_tokenizer\n",
    "\n",
    "    # if we've included our labels list, we'll use it to look up the value of our target(s)\n",
    "    trg_labels = tfm.kwargs['labels'] if ('labels' in tfm.kwargs) else None\n",
    "\n",
    "    res = L()\n",
    "    n_inp = learner.dls.n_inp\n",
    "\n",
    "    for idx, (input_ids, label, pred, sample) in enumerate(zip(x, y, outs, samples)):\n",
    "        if idx >= max_n:\n",
    "            break\n",
    "\n",
    "        # add in the input text\n",
    "        rets = [hf_tokenizer.decode(input_ids, skip_special_tokens=True)[:trunc_at]]\n",
    "        # add in the targets\n",
    "        for item in sample[n_inp:]:\n",
    "            if not torch.is_tensor(item):\n",
    "                trg = trg_labels[int(item)] if trg_labels else item\n",
    "            elif is_listy(item.tolist()):\n",
    "                trg = [trg_labels[idx] for idx, val in enumerate(label.numpy().tolist()) if (val == 1)] if (trg_labels) else label.item()\n",
    "            else:\n",
    "                trg = trg_labels[label.item()] if (trg_labels) else label.item()\n",
    "\n",
    "            rets.append(trg)\n",
    "        # add in the predictions\n",
    "        for item in pred:\n",
    "            if not torch.is_tensor(item):\n",
    "                p = trg_labels[int(item)] if trg_labels else item\n",
    "            elif is_listy(item.tolist()):\n",
    "                p = [trg_labels[idx] for idx, val in enumerate(item.numpy().tolist()) if (val == 1)] if (trg_labels) else item.item()\n",
    "            else:\n",
    "                p = trg_labels[item.item()] if (trg_labels) else item.item()\n",
    "\n",
    "            rets.append(p)\n",
    "\n",
    "        res.append(tuplify(rets))\n",
    "\n",
    "    cols = [\"text\"] + [\"target\" if (i == 0) else f\"target_{i}\" for i in range(len(res[0]) - n_inp * 2)]\n",
    "    cols += [\"prediction\" if (i == 0) else f\"prediction_{i}\" for i in range(len(res[0]) - n_inp * 2)]\n",
    "    display_df(pd.DataFrame(res, columns=cols)[:max_n])\n",
    "    return ctxs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The title is onomatopoeic, the sound of a streetcar clacking on the rails. It is metaphoric for all that the people who live in the dump cannot have. The misery of those people is illustrated by the passing streetcar which represents the relatively unobtainable rich life of the middle class. The pathos of the little boy and his beloved yet sadly insane father is most touching. This was Kurosawa's first film in colour and he uses beautifully shocking hues, colours seen only in dreams. The movie</td>\n",
       "      <td>pos</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Michael Cacoyannis has had a relatively long career but has surprisingly few credits to his name, including some real duds such as the unfunny cold war satire The Day the Fish Came Out. Iphigenia, however, is a highlight. Adapted by Cacoyannis from the play by Euripides, it's a superior rendering of the classic tragedy and recently made its first television appearance in many years in the United States courtesy the Flix Channel. The film is shot on an epic scale but is decidedly not a 'big' fil</td>\n",
       "      <td>pos</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, max_n=2, trunc_at=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.270743</td>\n",
       "      <td>0.259033</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.194705</td>\n",
       "      <td>0.255097</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>00:28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_seed()\n",
    "learn.fit_one_cycle(2, lr_max=slice(1e-7, 1e-4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "epoch\ttrain_loss\tvalid_loss\taccuracy\ttime\n",
    "0\t0.263290\t0.272322\t0.895000\t00:18\n",
    "1\t0.218568\t0.263317\t0.910000\t00:18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.recorder.plot_loss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The title is onomatopoeic, the sound of a streetcar clacking on the rails. It is metaphoric for all that the people who live in the dump cannot have. The misery of those people is illustrated by the passing streetcar which represents the relatively unobtainable rich life of the middle class. The pathos of the little boy and his beloved yet sadly insane father is most touching. This was Kurosawa's first film in colour and he uses beautifully shocking hues, colours seen only in dreams. The movie</td>\n",
       "      <td>pos</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Michael Cacoyannis has had a relatively long career but has surprisingly few credits to his name, including some real duds such as the unfunny cold war satire The Day the Fish Came Out. Iphigenia, however, is a highlight. Adapted by Cacoyannis from the play by Euripides, it's a superior rendering of the classic tragedy and recently made its first television appearance in many years in the United States courtesy the Flix Channel. The film is shot on an epic scale but is decidedly not a 'big' fil</td>\n",
       "      <td>pos</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, max_n=2, trunc_at=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@patch\n",
    "def blurr_predict(self: Learner, items, rm_type_tfms=None):\n",
    "    # grab our blurr tfm with the bits to properly decode/show our inputs/targets\n",
    "    tfm = first_blurr_tfm(self.dls)\n",
    "    trg_labels = tfm.kwargs['labels'] if ('labels' in tfm.kwargs) else None\n",
    "\n",
    "    is_split_str = tfm.is_split_into_words and isinstance(items[0], str)\n",
    "    is_df = isinstance(items, pd.DataFrame)\n",
    "\n",
    "    if not is_df and (is_split_str or not is_listy(items)):\n",
    "        items = [items]\n",
    "    dl = self.dls.test_dl(items, rm_type_tfms=rm_type_tfms, num_workers=0)\n",
    "\n",
    "    with self.no_bar():\n",
    "        probs, _, decoded_preds = self.get_preds(dl=dl, with_input=False, with_decoded=True)\n",
    "\n",
    "    trg_tfms = self.dls.tfms[self.dls.n_inp:]\n",
    "\n",
    "    outs = []\n",
    "    probs, decoded_preds = L(probs), L(decoded_preds)\n",
    "    for i in range(len(items)):\n",
    "        item_probs = probs.itemgot(i)\n",
    "        item_dec_preds = decoded_preds.itemgot(i)\n",
    "        item_dec_labels = tuplify([tfm.decode(item_dec_preds[tfm_idx]) for tfm_idx, tfm in enumerate(trg_tfms)])\n",
    "        if trg_labels:\n",
    "            item_dec_labels = [trg_labels[int(lbl)] for item in item_dec_labels for lbl in item]\n",
    "\n",
    "        outs.append((item_dec_labels, item_dec_preds, item_probs))\n",
    "\n",
    "    return outs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"Learner.blurr_predict\" class=\"doc_header\"><code>Learner.blurr_predict</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Learner.blurr_predict</code>(**`items`**, **`rm_type_tfms`**=*`None`*)\n",
       "\n",
       "\n",
       "\n",
       "**Parameters:**\n",
       "\n",
       "\n",
       " - **`items`** : *`<class 'inspect._empty'>`*\n",
       "\n",
       " - **`rm_type_tfms`** : *`<class 'NoneType'>`*, *optional*\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Learner.blurr_predict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to replace fastai's `Learner.predict` method with the one above which is able to work with inputs that are represented by multiple tensors included in a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['pos'], (#1) [tensor(1)], (#1) [tensor([0.0601, 0.9399])])]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.blurr_predict(\"I really liked the movie\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['neg'], (#1) [tensor(0)], (#1) [tensor([0.8857, 0.1143])])]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.blurr_predict(\"Acting was so bad it was almost funny.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['pos'], (#1) [tensor(1)], (#1) [tensor([0.0601, 0.9399])]),\n",
       " (['neg'], (#1) [tensor(0)], (#1) [tensor([0.5126, 0.4874])])]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.blurr_predict([\"I really liked the movie\", \"I really hated the movie\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though not useful in sequence classification, we will also add a `blurr_generate` method to `Learner` that uses Hugging Face's `PreTrainedModel.generate` for text generation tasks.  \n",
    "\n",
    "For the full list of arguments you can pass in see [here](https://huggingface.co/transformers/main_classes/model.html#transformers.PreTrainedModel.generate). You can also check out their [\"How To Generate\"](https://github.com/huggingface/blog/blob/master/notebooks/02_how_to_generate.ipynb) notebook for more information about how it all works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@patch\n",
    "def blurr_generate(self: Learner, inp, **kwargs):\n",
    "    \"\"\"Uses the built-in `generate` method to generate the text \n",
    "    (see [here](https://huggingface.co/transformers/main_classes/model.html#transformers.PreTrainedModel.generate)\n",
    "    for a list of arguments you can pass in)\n",
    "    \"\"\"\n",
    "    # grab our blurr tfm with the bits to properly decode/show our inputs/targets\n",
    "    tfm = first_blurr_tfm(self.dls)\n",
    "\n",
    "    # grab the Hugging Face tokenizer from the learner's dls.tfms\n",
    "    hf_config = tfm.hf_config\n",
    "    hf_tokenizer = tfm.hf_tokenizer\n",
    "    tok_kwargs = tfm.tok_kwargs\n",
    "\n",
    "    # grab the text generation kwargs\n",
    "    text_gen_kwargs = tfm.text_gen_kwargs if (len(kwargs) == 0) else kwargs\n",
    "\n",
    "    if isinstance(inp, str):\n",
    "        input_ids = hf_tokenizer.encode(inp, padding=True, truncation=True, return_tensors=\"pt\", **tok_kwargs)\n",
    "    else:\n",
    "        # note (10/30/2020): as of pytorch 1.7, this has to be a plain ol tensor (not a subclass of TensorBase)\n",
    "        input_ids = inp.as_subclass(Tensor)\n",
    "\n",
    "    input_ids = input_ids.to(self.model.hf_model.device)\n",
    "\n",
    "    gen_texts = self.model.hf_model.generate(input_ids, **text_gen_kwargs)\n",
    "    outputs = [hf_tokenizer.decode(txt, skip_special_tokens=True, clean_up_tokenization_spaces=False) for txt in gen_texts]\n",
    "\n",
    "    if tfm.hf_arch == \"pegasus\":\n",
    "        outputs = [o.replace(\"<n>\", \" \") for o in outputs]\n",
    "\n",
    "    return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"Learner.blurr_generate\" class=\"doc_header\"><code>Learner.blurr_generate</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Learner.blurr_generate</code>(**`inp`**, **\\*\\*`kwargs`**)\n",
       "\n",
       "Uses the built-in `generate` method to generate the text \n",
       "(see [here](https://huggingface.co/transformers/main_classes/model.html#transformers.PreTrainedModel.generate)\n",
       "for a list of arguments you can pass in)\n",
       "\n",
       "**Parameters:**\n",
       "\n",
       "\n",
       " - **`inp`** : *`<class 'inspect._empty'>`*\n",
       "\n",
       " - **`kwargs`** : *`<class 'inspect._empty'>`*\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Learner.blurr_generate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_fname = \"seq_class_learn_export\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using fast.ai `Learner.export` and `load_learner`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.export(fname=f\"{export_fname}.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['neg'], (#1) [tensor(0)], (#1) [tensor([0.9423, 0.0577])])]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_learn = load_learner(fname=f\"{export_fname}.pkl\")\n",
    "inf_learn.blurr_predict(\"This movie should not be seen by anyone!!!!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "try:\n",
    "    del learn\n",
    "    del inf_learn\n",
    "    torch.cuda.empty_cache()\n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the high-level API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Blearner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of constructing our low-level `Learner`, we can use the `Blearner` class which provides sensible defaults for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide_output\n",
    "model_cls = AutoModelForSequenceClassification\n",
    "\n",
    "pretrained_model_name = \"distilroberta-base\"  # \"distilbert-base-uncased\" \"bert-base-uncased\"\n",
    "hf_arch, hf_config, hf_tokenizer, hf_model = BLURR.get_hf_objects(pretrained_model_name, model_cls=model_cls)\n",
    "\n",
    "dls = dblock.dataloaders(imdb_df, bs=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@delegates(Learner.__init__)\n",
    "class Blearner(Learner):\n",
    "    def __init__(\n",
    "        self,\n",
    "        # Your fast.ai DataLoaders\n",
    "        dls: DataLoaders,\n",
    "        # Your pretrained Hugging Face transformer\n",
    "        hf_model: PreTrainedModel,\n",
    "        # Your `HF_BaseModelCallback`\n",
    "        base_model_cb: HF_BaseModelCallback = HF_BaseModelCallback,\n",
    "        # Any kwargs you want to pass to your `BLearner`\n",
    "        **kwargs\n",
    "    ):\n",
    "        model = kwargs.get(\"model\", HF_BaseModelWrapper(hf_model))\n",
    "        loss_func = kwargs.pop(\"loss_func\", dls.loss_func if hasattr(dls, \"loss_func\") else None)\n",
    "        splitter = kwargs.pop(\"splitter\", hf_splitter)\n",
    "\n",
    "        super().__init__(dls, model=model, loss_func=loss_func, splitter=splitter, **kwargs)\n",
    "\n",
    "        self.add_cb(base_model_cb)\n",
    "        self.freeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Blearner(dls, hf_model, metrics=[accuracy])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.328734</td>\n",
       "      <td>0.285076</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>00:19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, lr_max=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I love this movie, Jouvet, Arletty, Blier, Carn... almost everything has already been said about the movie, but there is one detail I'd like to shed some light onto: no footage of the real, still standing, Htel du Nord (is it still? I heard it was to be demolished...) has been used for the movie - the whole scene has been rebuilt on set, the main reason being that they could not stop the traffic on the St Martin canal for several weeks.</td>\n",
       "      <td>pos</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The eight Jean Rollin film I have watched is also possibly the weirdest; the intriguing plot (such as it is) seems initially to be too flimsy to sustain even its trim 84 minutes but it somehow contrives to get inordinately muddled as it goes along! A would-be female vampire (scantily-clad, as promised by the title) is held in captivity inside a remote chteau and emerges only to 'feast' on the blood of willing victims (who are apparently members of a suicide club) As if unsure where all of this</td>\n",
       "      <td>neg</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, max_n=2, trunc_at=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['pos'], (#1) [tensor(1)], (#1) [tensor([0.1776, 0.8224])])]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.blurr_predict(\"This was a really good movie\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['neg'], (#1) [tensor(0)], (#1) [tensor([0.8941, 0.1059])])]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.export(fname=f\"{export_fname}.pkl\")\n",
    "inf_learn = load_learner(fname=f\"{export_fname}.pkl\")\n",
    "inf_learn.blurr_predict(\"This movie should not be seen by anyone!!!!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BlearnerForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also introduce a task specific `Blearner` that get you your DataBlock, DataLoaders, and BLearner in one line of code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "try:\n",
    "    del learn\n",
    "    del inf_learn\n",
    "    torch.cuda.empty_cache()\n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@delegates(Blearner.__init__)\n",
    "class BlearnerForSequenceClassification(Blearner):\n",
    "    def __init__(self, dls: DataLoaders, hf_model: PreTrainedModel, **kwargs):\n",
    "        super().__init__(dls, hf_model, **kwargs)\n",
    "\n",
    "    @classmethod\n",
    "    def get_model_cls(self):\n",
    "        return AutoModelForSequenceClassification\n",
    "\n",
    "    @classmethod\n",
    "    def _get_x(cls, r, attr):\n",
    "        return r[attr] if (isinstance(attr, str)) else tuple(r[inp] for inp in attr)\n",
    "\n",
    "    @classmethod\n",
    "    def _get_y(cls, r, attr):\n",
    "        return r[attr] if (isinstance(attr, str)) else [r[inp] for inp in attr]\n",
    "\n",
    "    @classmethod\n",
    "    def _create_learner(\n",
    "        cls,\n",
    "        # Your raw dataset\n",
    "        data,\n",
    "        # The name or path of the pretrained model you want to fine-tune\n",
    "        pretrained_model_name_or_path: Optional[Union[str, os.PathLike]],\n",
    "        # A function to perform any preprocessing required for your Dataset\n",
    "        preprocess_func: Callable = None,\n",
    "        # The attribute in your dataset that contains your raw text\n",
    "        text_attr: str = \"text\",\n",
    "        # The attribute in your dataset that contains your labels/targets\n",
    "        label_attr: str = \"label\",\n",
    "        # The number of labels/classes your model should predict\n",
    "        n_labels: int = 2,\n",
    "        # A function that will split your Dataset into a training and validation set\n",
    "        # See [here](https://docs.fast.ai/data.transforms.html#Split) for a list of fast.ai splitters\n",
    "        dblock_splitter: Callable = RandomSplitter(),\n",
    "        # Any kwargs to pass to your `DataLoaders`\n",
    "        dl_kwargs={},\n",
    "        # Any kwargs to pass to your task specific `Blearner`\n",
    "        learner_kwargs={},\n",
    "    ):\n",
    "        # get our hf objects\n",
    "        hf_arch, hf_config, hf_tokenizer, hf_model = BLURR.get_hf_objects(\n",
    "            pretrained_model_name_or_path, model_cls=cls.get_model_cls(), config_kwargs={\"num_labels\": n_labels}\n",
    "        )\n",
    "\n",
    "        # if we need to preprocess the raw data before creating our DataLoaders\n",
    "        if preprocess_func:\n",
    "            data = preprocess_func(data, hf_arch, hf_config, hf_tokenizer, hf_model, text_attr, label_attr)\n",
    "\n",
    "        # not all architectures include a native pad_token (e.g., gpt2, ctrl, etc...), so we add one here\n",
    "        if hf_tokenizer.pad_token is None:\n",
    "            hf_tokenizer.add_special_tokens({\"pad_token\": \"<pad>\"})\n",
    "            hf_config.pad_token_id = hf_tokenizer.get_vocab()[\"<pad>\"]\n",
    "            hf_model.resize_token_embeddings(len(hf_tokenizer))\n",
    "\n",
    "        # defin our input/target getters\n",
    "        if isinstance(data, pd.DataFrame):\n",
    "            get_x = ColReader(text_attr)\n",
    "            get_y = ColReader(label_attr)\n",
    "        else:\n",
    "            get_x = partial(cls._get_x, attr=text_attr)\n",
    "            get_y = partial(cls._get_y, attr=label_attr)\n",
    "\n",
    "        # infer loss function and default metrics\n",
    "        if is_listy(label_attr):\n",
    "            trg_block = MultiCategoryBlock(encoded=True, vocab=label_attr)\n",
    "            learner_kwargs[\"metrics\"] = learner_kwargs.get(\"metrics\", [F1ScoreMulti(), accuracy_multi])\n",
    "        else:\n",
    "            trg_block = CategoryBlock\n",
    "            learner_kwargs[\"metrics\"] = learner_kwargs.get(\"metrics\", [F1Score(), accuracy])\n",
    "\n",
    "        # build our DataBlock and DataLoaders\n",
    "        blocks = (HF_TextBlock(hf_arch, hf_config, hf_tokenizer, hf_model), trg_block)\n",
    "        dblock = DataBlock(blocks=blocks, get_x=get_x, get_y=get_y, splitter=dblock_splitter)\n",
    "\n",
    "        dls = dblock.dataloaders(data, **dl_kwargs.copy())\n",
    "\n",
    "        # return BLearner instance\n",
    "        return cls(dls, hf_model, **learner_kwargs.copy())\n",
    "\n",
    "    @classmethod\n",
    "    def from_dataframe(\n",
    "        cls,\n",
    "        # Your pandas DataFrame\n",
    "        df: pd.DataFrame,\n",
    "        # The name or path of the pretrained model you want to fine-tune\n",
    "        pretrained_model_name_or_path: Optional[Union[str, os.PathLike]],\n",
    "        # A function to perform any preprocessing required for your Dataset\n",
    "        preprocess_func: Callable = None,\n",
    "        # The attribute in your dataset that contains your raw text\n",
    "        text_attr: str = \"text\",\n",
    "        # The attribute in your dataset that contains your labels/targets\n",
    "        label_attr: str = \"label\",\n",
    "        # The number of labels/classes your model should predict\n",
    "        n_labels: int = None,\n",
    "        # A function that will split your Dataset into a training and validation set\n",
    "        # See [here](https://docs.fast.ai/data.transforms.html#Split) for a list of fast.ai splitters\n",
    "        dblock_splitter: Callable = ColSplitter(),\n",
    "        # Any kwargs to pass to your `DataLoaders`\n",
    "        dl_kwargs={},\n",
    "        # Any kwargs to pass to your task specific `Blearner`\n",
    "        learner_kwargs={},\n",
    "    ):\n",
    "        # we need to tell transformer how many labels/classes to expect\n",
    "        if n_labels is None:\n",
    "            n_labels = len(label_attr) if (is_listy(label_attr)) else len(df[label_attr].unique())\n",
    "\n",
    "        return cls._create_learner(\n",
    "            df, pretrained_model_name_or_path, preprocess_func, text_attr, label_attr, n_labels, dblock_splitter, dl_kwargs, learner_kwargs\n",
    "        )\n",
    "\n",
    "    @classmethod\n",
    "    def from_csv(\n",
    "        cls,\n",
    "        # The path to your csv file\n",
    "        csv_file: Union[Path, str],\n",
    "        # The name or path of the pretrained model you want to fine-tune\n",
    "        pretrained_model_name_or_path: Optional[Union[str, os.PathLike]],\n",
    "        # A function to perform any preprocessing required for your Dataset\n",
    "        preprocess_func: Callable = None,\n",
    "        # The attribute in your dataset that contains your raw text\n",
    "        text_attr: str = \"text\",\n",
    "        # The attribute in your dataset that contains your labels/targets\n",
    "        label_attr: str = \"label\",\n",
    "        # The number of labels/classes your model should predict\n",
    "        n_labels: int = None,\n",
    "        # A function that will split your Dataset into a training and validation set\n",
    "        # See [here](https://docs.fast.ai/data.transforms.html#Split) for a list of fast.ai splitters\n",
    "        dblock_splitter: Callable = ColSplitter(),\n",
    "        # Any kwargs to pass to your `DataLoaders`\n",
    "        dl_kwargs={},\n",
    "        # Any kwargs to pass to your task specific `Blearner`\n",
    "        learner_kwargs={},\n",
    "    ):\n",
    "        df = pd.read_csv(csv_file)\n",
    "\n",
    "        return cls.from_dataframe(\n",
    "            df,\n",
    "            pretrained_model_name_or_path=pretrained_model_name_or_path,\n",
    "            preprocess_func=preprocess_func,\n",
    "            text_attr=text_attr,\n",
    "            label_attr=label_attr,\n",
    "            n_labels=n_labels,\n",
    "            dblock_splitter=dblock_splitter,\n",
    "            dl_kwargs=dl_kwargs,\n",
    "            learner_kwargs=learner_kwargs,\n",
    "        )\n",
    "\n",
    "    @classmethod\n",
    "    def from_dictionaries(\n",
    "        cls,\n",
    "        # A list of dictionaries\n",
    "        ds: List[Dict],\n",
    "        # The name or path of the pretrained model you want to fine-tune\n",
    "        pretrained_model_name_or_path: Optional[Union[str, os.PathLike]],\n",
    "        # A function to perform any preprocessing required for your Dataset\n",
    "        preprocess_func: Callable = None,\n",
    "        # The attribute in your dataset that contains your raw text\n",
    "        text_attr: str = \"text\",\n",
    "        # The attribute in your dataset that contains your labels/targets\n",
    "        label_attr: str = \"label\",\n",
    "        # The number of labels/classes your model should predict\n",
    "        n_labels: int = None,\n",
    "        # A function that will split your Dataset into a training and validation set\n",
    "        # See [here](https://docs.fast.ai/data.transforms.html#Split) for a list of fast.ai splitters\n",
    "        dblock_splitter: Callable = RandomSplitter(),\n",
    "        # Any kwargs to pass to your `DataLoaders`\n",
    "        dl_kwargs={},\n",
    "        # Any kwargs to pass to your task specific `Blearner`\n",
    "        learner_kwargs={},\n",
    "    ):\n",
    "        # we need to tell transformer how many labels/classes to expect\n",
    "        if n_labels is None:\n",
    "            n_labels = len(label_attr) if (is_listy(label_attr)) else len(set([item[label_attr] for item in ds]))\n",
    "\n",
    "        return cls._create_learner(\n",
    "            ds, pretrained_model_name_or_path, preprocess_func, text_attr, label_attr, n_labels, dblock_splitter, dl_kwargs, learner_kwargs\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = BlearnerForSequenceClassification.from_dataframe(\n",
    "    imdb_df, \"distilroberta-base\", text_attr=\"text\", label_attr=\"label\", dl_kwargs={\"bs\": 4}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.383753</td>\n",
       "      <td>0.211999</td>\n",
       "      <td>0.902564</td>\n",
       "      <td>0.905000</td>\n",
       "      <td>00:20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, lr_max=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/miniconda3/envs/blurr/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1495: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Don't be fooled by the plot out-line as it is described on the cover (at least the Swedish version). The story on this seems rather interesting, with speculative hints. Nothing can be further from the truth. This is the absolute most sad movie experience I've ever had... It is plain and right AWFUL and should not be sold or rented to anyone. If you still think the plot seems intriguing, reflect on this: telephones can move, run and kill people as can also any other electric appliance. It can th</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Where to begin.... This hideous excuse for a motion picture makes \"Plan 9 From Outer Space\" look well thought out. The music? It's culled from every single overwrought piece of PD shlock in existence. The focus? Hell, doesn't matter if in one shot there are thirty people standing in the road; the new angle shows a lone Packard with a waitress posing for Argosy Mag shots. Paul Le Mat, Diana Scarwid, Louise Fletcher, Wallace Shawn: fine actors who must have all been starving to death at that poin</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, max_n=2, trunc_at=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('1',), (#1) [tensor(1)], (#1) [tensor([0.1197, 0.8803])])]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.blurr_predict(\"This was a really good movie\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('0',), (#1) [tensor(0)], (#1) [tensor([0.9291, 0.0709])])]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.export(fname=f\"{export_fname}.pkl\")\n",
    "inf_learn = load_learner(fname=f\"{export_fname}.pkl\")\n",
    "inf_learn.blurr_predict(\"This movie should not be seen by anyone!!!!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the low-level API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thanks to the `BlurrDataLoader`, there isn't really anything you have to do to use plain ol' PyTorch or fast.ai `Dataset`s and `DataLoaders` with Blurr.  Let's take a look at fine-tuning a model against Glue's MRPC dataset ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cls = AutoModelForSequenceClassification\n",
    "\n",
    "pretrained_model_name = \"distilroberta-base\"  # \"distilbert-base-uncased\" \"bert-base-uncased\"\n",
    "hf_arch, hf_config, hf_tokenizer, hf_model = BLURR.get_hf_objects(pretrained_model_name, model_cls=model_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset glue (/home/wgilliam/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from blurr.data.core import preproc_hf_dataset\n",
    "\n",
    "raw_datasets = load_dataset(\"glue\", \"mrpc\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5ba79fb2c51402e9e65d9531dac37fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b05699a7fd5341aeb70f0b4216796a73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92c986c5b5fd4bb5bb476c8a58cf7b9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_function(example):\n",
    "    return hf_tokenizer(example[\"sentence1\"], example[\"sentence2\"], truncation=True)\n",
    "\n",
    "\n",
    "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = raw_datasets[\"train\"].features[\"label\"].names\n",
    "\n",
    "trn_dl = BlurrDataLoader(\n",
    "    tokenized_datasets[\"train\"],\n",
    "    hf_arch=hf_arch,\n",
    "    hf_config=hf_config,\n",
    "    hf_tokenizer=hf_tokenizer,\n",
    "    hf_model=hf_model,\n",
    "    preproccesing_func=preproc_hf_dataset,\n",
    "    batch_tfm_kwargs={'labels': label_names},\n",
    "    shuffle=True,\n",
    "    batch_size=8,\n",
    ")\n",
    "\n",
    "val_dl = BlurrDataLoader(\n",
    "    tokenized_datasets[\"validation\"],\n",
    "    hf_arch=hf_arch,\n",
    "    hf_config=hf_config,\n",
    "    hf_tokenizer=hf_tokenizer,\n",
    "    hf_model=hf_model,\n",
    "    preproccesing_func=preproc_hf_dataset,\n",
    "    batch_tfm_kwargs={'labels': label_names},\n",
    "    batch_size=16,\n",
    ")\n",
    "\n",
    "dls = DataLoaders(trn_dl, val_dl)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And with our fast.ai `DataLoaders` in hand, we can train our model's using the high or low-level Blurr API.  The `BlurrDataLoader` class sets up everything so that we can use our objects just as if we built our `DataLoaders` with the mid-level `DataBlock` API.  This means we get back methods like `one_batch`, `show_batch`, `show_results`, etc... with all levels of Blurr's API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = BlearnerForSequenceClassification(dls, hf_model, loss_func=HF_PreCalculatedLoss())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(valley=5.248074739938602e-05)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEKCAYAAAD5MJl4AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAAAoJklEQVR4nO3deZzcVZnv8c9T1dVrks7WWZuQsISQjcWwiIogWwQFVNQggjICMqM4OMJVrzMCOo4zd9wuDBgiBMY7yCIvENC4D7KIDAkYkhC2LCTprJ30lq7q7tqe+0dVN01v6aT711Vd/X2/XvXqrt/vVNVzurrr6XPO75xj7o6IiEhnoVwHICIi+UfJQUREulFyEBGRbpQcRESkGyUHERHpRslBRES6Kcp1AAdr4sSJPnPmzFyHISIyrLz44ot73b2qv+WHXXKYOXMmq1atynUYIiLDipltOZjy6lYSEZFulBxERKQbJQcREelm2I059CSRSFBTU0Nra2uuQ8mZ0tJSqquriUQiuQ5FRApAQSSHmpoaRo8ezcyZMzGzXIcz5Nydffv2UVNTw6xZs3IdjogUgILoVmptbWXChAkjMjEAmBkTJkwY0S0nERlcBZEcgBGbGNqN9PqLDGeptPPytgbyaQuFgkkOw8moUaMAeOutt5g/f36OoxGRXHt2w14uuv3P3Pz4K6TT+ZEgAksOZrbczPaY2bpezl9kZmvMbLWZrTKz9wYVSzdrHoIfzoebx2a+rnloyF5aRKSrumgbAP/5ly184xdr8yJBBNlyuBdY3Mf5PwLHufvxwN8AdwUYy9vWPARPfAkatwGe+frElwaUIL761a9yxx13dNy/+eabueWWWzjrrLM48cQTWbBgAY899lifz5FKpbjxxhs56aSTWLhwIXfeeScAl19++Tsee9lll/H4448fcqwikn9i8RQAS046jPtf2MYND79MKscJIrDk4O5PA3V9nG/2tzvYKoCh+Un88VuQaHnnsURL5vghWrJkCQ8++GDH/Yceeogrr7ySRx99lJdeeoknn3ySr3zlK332J959991UVlaycuVKVq5cyU9+8hM2b97MVVddxT333ANAY2Mjzz33HOeff/4hxyoi+SfWlkkO//ShuXzlnNk88tJ2rn9wNYlUOmcx5fRSVjP7CPBdYBJwQR/lrgGuAZgxY8bAXrSx5uCO98MJJ5zAnj172LFjB7W1tYwbN46pU6fy5S9/maeffppQKMT27dvZvXs3U6ZM6fE5fve737FmzRoefvjhTDiNjbz55puce+65fOELX2DPnj088sgjfOxjH6OoqCCuQBaRrGg8CUBZJMx1Zx1NcVGI7/76NWaML+PG8+bkJKacfsq4+6PAo2Z2OvBt4Oxeyi0DlgEsWrRoYC2Myupsl1IPxwfgkksu4eGHH2bXrl0sWbKE++67j9raWl588UUikQgzZ87s81JTd+e2227jvPPO63bu8ssv57777uOBBx5g+fLlA4pTRPJPLJ6iLBImFMpcdfj59x/Jm3uaWfrUJhbPm8qC6sohjykvrlbKdkEdaWYTA3+xs74JkbJ3HouUZY4PwJIlS3jggQd4+OGHueSSS2hsbGTSpElEIhGefPJJtmzpe0HE8847jx//+MckEgkA3njjDaLRKACf/exn+dGPfgTAvHnzBhSniOSfaFuSipLwO4790wVzmVBRzI0Pv0w8OfTdSzlLDmZ2lGUvzjezE4FiYF/gL7zwE/DhW6HyMMAyXz98a+b4AMybN4/9+/czffp0pk6dymWXXcaqVatYtGgR9913H3Pm9N00vOqqq5g7dy4nnngi8+fP5/Of/zzJZKapOXnyZI499liuvPLKAcUoIvkpFk9RXvzOjpzK8gj/8pEFvLZrP7c/uWHIY7KgJl2Y2f3AGcBEYDdwExABcPelZvZV4AogAbQAN7r7swd63kWLFnnX/RxeffVVjj322EGNP5/EYjEWLFjASy+9RGVl783LQv85iBSqa366iq11MX5z/endzn35wdU88fIOHvvie5g37dC7l8zsRXdf1N/yQV6tdKm7T3X3iLtXu/vd7r7U3Zdmz/+bu89z9+Pd/d39SQwj0R/+8AfmzJnDdddd12diEJHhqyWRoqKk5yHgmz48l7Hlxdz48zVDevVSXow5SO/OPvtstm7dyvXXX5/rUEQkING2JOXF4R7PjS0v5p8vns/6nU0s/dPGIYtJyUFEJMcyYw49JweAxfOncO37j+TdR04YspgK5oJ5dx/Ri8/l04JdInJwovEkFcV9fxx/7YNDO9+hIFoOpaWl7Nu3b8R+QLbv51BaWprrUETkEMTaUpSX9N5yyIWCaDlUV1dTU1NDbW1trkPJmfad4ERk+OlPy2Go5Vc0hygSiWgHNBEZllJppzWR7jbPIdcKoltJRGS4imXXVeo6QzrXlBxERHKoJbtct1oOIiLSIdqRHNRyEBGRrGhbpltJyUFERDq07wLX2/IZuaLkICKSQ+0b/ajlICIiHdq3CFXLQUREOqjlICIi3cSyA9L5NkNayUFEJIdiiUy3UplaDiIi0i7WliIcMkqK8uvjOL+iEREZYaLxzEY/+bblgJKDiEgOxdpSeTfeAEoOIiI5FY0n824vBwgwOZjZcjPbY2brejl/mZmtyd6eM7PjgopFRCRfxeIjr+VwL7C4j/Obgfe7+0Lg28CyAGMREclL0bZk3s1xgACTg7s/DdT1cf45d6/P3n0e0DZmIjLixOKpvJsdDfkz5vA54Ne9nTSza8xslZmtGslbgYpI4YnFk3k3xwHyIDmY2ZlkksNXeyvj7svcfZG7L6qqqhq64EREApYZc8i/5JDTtoyZLQTuAj7o7vtyGYuISC5kxhzUrdTBzGYAjwCXu/sbuYpDRCRX3D075jCCWg5mdj9wBjDRzGqAm4AIgLsvBb4JTADuyM4MTLr7oqDiERHJN/FUmmTa87LlEFhE7n7pAc5fBVwV1OuLiOS7jr0c8nDMIecD0iIiI1XHXg66lFVERNq1ZPePHlGT4EREpG/ReHu3kloOIiKS1b4LnFoOIiLSoaPloDEHERFpF4ur5SAiIl1E29RyEBGRLtRyEBGRbtpbDvk4Q1rJQUQkR2KJJCVFIcIhy3Uo3Sg5iIjkSKwtPzf6ASUHEZGcicbzc4tQUHIQEcmZWFsqL2dHg5KDiEjORONJyvNwLwdQchARyZnMFqFqOYiISCfRtiRlGnMQEZHOMi0HJQcREekkFk/l5UY/oOQgIpIzsXhSLQcREXlbOu2ZlsNIG5A2s+VmtsfM1vVyfo6Z/cXM2szshqDiEBHJRy2J9hVZR17L4V5gcR/n64AvAd8LMAYRkbwU7ViRdYS1HNz9aTIJoLfze9x9JZAIKgYRkXwV61iRdeS1HAaNmV1jZqvMbFVtbW2uwxERGbAR23IYTO6+zN0XufuiqqqqXIcjIjJgsfjIHXMQEZFetCcHtRxERKRDrC3TrZSvLYfAUpaZ3Q+cAUw0sxrgJiAC4O5LzWwKsAoYA6TN7Hpgrrs3BRWTiEi+iLZ3K+VpyyGwqNz90gOc3wVUB/X6IiL5LNYxIJ2fLQd1K4mI5EC0TWMOIiLSRSyexAxKI/n5MZyfUYmIFLhodotQM8t1KD1SchARyYFYPJm34w2g5CAikhOxeIqKPN3LAZQcRERyQi0HERHppn3MIV8pOYiI5EAsnqRMLQcREeksGk/l7dIZoOQgIpITsbZk3k6AAyUHEZGciMZTVKhbSUREOmuJpyjXpawiItIunkwTT6XVchARkbe15PlGP6DkICIy5Nr3j9bVSiIi0qF9L4cytRxERKRd+14OGnMQEZEO0Y5d4NRyEBGRrFh7y0FjDiIi0i6WGMFXK5nZcjPbY2brejlvZnarmW0wszVmdmJQsYiI5JNY28i+WuleYHEf5z8IHJ29XQP8OMBYRETyRnQkz3Nw96eBuj6KXAT81DOeB8aa2dSg4hERyRf7mtsIh2z4X61kZhVmFsp+P9vMLjSzyABfezqwrdP9muyxnl7/GjNbZWaramtrB/iyIiK5tW5HE7Mnj6YonL/Dvv2N7Gmg1MymA38EriTTbTQQ1sMx76mguy9z90XuvqiqqmqALysikjvuztqaBhZOr8x1KH3qb3Iwd48BHwVuc/ePAHMH+No1wGGd7lcDOwb4nCIieW17Qwv1sQTzqwskOZjZu4HLgF9ljw10JOVx4IrsVUunAo3uvnOAzykiktfW1jQC5H3Lob8f8NcDXwcedfdXzOwI4Mm+HmBm9wNnABPNrAa4CYgAuPtSYAVwPrABiJHpqhIRKWhrtjcSCRtzpo7OdSh96ldycPengKcAsgPTe939Swd4zKUHOO/AF/oZp4hIQVi3vZHZk0dTUpS/VypB/69W+pmZjTGzCmA98LqZ3RhsaCIihcXdWVPTyMI8H2+A/o85zHX3JuBiMt1BM4DLgwpKRKQQ1dS30NiSYH6ejzdA/5NDJDuv4WLgMXdP0MtlpyIi0rM1HYPRY3MbSD/0NzncCbwFVABPm9nhQFNQQYmIFKI12xsoDoeYPWVUrkM5oP4OSN8K3Nrp0BYzOzOYkERECtO67Y0cMyX/B6Oh/wPSlWb2g/YlLMzs+2RaESIi0g+ZmdGNLBgGg9HQ/26l5cB+4BPZWxNwT1BBiYgUmq11MZpakywYBoPR0P9JcEe6+8c63b/FzFYHEI+ISEFqH4weLsmhvy2HFjN7b/sdM3sP0BJMSCIihWft9sbMYPTk/J4Z3a6/LYdrgZ+aWXvKqwc+E0xIIiKFZ21NI8dOHU1xUf4u091Zv6J095fd/ThgIbDQ3U8APhBoZCIiBSKddtZtHz6D0XCQO8G5e1N2pjTAPwQQj4hIwdlSF2N/2/AZjIaBbRPa02Y9IiIjXiKVprElQWZ9UVhT0wDAgmEwM7rdQPZk0PIZIiI9uPKelTy7YS9lkTCTx5QQT6YpLgpx9OT8nxndrs/kYGb76TkJGFAWSEQiIsPcptpmFlZXcvLM8eze38buxlYuWDiVSB7vGd1Vn8nB3YfHNVciInmkPpbggoVT+cYFA91NOXeGTxoTERkGWhMpWhIpxpYX5zqUAVFyEBEZRA2xBADjlBxERKRdfSwOwLjySI4jGRglBxGRQdSeHNSt1AczW2xmr5vZBjP7Wg/nx5nZo2a2xsxeMLP5QcYjIhK0jm6lCrUcemRmYeB24IPAXOBSM+s6dP+/gdXuvhC4Avi/QcUjIjIU3u5WUsuhNycDG9x9k7vHgQeAi7qUmQv8EcDdXwNmmtnkAGMSEQlUe8uhskwth95MB7Z1ul+TPdbZy8BHAczsZOBwoLrrE5nZNe270NXW1gYUrojIwNVH45RFwpRG8n8r0L4EmRx6Wnup62zrfwXGZTcOug74K5Ds9iD3Ze6+yN0XVVVVDXqgIiKDpT6WGPZXKsHA1lY6kBrgsE73q4EdnQtkV3i9EsDMDNicvYmIDEsNsfiwv1IJgm05rASONrNZZlYMLAEe71zAzMZmzwFcBTzdaUlwEZFhpz4WH/ZXKkGALQd3T5rZF4HfAmFgubu/YmbXZs8vBY4ls8NcClgPfC6oeEREhkJDLMHUscN/XdIgu5Vw9xXAii7Hlnb6/i/A0UHGICIylOpj8YIYc9AMaRGRQZJOO40tiWE/xwGUHEREBk1Ta4K0D/+lM0DJQURk0NR3rMiqbiUREckqlKUzQMlBRGTQNHSsyKqWg4iIZNVHC2OjH1ByEBEZNA0tSg4iItJFQyxOyGB0aaBTyIaEkoOIyCCpz66rFAr1tO7o8KLkICIySOpjiYIYjAYlBxGRQdMQixfEeAMoOYiIDJr6aGHs5QBKDiIig6ZQ9nIAJQcRkUFTKLvAgZKDiMigaE2kaEmk1HIQEZG3NcQKZwIcKDmIiAyKtxfdU7eSiIhk1XcsuqeWg4iIZHV0K1Wo5SAiIlmFtJcDBJwczGyxmb1uZhvM7Gs9nK80syfM7GUze8XMrgwyHhGRoLS3HCrL1HLok5mFgduBDwJzgUvNbG6XYl8A1rv7ccAZwPfNrDDSroiMKPXROGWRMKWRcK5DGRRBthxOBja4+yZ3jwMPABd1KePAaDMzYBRQByQDjElEJBCFNAEOgk0O04Ftne7XZI919h/AscAOYC3w9+6e7vpEZnaNma0ys1W1tbVBxSsicsgKaekMCDY59LSguXe5fx6wGpgGHA/8h5mN6fYg92XuvsjdF1VVVQ12nCIiA1YfixfMlUoQbHKoAQ7rdL+aTAuhsyuBRzxjA7AZmBNgTCIigWiIJdRy6KeVwNFmNis7yLwEeLxLma3AWQBmNhk4BtgUYEwiIoGoj8ULaswhsI1O3T1pZl8EfguEgeXu/oqZXZs9vxT4NnCvma0l0w31VXffG1RMIiJBSKedxpZEwcxxgACTA4C7rwBWdDm2tNP3O4Bzg4xBRCRoTa0J0l44S2eAZkiLiAzY2yuyFk63kpKDiMgAFdrSGaDkICIyYO0th7FqOYiISDu1HEREpJv6AtsFDpQcREQGrCEWJ2QwujTQC0CHlJKDiMgA1WfXVQqFelo1aHhSchARGaD6WKKgBqNByUFEZMAaYvGCGm8AJQcRkQGrjxbWXg6g5CAiMmCFtpcDKDmIiAxIOu3UFdiKrKDkICIyIH/ZtI/WRJr50ytzHcqgUnIQERmAB1duo7IswnnzpuQ6lEGl5CAicogaYwl+88ouLj5+GqWRcK7DGVRKDiIih+gXq7cTT6b5xEmHHbjwMKPkICJyiB5cuY3508cwb1phjTeAkoOIyCFZt72R9Tub+OSiwms1gJKDiMg7tCZSvLqzCXfvs9yDK7dRUhTiwuOnD1FkQ6twlhAUERmgaFuSK5a/wItb6jlhxlg+f/qRnDN3MuEuC+q1JlL8YvV2Pjh/CpVlhTW/oV2gLQczW2xmr5vZBjP7Wg/nbzSz1dnbOjNLmdn4IGMSEelJLJ7kyntXsnpbA1e/bxb7muNc+18vcvYPnuK/nt9CQ3ZDH4DfrNvF/tZkQQ5Et7MDNZ0O+YnNwsAbwDlADbASuNTd1/dS/sPAl939A30976JFi3zVqlWDHa6IjGCtiRR/c+9Knt+0jx8tOYELj5tGKu38Zt0ulj61kbXbGwmHjFNmjefcuZN5Ys1O9uxv5akbzhw2y3Sb2Yvuvqi/5YPsVjoZ2ODumwDM7AHgIqDH5ABcCtwfYDwiIt20JlJc/dNV/GXTPr7/8eO48LhpAIRDxgULp3L+gims3d7Ib1/ZxW9f2c3NT2Q+wr5yzuxhkxgORZDJYTqwrdP9GuCUngqaWTmwGPhiL+evAa4BmDFjxuBGKSIjTjKVZtWWen6/fje/W7+LbXUt/NvHFvDRE6u7lTUzFlaPZWH1WG48bw4ba5tZubmOC4+floPIh06QyaGnlNpbH9aHgT+7e11PJ919GbAMMt1KgxOeiIw02+pi/PipjaxYu5OGWILicIjTjprAP14wt9/LXxxZNYojq0YFHGnuBZkcaoDOozXVwI5eyi5BXUoiEpBtdTHu+NMGfr6qhpBluovOnTuZ982uYlSJLtrsSZA/lZXA0WY2C9hOJgF8qmshM6sE3g98OsBYRGQE2rw3yrKnN3YkhU+dMoO/PeNIplaW5Tq0vBdYcnD3pJl9EfgtEAaWu/srZnZt9vzSbNGPAL9z92hQsYjIyPLytgaWPrWR37yyi0g4xKUnz+DvzlRSOBiBXcoaFF3KKjLy7Gps5dfrdrJi7U5e27WfceXFTBhVzISKYsaURUinnUTaSSTT7NnfxuptDYwuLeLyUw/ns++ZyaTRpbmuQs7l06WskofcnQ17mtnd1Ma4iggTKkoYX1FMcdHBz4d0d9qSaZrbksTaUoTDxoSK4oJbuliGRjKV5o3dzWxvaKE+GqcuFqc+GufFLfWs2lIPwJwpo7no+Gnsb02yrznO9oZWXt25n3DIiISNSDhEaSTMN84/liUnH8bo0sKcvTwURkxy2LCnmbuf3cQtF84/pA/CoMWTafa3JtjfmmR3UysbapvZuCfKxtpmdje1Eg4ZReEQRSGjOByioiTMqJIiKkqKGFVaxLjyYsaVRzJfK4oJmZFMpUll/6PasKeZFzbvY+Vb9dRF491ev6I4TFlxEWXFIcojRUSKjJZ4ilg8RXNbkpZ4CoCQGaFQ5mtbMvP8XZUXh5kwqpjJo0s5oqqCI6pGccTECg6fUEFlWYRRpUVUFIcxC+4a8dZEijU1jby+q4nDJ1SwYHol4yoKa4/f4SyVdrbWxXhtZxMv1zTy1631rKlppCWReke54qIQR1WN4ivnzOb8hVNHxFVC+WLEJIea+hj3v7CNOVPG8JnTZuY6HJpaEzy2egcPrdzGm3v205pIdytTFglzRFUF1ePKcc98yKfSaeLJNDsaEjS3JYm2JdnfmiSe6v74rmaML+cDcyZx8qzxzBhfTn00zr5onLponIZYgpZEitZEipZ4irZkivLiIsqLw1SUZL6aQSqdaTGk0k5JJERFSREVxZkklUylO56vLhpne0ML//1aLQ+tqukWS8igoqSIopARDhkhM4pCxuTKUg4fX86MCRUcPr6corARbUsRiydpbkuSdigpClEcDlFcFCIcso54Ug710Tgr36rjr9saiCff+TOZPraMBdMrWVBdydxpY5g/rZKq0SW9/8DWPAR//BY01kBlNZz1TVj4iQO/uQLAxtpm7npmE23JNIYRskxS2FjbzBu7mzsSQSRszJtWySdPOowTZoxl1sQKxlcUM76imLJIsP9ESO9GzJiDu7Nk2fNsrG3mqRvPpGKILl+LtiVpbEkQbUsSjaeoj8VZsWYnv1yzk5ZEirlTx/CeoyYwpjTCmLIIo0uLmDiqhCMnjWLqmNJ+zcB0d1oSqY4P+bponLQ7kWxLoygcYtrY0pwNxjW2JNi8N8q2uhj7W5MdLaTmtmT2Q91Jp514Ks3Ohla21sXY0djCofxqhgzmT6/k5JnjOXnWeOZOG8PWfTHWbm9kzfZG1m1vZMu+WEf5SaNLmDiqJJOgQkbYYPq4cj5V9jynrLuFULLl7SePlMGHbx2RCaKpNcE9z77F+IoIS06eQSTcd+v71Z1NfPqu/6ElkWJceabF5u6YGTMnlnPM5DHMmTqaOVNGM3vyaHVFDoGDHXMYMckB4KWt9Xz0juf4yjmzue6so7udT6WdWDxJWzLz33lbMs3UytJef3GTqTQ7G1uZOKqEsuK3y+xoaOG3r+zi1+t2seqtOrr2vFQUh7nw+OlcevJhLJheqf+MetCWTLGjoZVU2hlVUkR5SZiK4iJCBvFU5v2JZ7u1QtmWR9iMkkjogB80Ta0J1u9oyqzHv6OJptZER8sjlU7z5u5mHmn7PNWhvd0e21o+jW2feYHqceXveM8LlbvzyzU7+dYv11O7vw2AoyaN4psfmsvps6t6fMzL2xq4YvkLlEXC3Hf1KeoKyhNKDgdwzU9X8ZeN+3jqf53J+E590G/u3s8Vy19gZ2PrO8qPK4/wuffO4orTZjImO7gVT6Z55KUa7vjTRrbWZf4LHVNaxOQxpYRDxmu79gNwzOTRnDtvMtXjyigvLqIi+wE3b3qlJt7kMXeHW8ZhPUzoT7txRNt9AEwcVcKM8WXMnFDB+4+p4gNzJhXUAOjmvVG++dg6nnlzL/Onj+E7Fy+gdn8b3/7Verbsi3H2sZP5uzOPZPbk0R2/zyvfquPKe1YyriLCz646lcPGl+e4FtJOyeEA3ti9n8U/eprPvXcW37hgLgBv7Y3yiTv/ggNXv28WZZFwtj87xIq1O/nv1/YwurSIK0+byYRRJdz51EZ2NLaysLqSj7+rmv1tSXY3trKrqZVoW4rTjprA4nlTOEL/MQ1fP5wPjdu6HW6rmM5vzvk9NfUtbN0XY1t9jDd272dvc5zicIjTZ09k8fzMYm3lxfn9D0BTa6LjH56ufrNuF9c/+FcioRA3nHcMnz718I49DdqSKe7581vc9sc3iWYvVJg0uoSZEytYW9PI1MpS7rv6FM0pyDNKDv1ww89f5vGXd/CnG84g7c4n73yelkSKB645ldmTR3crv257I7c/uYFfr9uVieHwcVx31tGcfvREdQkVqjUPwRNfgsSBxxzSaeelrfX8et0ufr12JzsaWxlbHuGKUw/nitNmMnFUH4PefUik0ry4pZ7/fm0P67Y38smTDuPC46YNyu/cXc9s4jsrXuWKUw/nhvOO6WjxuDt3P7uZ76x4leOqx3Ln5e9i8pie5wjsbW5j1Vt1bNobZXNtlM17o1SUFPG9jx/X90C/5ISSQz/U1Mf4wPee4sw5Vby2az/10Tg/u/pU5k/ve5PwDXuaibYlWVitcYIR4RCuVnJ3Vr5Vz13PbOL3r+6mOBzikndVc/6CqRxRVcGUMaU9/u7sb02wZV+MrXUxtuyLsX5nE0+9voem1iSRsDFpdCnbG1p4/+wq/vni+QPqrnlj934+dOuzTBtbypa6GJNHl/Kti+bxgTmTuOWJ9fy/57fwwflT+OEnj9dAcQFRcuinbz2xnuV/3kxFcZj/uuoUTpgxbhCiE3nbhj2ZSzkfeWl7x6XG5cVhZk2sYFRJEY0tCRpbEh2XEXc2eUwJpx9dxVnHTuK9R1dRFgnzn8+9xfd+9zru8A/nzObSU2Yc9NhVIpXmo3c8x/aGFn735dPZVhfj64+s5bVd+6keV0ZNfQvXnH4EX1s8p6D3KhiJlBz6qS4a5xuPruXK98zi5FnamVSCUx+N8+rOJjbujbKptpmNtVFa4knGlhcztizC2PIIE0aVZOd3lHP4hIpeP/S3N7Rw02Pr+MOrezCDIyZmJvjNn17J4vlTqB7Xd4vitj++yfd//wZ3XHYi5y+YCmQSxt3PbubuZzfz92cdzadPPXzQfwaSe0oOIgXO3Xl+Ux0r36pjTU1m7sauplbKImFuOO8YPnvazI7B487W72jiotufZfH8qdx26Qk5iFxySWsriRQ4M+PdR07g3UdO6Di2dV+Mmx5fx7d/uZ5frdnB/7lkIUdNevviingyzT88tJqx5cV868J5uQhbhhm1HEQKhLvzi9XbueWJ9cTaUpw+eyJNLUn2RdvY2xynsSXBXVcs4uy5k3MdquSAWg4iI5SZ8ZETqnnvUVX8y4pXWbe9kfEVxRwzZTTvrijmXYePU2KQflNyECkwVaNL+OEnj891GDLM5d/a1SIiknNKDiIi0o2Sg4iIdKPkICIi3QSaHMxssZm9bmYbzOxrvZQ5w8xWm9krZvZUkPGIiEj/BHa1kpmFgduBc4AaYKWZPe7u6zuVGQvcASx2961mNimoeEREpP+CbDmcDGxw903uHgceAC7qUuZTwCPuvhXA3fcEGI+IiPRTkMlhOtB5t5Sa7LHOZgPjzOxPZvaimV3R0xOZ2TVmtsrMVtXW1gYUroiItAtyElxP6/12XaujCHgXcBZQBvzFzJ539zfe8SD3ZcAyADOrNbMtnU5XAo39/H4i0H1j4P7r/JyHUqanc12PHUx9YGB1Gur6dL3f/v1Q1qevcqpPfv8NjcT6dD02kPoc3HK77h7IDXg38NtO978OfL1Lma8BN3e6fzfw8YN8nWX9/R5YNcA6LRtImZ7OdT12MPUZaJ2Guj59vC9DVp++yqk++f03NBLr0586DGZ9Ot+C7FZaCRxtZrPMrBhYAjzepcxjwPvMrMjMyoFTgFcP8nWeOMjvB6I/z9NXmZ7OdT1WyPXpev+JXsocqv4+T2/lVJ/8/p0bifXpeizo+nQIdFVWMzsf+BEQBpa7+3fM7FoAd1+aLXMjcCWQBu5y9x8FGM8qP4hVCYeDQquT6pPfVJ/8Npj1CXThPXdfAazocmxpl/v/Dvx7kHF0smyIXmcoFVqdVJ/8pvrkt0Grz7Dbz0FERIKn5TNERKQbJQcREelGyUFERLpRcsgys/eZ2VIzu8vMnst1PANlZiEz+46Z3WZmn8l1PAOVXaDxmex7dEau4xkMZlaRXRngQ7mOZTCY2bHZ9+dhM/vbXMczUGZ2sZn9xMweM7Nzcx3PQJnZEWZ2t5k93J/yBZEczGy5me0xs3Vdjh9wVdh27v6Mu18L/BL4zyDjPZDBqA+ZdaymAwkyS5fkzCDVx4FmoJTCqA/AV4GHgony4AzS39Cr2b+hTwA5vTx0kOrzC3e/Gvgs8MkAwz2gQarPJnf/XL9fdLBm0+XyBpwOnAis63QsDGwEjgCKgZeBucACMgmg821Sp8c9BIwZ7vUhM/v889nHPlwA9QllHzcZuK8A6nM2mYmhnwU+lMv6DFadso+5EHgO+FQh1Cf7uO8DJxZQffr1eRDoPIeh4u5Pm9nMLoc7VoUFMLMHgIvc/btAj814M5sBNLp7U5DxHshg1MfMaoB49m4qwHAPaLDen6x6oCSQQPtpkN6fM4EKMn/MLWa2wt3TwUbeu8F6j9z9ceBxM/sV8LMAQ+7TIL1HBvwr8Gt3fyngkPs0yH9D/VIQyaEXPa0Ke8oBHvM54J7AIhqYg63PI8BtZvY+4OkgAztEB1UfM/socB4wFviPQCM7NAdVH3f/BoCZfRbYm8vE0IeDfY/OAD5KJnmv6K1cDh3s39B1ZFp4lWZ2lHeZwJsHDvb9mQB8BzjBzL6eTSK9KuTk0J9VYd950v2mgGIZDAdVH3ePkUl2+epg6/MImYSXrw769w3A3e8d/FAGzcG+R38C/hRUMIPgYOtzK3BrcOEM2MHWZx9wbX+fvCAGpHtRAxzW6X41sCNHsQwG1Se/FVp9oPDqpPochEJODv1ZFXY4UX3yW6HVBwqvTqrPwcjlCPwgjuTfD+zk7cs2P5c9fj7wBpkR/W/kOk7VR/XJ11uh1Un1GfhNC++JiEg3hdytJCIih0jJQUREulFyEBGRbpQcRESkGyUHERHpRslBRES6UXKQgmBmzUP8eoOy50d2n4pGM/urmb1mZt/rx2MuNrO5g/H6Ir1RchDpgZn1ue6Yu582iC/3jLufAJwAfMjM3nOA8heTWc1VJDCFvPCejHBmdiRwO1AFxICr3f01M/sw8I9k1sDfB1zm7rvN7GZgGjAT2GtmbwAzyKyXPwP4kWcWY8PMmt19VHYl0puBvcB84EXg0+7uZnY+8IPsuZeAI9y916WU3b3FzFaTWW0TM7sauCYb5wbgcuB4MnsmvN/M/hH4WPbh3ep5qD83EVDLQQrbMuA6d38XcANwR/b4s8Cp2f/WHwD+V6fHvIvMmvifyt6fQ2ap8JOBm8ws0sPrnABcT+a/+SOA95hZKXAn8EF3fy+ZD+4+mdk44GjeXmL9EXc/yd2PA14ls2TCc2TWz7nR3Y9394191FPkkKnlIAXJzEYBpwE/z+zZAry9SVA18KCZTSXzX/nmTg993N1bOt3/lbu3AW1mtofMTnRdtyl9wd1rsq+7mkzLoxnY5O7tz30/mVZAT95nZmuAY4B/dfdd2ePzzeyfyexhMQr47UHWU+SQKTlIoQoBDe5+fA/nbgN+4O6Pd+oWahftUrat0/cpev6b6alMT2vt9+YZd/+Qmc0GnjWzR919NXAvcLG7v5zdFOiMHh7bVz1FDpm6laQgeWar181m9nHIbPloZsdlT1cC27PffyagEF4Djui0teMBN6h39zeA7wJfzR4aDezMdmVd1qno/uy5A9VT5JApOUihKDezmk63fyDzgfo5M3sZeAW4KFv2ZjLdMM+QGSwedNmuqb8DfmNmzwK7gcZ+PHQpcLqZzQL+Cfgf4Pdkkk27B4Abs5e/Hknv9RQ5ZFqyWyQgZjbK3ZuzG9XfDrzp7j/MdVwi/aGWg0hwrs4OUL9CpivrztyGI9J/ajmIiEg3ajmIiEg3Sg4iItKNkoOIiHSj5CAiIt0oOYiISDdKDiIi0s3/BwsrG52vas0wAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.523373</td>\n",
       "      <td>0.480889</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, lr_max=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.528208</td>\n",
       "      <td>0.481631</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.491082</td>\n",
       "      <td>0.481725</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(2, lr_max=slice(1e-8, 1e-6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Spansion products are to be available from both AMD and Fujitsu, AMD said. Spansion Flash memory solutions are available worldwide from AMD and Fujitsu.</td>\n",
       "      <td>equivalent</td>\n",
       "      <td>equivalent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>However, EPA officials would not confirm the 20 percent figure. Only in the past few weeks have officials settled on the 20 percent figure.</td>\n",
       "      <td>not_equivalent</td>\n",
       "      <td>not_equivalent</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, max_n=2, trunc_at=500)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests\n",
    "\n",
    "The tests below to ensure the core training code above works for **all** pretrained sequence classification models available in Hugging Face.  These tests are excluded from the CI workflow because of how long they would take to run and the amount of data that would be required to download.\n",
    "\n",
    "**Note**: Feel free to modify the code below to test whatever pretrained classification models you are working with ... and if any of your pretrained sequence classification models fail, please submit a github issue *(or a PR if you'd like to fix it yourself)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "try:\n",
    "    del learn\n",
    "    del inf_learn\n",
    "    torch.cuda.empty_cache()\n",
    "except:\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AlbertForSequenceClassification',\n",
       " 'BartForSequenceClassification',\n",
       " 'BertForSequenceClassification',\n",
       " 'BigBirdForSequenceClassification',\n",
       " 'BigBirdPegasusForSequenceClassification',\n",
       " 'CTRLForSequenceClassification',\n",
       " 'CamembertForSequenceClassification',\n",
       " 'CanineForSequenceClassification',\n",
       " 'ConvBertForSequenceClassification',\n",
       " 'DebertaForSequenceClassification',\n",
       " 'DebertaV2ForSequenceClassification',\n",
       " 'DistilBertForSequenceClassification',\n",
       " 'ElectraForSequenceClassification',\n",
       " 'FNetForSequenceClassification',\n",
       " 'FlaubertForSequenceClassification',\n",
       " 'FunnelForSequenceClassification',\n",
       " 'GPT2ForSequenceClassification',\n",
       " 'GPTJForSequenceClassification',\n",
       " 'GPTNeoForSequenceClassification',\n",
       " 'HubertForSequenceClassification',\n",
       " 'IBertForSequenceClassification',\n",
       " 'LEDForSequenceClassification',\n",
       " 'LayoutLMForSequenceClassification',\n",
       " 'LayoutLMv2ForSequenceClassification',\n",
       " 'LongformerForSequenceClassification',\n",
       " 'MBartForSequenceClassification',\n",
       " 'MPNetForSequenceClassification',\n",
       " 'MegatronBertForSequenceClassification',\n",
       " 'MobileBertForSequenceClassification',\n",
       " 'OpenAIGPTForSequenceClassification',\n",
       " 'PerceiverForSequenceClassification',\n",
       " 'ReformerForSequenceClassification',\n",
       " 'RemBertForSequenceClassification',\n",
       " 'RoFormerForSequenceClassification',\n",
       " 'RobertaForSequenceClassification',\n",
       " 'SEWDForSequenceClassification',\n",
       " 'SEWForSequenceClassification',\n",
       " 'SqueezeBertForSequenceClassification',\n",
       " 'TransfoXLForSequenceClassification',\n",
       " 'UniSpeechForSequenceClassification',\n",
       " 'UniSpeechSatForSequenceClassification',\n",
       " 'Wav2Vec2ForSequenceClassification',\n",
       " 'WavLMForSequenceClassification',\n",
       " 'XLMForSequenceClassification',\n",
       " 'XLMRobertaForSequenceClassification',\n",
       " 'XLNetForSequenceClassification']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hide\n",
    "[model_type for model_type in BLURR.get_models(task=\"SequenceClassification\") if (not model_type.startswith(\"TF\"))]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "pretrained_model_names = [\n",
    "    \"hf-internal-testing/tiny-albert\",\n",
    "    \"hf-internal-testing/tiny-random-bart\",\n",
    "    \"hf-internal-testing/tiny-bert\",\n",
    "    \"hf-internal-testing/tiny-random-big_bird\",\n",
    "    \"hf-internal-testing/tiny-random-bigbird_pegasus\",\n",
    "    \"hf-internal-testing/tiny-random-ctrl\",\n",
    "    \"camembert-base\",\n",
    "    \"hf-internal-testing/tiny-random-canine\",\n",
    "    \"YituTech/conv-bert-base\",\n",
    "    \"hf-internal-testing/tiny-deberta\",\n",
    "    \"hf-internal-testing/tiny-random-deberta-v2\",\n",
    "    \"hf-internal-testing/tiny-random-distilbert\",\n",
    "    \"hf-internal-testing/tiny-electra\",\n",
    "    \"google/fnet-base\",\n",
    "    \"hf-internal-testing/tiny-random-flaubert\",\n",
    "    \"hf-internal-testing/tiny-random-funnel\",\n",
    "    \"hf-internal-testing/tiny-random-gpt2\",\n",
    "    \"hf-internal-testing/tiny-random-gptj\",\n",
    "    \"hf-internal-testing/tiny-random-gpt_neo\",\n",
    "    \"hf-internal-testing/tiny-random-hubert\",\n",
    "    \"kssteven/ibert-roberta-base\",\n",
    "    \"hf-internal-testing/tiny-random-led\",\n",
    "    \"hf-internal-testing/tiny-layoutlm\",\n",
    "    \"microsoft/layoutlmv2-base-uncased\",\n",
    "    \"hf-internal-testing/tiny-random-longformer\",\n",
    "    \"hf-internal-testing/tiny-random-mbart\", \n",
    "    \"hf-internal-testing/tiny-random-mpnet\",\n",
    "    \"anton-l/megatron-11b\",                            \n",
    "    \"hf-internal-testing/tiny-random-mobilebert\",\n",
    "    \"openai-gpt\",\n",
    "    \"hf-internal-testing/tiny-random-reformer\",\n",
    "    \"google/rembert\",\n",
    "    \"hf-internal-testing/tiny-random-roformer\",\n",
    "    'google/reformer-enwik8',    \n",
    "    \"hf-internal-testing/tiny-random-roberta\",\n",
    "    \"hf-internal-testing/tiny-random-squeezebert\",\n",
    "    \"hf-internal-testing/tiny-random-transfo-xl\",\n",
    "    \"hf-internal-testing/tiny-random-xlm\",\n",
    "    \"hf-internal-testing/tiny-xlm-roberta\",\n",
    "    \"hf-internal-testing/tiny-random-xlnet\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset imdb (/home/wgilliam/.cache/huggingface/datasets/imdb/plain_text/1.0.0/4ea52f2e58a08dbc12c2bd52d0d92b30b88c00230b4522801b3636782f625c5b)\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "raw_datasets = load_dataset(\"imdb\", split=['train', 'test'])\n",
    "raw_datasets[0] = raw_datasets[0].add_column('is_valid', [False] * len(raw_datasets[0]))\n",
    "raw_datasets[1] = raw_datasets[1].add_column('is_valid', [True] * len(raw_datasets[1]))\n",
    "\n",
    "final_ds = concatenate_datasets([raw_datasets[0].shuffle().select(range(1000)), raw_datasets[1].shuffle().select(range(200))])\n",
    "imdb_df = pd.DataFrame(final_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== hf-internal-testing/tiny-albert ===\n",
      "\n",
      "architecture:\talbert\n",
      "tokenizer:\tAlbertTokenizerFast\n",
      "model:\t\tAlbertForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i have to say i was pleasantly surprised by this movie. other than the mother being a complete moron on a few oc</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i was on my way out one morning when i was checking something on the t.v. and came across this film. i don'</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== hf-internal-testing/tiny-random-bart ===\n",
      "\n",
      "architecture:\tbart\n",
      "tokenizer:\tBartTokenizerFast\n",
      "model:\t\tBartForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is a wonderful movie, and I still love it! It just so magical and it is f</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>At first I didn't think I would like this movie, but as it progressed it became better and</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== hf-internal-testing/tiny-bert ===\n",
      "\n",
      "architecture:\tbert\n",
      "tokenizer:\tBertTokenizerFast\n",
      "model:\t\tBertForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>this is absolutely beyond question the worst movie i have ever seen. it is so bad in fact that i plan on renting it again as soon as</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i know it's hard for you americans to find european films on video / dvd, particularly from the 80's but please seek out the original</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== hf-internal-testing/tiny-random-big_bird ===\n",
      "\n",
      "=== hf-internal-testing/tiny-random-bigbird_pegasus ===\n",
      "\n",
      "architecture:\tbigbird_pegasus\n",
      "tokenizer:\tPegasusTokenizerFast\n",
      "model:\t\tBigBirdPegasusForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The bad news: the Canadian version</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A young woman leaves her provin</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== hf-internal-testing/tiny-random-ctrl ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/miniconda3/envs/blurr/lib/python3.9/site-packages/transformers/models/ctrl/modeling_ctrl.py:45: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  angle_rates = 1 / torch.pow(10000, (2 * (i // 2)) / d_model_size)\n",
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\tctrl\n",
      "tokenizer:\tCTRLTokenizer\n",
      "model:\t\tCTRLForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I know it's hard for you Americans to find European films on video/DVD, particularly from the 80's but please seek out the original version of the Vanishing - title S@@</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I rented this movie without having heard (or read) anything about it. What a shame! This movie is intelligent, witty, hilarious, fast-paced, and realistically ridiculous. The characters manage</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== camembert-base ===\n",
      "\n",
      "architecture:\tcamembert\n",
      "tokenizer:\tCamembertTokenizerFast\n",
      "model:\t\tCamembertForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is the funniest movie I have ever seen. However, I have laughed harder at plenty of movie</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This movie is simply excellent. For some reason it wasn't a success at the box office in India. In New York,</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== hf-internal-testing/tiny-random-canine ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using unk_token, but it is not set yet.\n",
      "Using unk_token, but it is not set yet.\n",
      "Using unk_token, but it is not set yet.\n",
      "Using unk_token, but it is not set yet.\n",
      "Using unk_token, but it is not set yet.\n",
      "Using unk_token, but it is not set yet.\n",
      "Using unk_token, but it is not set yet.\n",
      "Using unk_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\tcanine\n",
      "tokenizer:\tCanineTokenizer\n",
      "model:\t\tCanineForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Obviously the previous reviewe</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>My Father The Hero used to be</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== YituTech/conv-bert-base ===\n",
      "\n",
      "architecture:\tconvbert\n",
      "tokenizer:\tConvBertTokenizerFast\n",
      "model:\t\tConvBertForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nickelodeon has gone down the toilet. they have kids saying things like \" oh my god! \" and \" we're screwed \" &lt; br / &gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>this film is bone chilling in a way that is hard to describe. while it is fairly accurate in its description of the events leading up to and the</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== hf-internal-testing/tiny-deberta ===\n",
      "\n",
      "architecture:\tdeberta\n",
      "tokenizer:\tDebertaTokenizerFast\n",
      "model:\t\tDebertaForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/500 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== hf-internal-testing/tiny-random-deberta-v2 ===\n",
      "\n",
      "architecture:\tdeberta_v2\n",
      "tokenizer:\tDebertaV2Tokenizer\n",
      "model:\t\tDebertaV2ForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>If this is the author's and director's idea of a slice of life, they are clinically manic depressives. A sad, moody film</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>At the heart of almost every truly great crime thriller is a carefully considered, methodically planned-out high stakes super-crime, which 9 times out of</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== hf-internal-testing/tiny-random-distilbert ===\n",
      "\n",
      "architecture:\tdistilbert\n",
      "tokenizer:\tDistilBertTokenizerFast\n",
      "model:\t\tDistilBertForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10 / 10 &lt; br / &gt; &lt; br / &gt; plot discussion &lt;</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the movie jennifer with ida lupino a</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== hf-internal-testing/tiny-electra ===\n",
      "\n",
      "architecture:\telectra\n",
      "tokenizer:\tElectraTokenizerFast\n",
      "model:\t\tElectraForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>take someone you love or want to love and go see this film. &lt; br / &gt; &lt; br / &gt; it touches you in all</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>this is one of those films with a great potential. brilliant actors, a debut from a very interesting director and a h</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== google/fnet-base ===\n",
      "\n",
      "architecture:\tfnet\n",
      "tokenizer:\tFNetTokenizerFast\n",
      "model:\t\tFNetForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/500 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== hf-internal-testing/tiny-random-flaubert ===\n",
      "\n",
      "architecture:\tflaubert\n",
      "tokenizer:\tFlaubertTokenizer\n",
      "model:\t\tFlaubertForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Meticulously constructed and perfectly played, To The Ends Of The Earth is a simply astonishing voyage</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is a Very Very Boring and uninteresting action film, and without Chuck Norris it would have been unbear</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== hf-internal-testing/tiny-random-funnel ===\n",
      "\n",
      "architecture:\tfunnel\n",
      "tokenizer:\tFunnelTokenizerFast\n",
      "model:\t\tFunnelForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>as you may remember i have seem all th</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>you know, i always fancy disturbing</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== hf-internal-testing/tiny-random-gpt2 ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\tgpt2\n",
      "tokenizer:\tGPT2TokenizerFast\n",
      "model:\t\tGPT2ForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Let me break down this film for you...&lt;br /&gt;&lt;br /&gt;The first fifte</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A group of douche-bag teenagers go up to an old mining town in hopes of fin</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== hf-internal-testing/tiny-random-gptj ===\n",
      "\n",
      "=== hf-internal-testing/tiny-random-gpt_neo ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\tgpt_neo\n",
      "tokenizer:\tGPT2TokenizerFast\n",
      "model:\t\tGPTNeoForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The movie opens with Charlie (Jeff Daniels), a business man just finishing</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Something I think some people miss about great science fiction is that it predicts some</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== hf-internal-testing/tiny-random-hubert ===\n",
      "\n",
      "=== kssteven/ibert-roberta-base ===\n",
      "\n",
      "architecture:\tibert\n",
      "tokenizer:\tRobertaTokenizer\n",
      "model:\t\tIBertForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>According to the article at http://blog.ifeng.com/article/2737487.html, one of the actors in the film,</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This movie was sheer, slow, plodding torture. Not being a fan of slasher films, and preferring classic horror, I may not be</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== hf-internal-testing/tiny-random-led ===\n",
      "\n",
      "architecture:\tled\n",
      "tokenizer:\tLEDTokenizerFast\n",
      "model:\t\tLEDForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>During the brief period between Clint Eastwood's string of spaghetti</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>just saw this film at resfest and was floored. i've never been a huge fan</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== hf-internal-testing/tiny-layoutlm ===\n",
      "\n",
      "architecture:\tlayoutlm\n",
      "tokenizer:\tLayoutLMTokenizerFast\n",
      "model:\t\tLayoutLMForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>well in to 2002 i've got some catching up to do. and looking back on a lacklustre year, best in show</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rented this one by mistake thinking it was another film with the same title, and realizing that i had rent</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== microsoft/layoutlmv2-base-uncased ===\n",
      "\n",
      "architecture:\tlayoutlmv2\n",
      "tokenizer:\tLayoutLMv2TokenizerFast\n",
      "model:\t\tLayoutLMv2ForSequenceClassification\n",
      "\n",
      "Could not do one pass in your dataloader, there is something wrong in it\n",
      "=== hf-internal-testing/tiny-random-longformer ===\n",
      "\n",
      "architecture:\tlongformer\n",
      "tokenizer:\tLongformerTokenizerFast\n",
      "model:\t\tLongformerForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Very nice movie! I was browsing the channels on my TV and I usually ignore</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>During the brief period between Clint Eastwood's string of spaghetti</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== hf-internal-testing/tiny-random-mbart ===\n",
      "\n",
      "architecture:\tmbart\n",
      "tokenizer:\tMBartTokenizerFast\n",
      "model:\t\tMBartForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SO THIS IS where Columbia's he</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Palwol ui Christmas is very Kor</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== hf-internal-testing/tiny-random-mpnet ===\n",
      "\n",
      "architecture:\tmpnet\n",
      "tokenizer:\tMPNetTokenizerFast\n",
      "model:\t\tMPNetForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>now i've seen it all. just when i thou</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>you know, i always fancy disturbing</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== anton-l/megatron-11b ===\n",
      "\n",
      "=== hf-internal-testing/tiny-random-mobilebert ===\n",
      "\n",
      "architecture:\tmobilebert\n",
      "tokenizer:\tMobileBertTokenizerFast\n",
      "model:\t\tMobileBertForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one night at mccool's / ( 2001 ) * * * ( o</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>if you have ever seen a bollywood mov</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== openai-gpt ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\topenai\n",
      "tokenizer:\tOpenAIGPTTokenizerFast\n",
      "model:\t\tOpenAIGPTForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>crimson begins with some cool jazzy music so i liked it immediately, but as the film wore on i began to wonder if the music wasn't the best</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>to be honest, i did never read one of the comics and cannot remember part 2 and 3 at all. i can compare to the first part ( wer</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== hf-internal-testing/tiny-random-reformer ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\treformer\n",
      "tokenizer:\tReformerTokenizerFast\n",
      "model:\t\tReformerForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/500 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== google/rembert ===\n",
      "\n",
      "architecture:\trembert\n",
      "tokenizer:\tRemBertTokenizerFast\n",
      "model:\t\tRemBertForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Not even original in the plot. Ho hum. There were a couple of angles that could have been quite interesting, but the film follows the path of</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Anytime I'm not giving 150% to my dreams or my goals I think of Mark Borchardt, the real-life subject of \"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== hf-internal-testing/tiny-random-roformer ===\n",
      "\n",
      "architecture:\troformer\n",
      "tokenizer:\tRoFormerTokenizerFast\n",
      "model:\t\tRoFormerForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a better film could have been made to portray the tragedy of bosnia. some parts are very ef</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>this movie is very silly and very funny. you can't ever criticize it for taking itself serio</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== google/reformer-enwik8 ===\n",
      "\n",
      "=== hf-internal-testing/tiny-random-roberta ===\n",
      "\n",
      "architecture:\troberta\n",
      "tokenizer:\tRobertaTokenizerFast\n",
      "model:\t\tRobertaForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dear Readers,&lt;br /&gt;&lt;br /&gt;I've found in my studies of movies that when</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SO THIS IS where Columbia's head of their Short Subjects Unit got</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== hf-internal-testing/tiny-random-squeezebert ===\n",
      "\n",
      "architecture:\tsqueezebert\n",
      "tokenizer:\tSqueezeBertTokenizerFast\n",
      "model:\t\tSqueezeBertForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the movie jennifer with ida lupino a</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>my father the hero used to be my favor</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== hf-internal-testing/tiny-random-transfo-xl ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\ttransfo_xl\n",
      "tokenizer:\tTransfoXLTokenizer\n",
      "model:\t\tTransfoXLForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This film is bone chilling in a way that is hard to describe. While it is fairly accurate in its description of the events leading up to and the subsequent investigation</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Please -- if you haven't attempted to sit through this garbage and are considering viewing this flick / mini-series -- do yourself a favor and find anything else to</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== hf-internal-testing/tiny-random-xlm ===\n",
      "\n",
      "architecture:\txlm\n",
      "tokenizer:\tXLMTokenizer\n",
      "model:\t\tXLMForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>if you have ever seen a bollywood movie, you know they are longer than most movies due to the multiple song and dance routines ( each one is</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>looking for proof that real life is more entertaining than fiction? you just found it. this superb documentary about an aspiring feature filmmaker ( mark bortchart</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== hf-internal-testing/tiny-xlm-roberta ===\n",
      "\n",
      "architecture:\txlm_roberta\n",
      "tokenizer:\tXLMRobertaTokenizerFast\n",
      "model:\t\tXLMRobertaForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I decided to watch this on FearNet on demand for free because I figured well, no</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This movie is George C. Scott at his very best, Bernard Hughes at his very best</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== hf-internal-testing/tiny-random-xlnet ===\n",
      "\n",
      "architecture:\txlnet\n",
      "tokenizer:\tXLNetTokenizerFast\n",
      "model:\t\tXLNetForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dear Readers,&lt;br /&gt;&lt;br /&gt;I've found</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not even original in the plot. Ho hum. There were</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide\n",
    "from transformers import RobertaTokenizer\n",
    "\n",
    "model_cls = AutoModelForSequenceClassification\n",
    "bsz = 2\n",
    "seq_sz = 32\n",
    "\n",
    "test_results = []\n",
    "for model_name in pretrained_model_names:\n",
    "    error = None\n",
    "\n",
    "    print(f\"=== {model_name} ===\\n\")\n",
    "\n",
    "    # 1. get/configure our Hugging Face objects\n",
    "    tok_class = RobertaTokenizer if (\"/ibert\" in model_name) else None\n",
    "\n",
    "    try:\n",
    "        learn = None\n",
    "        \n",
    "        hf_arch, hf_config, hf_tokenizer, hf_model = BLURR.get_hf_objects(\n",
    "            model_name, model_cls=model_cls, tokenizer_cls=tok_class, config_kwargs={\"num_labels\": 2}\n",
    "        )\n",
    "\n",
    "        print(f\"architecture:\\t{hf_arch}\\ntokenizer:\\t{type(hf_tokenizer).__name__}\\nmodel:\\t\\t{type(hf_model).__name__}\\n\")\n",
    "\n",
    "        # not all architectures include a native pad_token (e.g., gpt2, ctrl, etc...), so we add one here\n",
    "        if hf_tokenizer.pad_token is None:\n",
    "            hf_tokenizer.add_special_tokens({\"pad_token\": \"<pad>\"})\n",
    "            hf_config.pad_token_id = hf_tokenizer.get_vocab()[\"<pad>\"]\n",
    "            hf_model.resize_token_embeddings(len(hf_tokenizer))\n",
    "\n",
    "        # 2. get our DataLoaders\n",
    "        blocks = (HF_TextBlock(hf_arch, hf_config, hf_tokenizer, hf_model, max_length=seq_sz, padding=\"max_length\"), CategoryBlock)\n",
    "\n",
    "        dblock = DataBlock(blocks=blocks, get_x=ColReader(\"text\"), get_y=ColReader(\"label\"), splitter=ColSplitter(col=\"is_valid\"))\n",
    "\n",
    "        dls = dblock.dataloaders(imdb_df, bs=bsz)\n",
    "\n",
    "        # 3. configure our Learner\n",
    "        model = HF_BaseModelWrapper(hf_model)\n",
    "        learn = Learner(\n",
    "            dls,\n",
    "            model,\n",
    "            opt_func=partial(Adam),\n",
    "            loss_func=CrossEntropyLossFlat(),\n",
    "            metrics=[accuracy],\n",
    "            cbs=[HF_BaseModelCallback],\n",
    "            splitter=hf_splitter,\n",
    "        )\n",
    "\n",
    "        learn.freeze()\n",
    "\n",
    "        b = dls.one_batch()\n",
    "\n",
    "        # 4. train\n",
    "        print(\"*** TESTING DataLoaders ***\")\n",
    "        test_eq(len(b), bsz)\n",
    "        test_eq(len(b[0][\"input_ids\"]), bsz)\n",
    "        test_eq(b[0][\"input_ids\"].shape, torch.Size([bsz, seq_sz]))\n",
    "        test_eq(len(b[1]), bsz)\n",
    "\n",
    "        #         print('*** TESTING One pass through the model ***')\n",
    "        #         preds = learn.model(b[0])\n",
    "        #         test_eq(len(preds[0]), bsz)\n",
    "        #         test_eq(preds[0].shape, torch.Size([bsz, 2]))\n",
    "\n",
    "        print(\"*** TESTING Training/Results ***\")\n",
    "        learn.fit_one_cycle(1, lr_max=1e-3, cbs=ShortEpochCallback(pct=0.2, short_valid=True))\n",
    "\n",
    "        test_results.append((hf_arch, type(hf_tokenizer).__name__, type(hf_model).__name__, \"PASSED\", \"\"))\n",
    "        learn.show_results(learner=learn, max_n=2, trunc_at=250)\n",
    "    except Exception as err:\n",
    "        test_results.append((hf_arch, type(hf_tokenizer).__name__, type(hf_model).__name__, \"FAILED\", err))\n",
    "    finally:\n",
    "        # cleanup\n",
    "        if learn:\n",
    "            del learn\n",
    "        torch.cuda.empty_cache()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arch</th>\n",
       "      <th>tokenizer</th>\n",
       "      <th>model</th>\n",
       "      <th>result</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>albert</td>\n",
       "      <td>AlbertTokenizerFast</td>\n",
       "      <td>AlbertForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bart</td>\n",
       "      <td>BartTokenizerFast</td>\n",
       "      <td>BartForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bert</td>\n",
       "      <td>BertTokenizerFast</td>\n",
       "      <td>BertForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bert</td>\n",
       "      <td>BertTokenizerFast</td>\n",
       "      <td>BertForSequenceClassification</td>\n",
       "      <td>FAILED</td>\n",
       "      <td>Error(s) in loading state_dict for BigBirdForSequenceClassification:\\n\\tsize mismatch for classifier.out_proj.weight: copying a param with shape torch.Size([1, 32]) from checkpoint, the shape in current model is torch.Size([2, 32]).\\n\\tsize mismatch for classifier.out_proj.bias: copying a param with shape torch.Size([1]) from checkpoint, the shape in current model is torch.Size([2]).</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bigbird_pegasus</td>\n",
       "      <td>PegasusTokenizerFast</td>\n",
       "      <td>BigBirdPegasusForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ctrl</td>\n",
       "      <td>CTRLTokenizer</td>\n",
       "      <td>CTRLForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>camembert</td>\n",
       "      <td>CamembertTokenizerFast</td>\n",
       "      <td>CamembertForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>canine</td>\n",
       "      <td>CanineTokenizer</td>\n",
       "      <td>CanineForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>convbert</td>\n",
       "      <td>ConvBertTokenizerFast</td>\n",
       "      <td>ConvBertForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>deberta</td>\n",
       "      <td>DebertaTokenizerFast</td>\n",
       "      <td>DebertaForSequenceClassification</td>\n",
       "      <td>FAILED</td>\n",
       "      <td>mat1 and mat2 shapes cannot be multiplied (2x32 and 768x768)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>deberta_v2</td>\n",
       "      <td>DebertaV2Tokenizer</td>\n",
       "      <td>DebertaV2ForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>distilbert</td>\n",
       "      <td>DistilBertTokenizerFast</td>\n",
       "      <td>DistilBertForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>electra</td>\n",
       "      <td>ElectraTokenizerFast</td>\n",
       "      <td>ElectraForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>fnet</td>\n",
       "      <td>FNetTokenizerFast</td>\n",
       "      <td>FNetForSequenceClassification</td>\n",
       "      <td>FAILED</td>\n",
       "      <td>forward() got an unexpected keyword argument 'output_attentions'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>flaubert</td>\n",
       "      <td>FlaubertTokenizer</td>\n",
       "      <td>FlaubertForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>funnel</td>\n",
       "      <td>FunnelTokenizerFast</td>\n",
       "      <td>FunnelForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>GPT2TokenizerFast</td>\n",
       "      <td>GPT2ForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>GPT2TokenizerFast</td>\n",
       "      <td>GPT2ForSequenceClassification</td>\n",
       "      <td>FAILED</td>\n",
       "      <td>Error(s) in loading state_dict for GPTJForSequenceClassification:\\n\\tsize mismatch for score.weight: copying a param with shape torch.Size([2, 512]) from checkpoint, the shape in current model is torch.Size([2, 32]).</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>gpt_neo</td>\n",
       "      <td>GPT2TokenizerFast</td>\n",
       "      <td>GPTNeoForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>gpt_neo</td>\n",
       "      <td>GPT2TokenizerFast</td>\n",
       "      <td>GPTNeoForSequenceClassification</td>\n",
       "      <td>FAILED</td>\n",
       "      <td>Can't load tokenizer for 'hf-internal-testing/tiny-random-hubert'. Make sure that:\\n\\n- 'hf-internal-testing/tiny-random-hubert' is a correct model identifier listed on 'https://huggingface.co/models'\\n  (make sure 'hf-internal-testing/tiny-random-hubert' is not a path to a local directory with something else, in that case)\\n\\n- or 'hf-internal-testing/tiny-random-hubert' is the correct path to a directory containing relevant tokenizer files\\n\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ibert</td>\n",
       "      <td>RobertaTokenizer</td>\n",
       "      <td>IBertForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>led</td>\n",
       "      <td>LEDTokenizerFast</td>\n",
       "      <td>LEDForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>layoutlm</td>\n",
       "      <td>LayoutLMTokenizerFast</td>\n",
       "      <td>LayoutLMForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>layoutlmv2</td>\n",
       "      <td>LayoutLMv2TokenizerFast</td>\n",
       "      <td>LayoutLMv2ForSequenceClassification</td>\n",
       "      <td>FAILED</td>\n",
       "      <td>You must provide corresponding bounding boxes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>longformer</td>\n",
       "      <td>LongformerTokenizerFast</td>\n",
       "      <td>LongformerForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>mbart</td>\n",
       "      <td>MBartTokenizerFast</td>\n",
       "      <td>MBartForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>mpnet</td>\n",
       "      <td>MPNetTokenizerFast</td>\n",
       "      <td>MPNetForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>mpnet</td>\n",
       "      <td>MPNetTokenizerFast</td>\n",
       "      <td>MPNetForSequenceClassification</td>\n",
       "      <td>FAILED</td>\n",
       "      <td>'megatron'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>mobilebert</td>\n",
       "      <td>MobileBertTokenizerFast</td>\n",
       "      <td>MobileBertForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>openai</td>\n",
       "      <td>OpenAIGPTTokenizerFast</td>\n",
       "      <td>OpenAIGPTForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>reformer</td>\n",
       "      <td>ReformerTokenizerFast</td>\n",
       "      <td>ReformerForSequenceClassification</td>\n",
       "      <td>FAILED</td>\n",
       "      <td>If training, make sure that config.axial_pos_shape factors: (4, 25) multiply to sequence length. Got prod((4, 25)) != sequence_length: 32. You might want to consider padding your sequence length to 100 or changing config.axial_pos_shape.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>rembert</td>\n",
       "      <td>RemBertTokenizerFast</td>\n",
       "      <td>RemBertForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>roformer</td>\n",
       "      <td>RoFormerTokenizerFast</td>\n",
       "      <td>RoFormerForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>roformer</td>\n",
       "      <td>RoFormerTokenizerFast</td>\n",
       "      <td>RoFormerForSequenceClassification</td>\n",
       "      <td>FAILED</td>\n",
       "      <td>not a string</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>roberta</td>\n",
       "      <td>RobertaTokenizerFast</td>\n",
       "      <td>RobertaForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>squeezebert</td>\n",
       "      <td>SqueezeBertTokenizerFast</td>\n",
       "      <td>SqueezeBertForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>transfo_xl</td>\n",
       "      <td>TransfoXLTokenizer</td>\n",
       "      <td>TransfoXLForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>xlm</td>\n",
       "      <td>XLMTokenizer</td>\n",
       "      <td>XLMForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>xlm_roberta</td>\n",
       "      <td>XLMRobertaTokenizerFast</td>\n",
       "      <td>XLMRobertaForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>xlnet</td>\n",
       "      <td>XLNetTokenizerFast</td>\n",
       "      <td>XLNetForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hide_input\n",
    "test_results_df = pd.DataFrame(test_results, columns=[\"arch\", \"tokenizer\", \"model\", \"result\", \"error\"])\n",
    "display_df(test_results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This module includes the fundamental building blocks for training using Blurr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_utils.ipynb.\n",
      "Converted 01_data-core.ipynb.\n",
      "Converted 01_modeling-core.ipynb.\n",
      "Converted 02_data-language-modeling.ipynb.\n",
      "Converted 02_modeling-language-modeling.ipynb.\n",
      "Converted 03_data-token-classification.ipynb.\n",
      "Converted 03_modeling-token-classification.ipynb.\n",
      "Converted 04_data-question-answering.ipynb.\n",
      "Converted 04_modeling-question-answering.ipynb.\n",
      "Converted 10_data-seq2seq-core.ipynb.\n",
      "Converted 10_modeling-seq2seq-core.ipynb.\n",
      "Converted 11_data-seq2seq-summarization.ipynb.\n",
      "Converted 11_modeling-seq2seq-summarization.ipynb.\n",
      "Converted 12_data-seq2seq-translation.ipynb.\n",
      "Converted 12_modeling-seq2seq-translation.ipynb.\n",
      "Converted 99a_examples-high-level-api.ipynb.\n",
      "Converted 99b_examples-glue.ipynb.\n",
      "Converted 99c_examples-glue-plain-pytorch.ipynb.\n",
      "Converted 99d_examples-multilabel.ipynb.\n",
      "Converted 99e_examples-causal-lm-gpt2.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import notebook2script\n",
    "\n",
    "notebook2script()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
