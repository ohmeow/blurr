{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp modeling.core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modeling.core\n",
    "\n",
    "> This module contains core custom models, loss functions, and a default layer group splitter for use in applying discriminiative learning rates to your huggingface models trained via fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import inspect, torch\n",
    "from transformers import *\n",
    "\n",
    "from fastai.text.all import *\n",
    "from fastai.callback.hook import _print_shapes\n",
    "\n",
    "from blurr.utils import *\n",
    "from blurr.data.core import *\n",
    "\n",
    "logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pytorch 1.7.1\n",
      "Using fastai 2.4\n",
      "Using transformers 4.8.1\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "import pdb\n",
    "\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *\n",
    "\n",
    "from fastai import __version__ as fa_version\n",
    "from torch import __version__ as pt_version\n",
    "from transformers import __version__ as hft_version\n",
    "\n",
    "print(f'Using pytorch {pt_version}')\n",
    "print(f'Using fastai {fa_version}')\n",
    "print(f'Using transformers {hft_version}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU #1: GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "#cuda\n",
    "torch.cuda.set_device(1)\n",
    "print(f'Using GPU #{torch.cuda.current_device()}: {torch.cuda.get_device_name()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base splitter, model wrapper, and model callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def hf_splitter(m):\n",
    "    \"\"\"Splits the huggingface model based on various model architecture conventions\"\"\"\n",
    "    model = m.hf_model if (hasattr(m, 'hf_model')) else m\n",
    "    root_modules = list(model.named_children())\n",
    "    top_module_name, top_module = root_modules[0]\n",
    "    \n",
    "    groups = L([ m for m_name, m in list(top_module.named_children()) ])\n",
    "    groups += L([ m for m_name, m in root_modules[1:] ])\n",
    "\n",
    "    return groups.map(params).filter(lambda el: len(el) > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"hf_splitter\" class=\"doc_header\"><code>hf_splitter</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>hf_splitter</code>(**`m`**)\n",
       "\n",
       "Splits the huggingface model based on various model architecture conventions"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(hf_splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class HF_BaseModelWrapper(Module):\n",
    "    def __init__(self, hf_model, output_hidden_states=False, output_attentions=False, hf_model_kwargs={}):\n",
    "        super().__init__()\n",
    "        \n",
    "        store_attr(self=self, names='output_hidden_states, output_attentions, hf_model_kwargs')\n",
    "        self.hf_model = hf_model.cuda() if torch.cuda.is_available() else hf_model\n",
    "        \n",
    "        self.hf_model_fwd_args = list(inspect.signature(self.hf_model.forward).parameters.keys())\n",
    "\n",
    "    def forward(self, x): \n",
    "        for k in list(x): \n",
    "            if k not in self.hf_model_fwd_args: \n",
    "                del x[k]\n",
    "\n",
    "        return self.hf_model(**x,  \n",
    "                             output_hidden_states=self.output_hidden_states, \n",
    "                             output_attentions=self.output_attentions,\n",
    "                             return_dict=True,\n",
    "                             **self.hf_model_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `HF_BaseModelWrapper` includes some nifty code for just passing in the things your model needs, as not all transformer architectures require/use the same information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class HF_PreCalculatedLoss():\n",
    "    def __call__(self, inp, targ, **kwargs):return tensor(0.)\n",
    "    def decodes(self, x): return x.argmax(dim=-1)\n",
    "    def activation(self, x): return F.softmax(x, dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to let your huggingface model calculate the loss for you, make sure you include the `labels` argument in your inputs and use `HF_PreCalculatedLoss` as your loss function. Even though we don't really need a loss function per se, we have to provide a custom loss class/function for fastai to function properly (e.g. one with a `decodes` and `activation` methods).  Why?  Because these methods will get called in methods like `show_results` to get the actual predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class HF_BaseModelCallback(Callback):\n",
    "\n",
    "    def before_batch(self): self.hf_loss = None\n",
    "        \n",
    "    def after_pred(self): \n",
    "        model_outputs = self.pred\n",
    "        self.learn.blurr_model_outputs = {}\n",
    "        \n",
    "        for k,v in model_outputs.items():\n",
    "            # if the \"labels\" are included, we are training with target labels in which case the loss is returned\n",
    "            if (k == 'loss' and isinstance(self.learn.loss_func, HF_PreCalculatedLoss)): \n",
    "                self.hf_loss = to_float(v)\n",
    "            # the logits represent the prediction\n",
    "            elif (k == 'logits'):\n",
    "                self.learn.pred = v\n",
    "            # add any other things included in model_outputs as blurr_{model_output_key}\n",
    "            else:\n",
    "                self.learn.blurr_model_outputs[k] = v\n",
    "            \n",
    "    def after_loss(self): \n",
    "        # if we already have the loss from the model, update the Learner's loss to be it\n",
    "        if (self.hf_loss is not None): \n",
    "            self.learn.loss_grad = self.hf_loss\n",
    "            self.learn.loss = self.learn.loss_grad.clone()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a `Callback` for handling what is returned from the huggingface model. The return type is (`ModelOutput`)[https://huggingface.co/transformers/main_classes/output.html#transformers.file_utils.ModelOutput] which makes it easy to return all the goodies we asked for.\n",
    "\n",
    "Note that your `Learner`'s loss will be set for you only if the huggingface model returns one *and* you are using the `HF_PreCalculatedLoss` loss function.  \n",
    "\n",
    "Also note that anything else you asked the model to return (for example, last hidden state, etc..) will be available for you via the `blurr_model_outputs` property attached to your `Learner`. For example, assuming you are using BERT for a classification task ... if you have told your `HF_BaseModelWrapper` instance to return attentions, you'd be able to access them via `learn.blurr_model_outputs['attentions']`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence classification\n",
    "\n",
    "Below demonstrates how to setup your `blurr` pipeline for a sequence classification task (e.g., a model that requires a single text input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.IMDB_SAMPLE)\n",
    "imdb_df = pd.read_csv(path/'texts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>is_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negative</td>\n",
       "      <td>Un-bleeping-believable! Meg Ryan doesn't even look her usual pert lovable self in this, which normally makes me forgive her shallow ticky acting schtick. Hard to believe she was the producer on this dog. Plus Kevin Kline: what kind of suicide trip has his career been on? Whoosh... Banzai!!! Finally this was directed by the guy who did Big Chill? Must be a replay of Jonestown - hollywood style. Wooofff!</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>This is a extremely well-made film. The acting, script and camera-work are all first-rate. The music is good, too, though it is mostly early in the film, when things are still relatively cheery. There are no really superstars in the cast, though several faces will be familiar. The entire cast does an excellent job with the script.&lt;br /&gt;&lt;br /&gt;But it is hard to watch, because there is no good end to a situation like the one presented. It is now fashionable to blame the British for setting Hindus and Muslims against each other, and then cruelly separating them into two countries. There is som...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>Every once in a long while a movie will come along that will be so awful that I feel compelled to warn people. If I labor all my days and I can save but one soul from watching this movie, how great will be my joy.&lt;br /&gt;&lt;br /&gt;Where to begin my discussion of pain. For starters, there was a musical montage every five minutes. There was no character development. Every character was a stereotype. We had swearing guy, fat guy who eats donuts, goofy foreign guy, etc. The script felt as if it were being written as the movie was being shot. The production value was so incredibly low that it felt li...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>Name just says it all. I watched this movie with my dad when it came out and having served in Korea he had great admiration for the man. The disappointing thing about this film is that it only concentrate on a short period of the man's life - interestingly enough the man's entire life would have made such an epic bio-pic that it is staggering to imagine the cost for production.&lt;br /&gt;&lt;br /&gt;Some posters elude to the flawed characteristics about the man, which are cheap shots. The theme of the movie \"Duty, Honor, Country\" are not just mere words blathered from the lips of a high-brassed offic...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>This movie succeeds at being one of the most unique movies you've seen. However this comes from the fact that you can't make heads or tails of this mess. It almost seems as a series of challenges set up to determine whether or not you are willing to walk out of the movie and give up the money you just paid. If you don't want to feel slighted you'll sit through this horrible film and develop a real sense of pity for the actors involved, they've all seen better days, but then you realize they actually got paid quite a bit of money to do this and you'll lose pity for them just like you've alr...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label  \\\n",
       "0  negative   \n",
       "1  positive   \n",
       "2  negative   \n",
       "3  positive   \n",
       "4  negative   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      text  \\\n",
       "0                                                                                                                                                                                                    Un-bleeping-believable! Meg Ryan doesn't even look her usual pert lovable self in this, which normally makes me forgive her shallow ticky acting schtick. Hard to believe she was the producer on this dog. Plus Kevin Kline: what kind of suicide trip has his career been on? Whoosh... Banzai!!! Finally this was directed by the guy who did Big Chill? Must be a replay of Jonestown - hollywood style. Wooofff!   \n",
       "1  This is a extremely well-made film. The acting, script and camera-work are all first-rate. The music is good, too, though it is mostly early in the film, when things are still relatively cheery. There are no really superstars in the cast, though several faces will be familiar. The entire cast does an excellent job with the script.<br /><br />But it is hard to watch, because there is no good end to a situation like the one presented. It is now fashionable to blame the British for setting Hindus and Muslims against each other, and then cruelly separating them into two countries. There is som...   \n",
       "2  Every once in a long while a movie will come along that will be so awful that I feel compelled to warn people. If I labor all my days and I can save but one soul from watching this movie, how great will be my joy.<br /><br />Where to begin my discussion of pain. For starters, there was a musical montage every five minutes. There was no character development. Every character was a stereotype. We had swearing guy, fat guy who eats donuts, goofy foreign guy, etc. The script felt as if it were being written as the movie was being shot. The production value was so incredibly low that it felt li...   \n",
       "3  Name just says it all. I watched this movie with my dad when it came out and having served in Korea he had great admiration for the man. The disappointing thing about this film is that it only concentrate on a short period of the man's life - interestingly enough the man's entire life would have made such an epic bio-pic that it is staggering to imagine the cost for production.<br /><br />Some posters elude to the flawed characteristics about the man, which are cheap shots. The theme of the movie \"Duty, Honor, Country\" are not just mere words blathered from the lips of a high-brassed offic...   \n",
       "4  This movie succeeds at being one of the most unique movies you've seen. However this comes from the fact that you can't make heads or tails of this mess. It almost seems as a series of challenges set up to determine whether or not you are willing to walk out of the movie and give up the money you just paid. If you don't want to feel slighted you'll sit through this horrible film and develop a real sense of pity for the actors involved, they've all seen better days, but then you realize they actually got paid quite a bit of money to do this and you'll lose pity for them just like you've alr...   \n",
       "\n",
       "   is_valid  \n",
       "0     False  \n",
       "1     False  \n",
       "2     False  \n",
       "3     False  \n",
       "4     False  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide_output\n",
    "model_cls = AutoModelForSequenceClassification\n",
    "\n",
    "pretrained_model_name = \"distilroberta-base\" # \"distilbert-base-uncased\" \"bert-base-uncased\"\n",
    "hf_arch, hf_config, hf_tokenizer, hf_model = BLURR.get_hf_objects(pretrained_model_name, model_cls=model_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single input\n",
    "blocks = (HF_TextBlock(hf_arch, hf_config, hf_tokenizer, hf_model), CategoryBlock)\n",
    "dblock = DataBlock(blocks=blocks, get_x=ColReader('text'), get_y=ColReader('label'), splitter=ColSplitter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dblock.summary(imdb_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = dblock.dataloaders(imdb_df, bs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Raising Victor Vargas: A Review&lt;br /&gt;&lt;br /&gt;You know, Raising Victor Vargas is like sticking your hands into a big, steaming bowl of oatmeal. It's warm and gooey, but you're not sure if it feels right. Try as I might, no matter how warm and gooey Raising Victor Vargas became I was always aware that something didn't quite feel right. Victor Vargas suffers from a certain overconfidence on the director's part. Apparently, the director thought that the ethnic backdrop of a Latino family on the lower east side, and an idyllic storyline would make the film critic proof. He was right, but it didn't fool me. Raising Victor Vargas is the story about a seventeen-year old boy called, you guessed it, Victor Vargas (Victor Rasuk) who lives his teenage years chasing more skirt than the Rolling Stones could do in all the years they've toured. The movie starts off in `Ugly Fat' Donna's bedroom where Victor is sure to seduce her, but a cry from outside disrupts his plans when his best-friend Harold (Kevin Rivera) comes-a-looking for him. Caught in the attempt by Harold and his sister, Victor Vargas runs off for damage control. Yet even with the embarrassing implication that he's been boffing the homeliest girl in the neighborhood, nothing dissuades young Victor from going off on the hunt for more fresh meat. On a hot, New York City day they make way to the local public swimming pool where Victor's eyes catch a glimpse of the lovely young nymph Judy (Judy Marte), who's not just pretty, but a strong and independent too. The relationship that develops between Victor and Judy becomes the focus of the film. The story also focuses on Victor's family that is comprised of his grandmother or abuelita (Altagracia Guzman), his brother Nino (also played by real life brother to Victor, Silvestre Rasuk) and his sister Vicky (Krystal Rodriguez). The action follows Victor between scenes with Judy and scenes with his family. Victor tries to cope with being an oversexed pimp-daddy, his feelings for Judy and his grandmother's conservative Catholic upbringing.&lt;br /&gt;&lt;br /&gt;The problems that arise from Raising Victor Vargas are a few, but glaring errors. Throughout the film you get to know certain characters like Vicky, Nino, Grandma,</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Now that Che(2008) has finished its relatively short Australian cinema run (extremely limited release:1 screen in Sydney, after 6wks), I can guiltlessly join both hosts of \"At The Movies\" in taking Steven Soderbergh to task.&lt;br /&gt;&lt;br /&gt;It's usually satisfying to watch a film director change his style/subject, but Soderbergh's most recent stinker, The Girlfriend Experience(2009), was also missing a story, so narrative (and editing?) seem to suddenly be Soderbergh's main challenge. Strange, after 20-odd years in the business. He was probably never much good at narrative, just hid it well inside \"edgy\" projects.&lt;br /&gt;&lt;br /&gt;None of this excuses him this present, almost diabolical failure. As David Stratton warns, \"two parts of Che don't (even) make a whole\". &lt;br /&gt;&lt;br /&gt;Epic biopic in name only, Che(2008) barely qualifies as a feature film! It certainly has no legs, inasmuch as except for its uncharacteristic ultimate resolution forced upon it by history, Soderbergh's 4.5hrs-long dirge just goes nowhere.&lt;br /&gt;&lt;br /&gt;Even Margaret Pomeranz, the more forgiving of Australia's At The Movies duo, noted about Soderbergh's repetitious waste of (HD digital storage): \"you're in the woods...you're in the woods...you're in the woods...\". I too am surprised Soderbergh didn't give us another 2.5hrs of THAT somewhere between his existing two Parts, because he still left out massive chunks of Che's \"revolutionary\" life! &lt;br /&gt;&lt;br /&gt;For a biopic of an important but infamous historical figure, Soderbergh unaccountably alienates, if not deliberately insults, his audiences by&lt;br /&gt;&lt;br /&gt;1. never providing most of Che's story; &lt;br /&gt;&lt;br /&gt;2. imposing unreasonable film lengths with mere dullard repetition; &lt;br /&gt;&lt;br /&gt;3. ignoring both true hindsight and a narrative of events; &lt;br /&gt;&lt;br /&gt;4. barely developing an idea, or a character; &lt;br /&gt;&lt;br /&gt;5. remaining claustrophobically episodic; &lt;br /&gt;&lt;br /&gt;6. ignoring proper context for scenes---whatever we do get is mired in disruptive timeshifts; &lt;br /&gt;&lt;br /&gt;7. linguistically</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch(dataloaders=dls, max_n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "We'll also add in custom summary methods for blurr learners/models that work with dictionary inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HF_BaseModelWrapper(hf_model)\n",
    "\n",
    "learn = Learner(dls, \n",
    "                model,\n",
    "                opt_func=partial(OptimWrapper, opt=torch.optim.Adam),\n",
    "                loss_func=CrossEntropyLossFlat(),\n",
    "                metrics=[accuracy],\n",
    "                cbs=[HF_BaseModelCallback],\n",
    "                splitter=hf_splitter)\n",
    "\n",
    "learn.freeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.to_fp16()` requires a GPU so had to remove for tests to run on github.  Let's check that we can get predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "HF_BaseModelWrapper (Input shape: 4)\n",
       "============================================================================\n",
       "Layer (type)         Output Shape         Param #    Trainable \n",
       "============================================================================\n",
       "                     4 x 512 x 768       \n",
       "Embedding                                 38603520   False     \n",
       "Embedding                                 394752     False     \n",
       "Embedding                                 768        False     \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "Linear                                    590592     False     \n",
       "Linear                                    590592     False     \n",
       "Linear                                    590592     False     \n",
       "Dropout                                                        \n",
       "Linear                                    590592     False     \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "____________________________________________________________________________\n",
       "                     4 x 512 x 3072      \n",
       "Linear                                    2362368    False     \n",
       "____________________________________________________________________________\n",
       "                     4 x 512 x 768       \n",
       "Linear                                    2360064    False     \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "Linear                                    590592     False     \n",
       "Linear                                    590592     False     \n",
       "Linear                                    590592     False     \n",
       "Dropout                                                        \n",
       "Linear                                    590592     False     \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "____________________________________________________________________________\n",
       "                     4 x 512 x 3072      \n",
       "Linear                                    2362368    False     \n",
       "____________________________________________________________________________\n",
       "                     4 x 512 x 768       \n",
       "Linear                                    2360064    False     \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "Linear                                    590592     False     \n",
       "Linear                                    590592     False     \n",
       "Linear                                    590592     False     \n",
       "Dropout                                                        \n",
       "Linear                                    590592     False     \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "____________________________________________________________________________\n",
       "                     4 x 512 x 3072      \n",
       "Linear                                    2362368    False     \n",
       "____________________________________________________________________________\n",
       "                     4 x 512 x 768       \n",
       "Linear                                    2360064    False     \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "Linear                                    590592     False     \n",
       "Linear                                    590592     False     \n",
       "Linear                                    590592     False     \n",
       "Dropout                                                        \n",
       "Linear                                    590592     False     \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "____________________________________________________________________________\n",
       "                     4 x 512 x 3072      \n",
       "Linear                                    2362368    False     \n",
       "____________________________________________________________________________\n",
       "                     4 x 512 x 768       \n",
       "Linear                                    2360064    False     \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "Linear                                    590592     False     \n",
       "Linear                                    590592     False     \n",
       "Linear                                    590592     False     \n",
       "Dropout                                                        \n",
       "Linear                                    590592     False     \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "____________________________________________________________________________\n",
       "                     4 x 512 x 3072      \n",
       "Linear                                    2362368    False     \n",
       "____________________________________________________________________________\n",
       "                     4 x 512 x 768       \n",
       "Linear                                    2360064    False     \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "Linear                                    590592     False     \n",
       "Linear                                    590592     False     \n",
       "Linear                                    590592     False     \n",
       "Dropout                                                        \n",
       "Linear                                    590592     False     \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "____________________________________________________________________________\n",
       "                     4 x 512 x 3072      \n",
       "Linear                                    2362368    False     \n",
       "____________________________________________________________________________\n",
       "                     4 x 512 x 768       \n",
       "Linear                                    2360064    False     \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "Linear                                    590592     True      \n",
       "Dropout                                                        \n",
       "____________________________________________________________________________\n",
       "                     4 x 2               \n",
       "Linear                                    1538       True      \n",
       "____________________________________________________________________________\n",
       "\n",
       "Total params: 82,119,938\n",
       "Total trainable params: 612,098\n",
       "Total non-trainable params: 81,507,840\n",
       "\n",
       "Optimizer used: functools.partial(<class 'fastai.optimizer.OptimWrapper'>, opt=<class 'torch.optim.adam.Adam'>)\n",
       "Loss function: FlattenedLoss of CrossEntropyLoss()\n",
       "\n",
       "Model frozen up to parameter group #2\n",
       "\n",
       "Callbacks:\n",
       "  - TrainEvalCallback\n",
       "  - HF_BaseModelCallback\n",
       "  - Recorder\n",
       "  - ProgressCallback"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(len(learn.opt.param_groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/miniconda3/envs/blurr/lib/python3.9/site-packages/fastai/callback/schedule.py:270: UserWarning: color is redundantly defined by the 'color' keyword argument and the fmt string \"ro\" (-> color='r'). The keyword argument will take precedence.\n",
      "  ax.plot(val, idx, 'ro', label=nm, c=color)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(minimum=1.318256749982538e-07, steep=1.0964781722577754e-06, valley=tensor(0.0004), slide=tensor(0.0008))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "learn.lr_find(suggest_funcs=[minimum, steep, valley, slide])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.327187</td>\n",
       "      <td>0.304522</td>\n",
       "      <td>0.885000</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "learn.fit_one_cycle(1, lr_max=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Showing results\n",
    "\n",
    "And here we creat a @typedispatched impelmentation of `Learner.show_results`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@typedispatch\n",
    "def show_results(x:HF_BaseInput, y, samples, outs, learner, ctxs=None, max_n=6, trunc_at=None, **kwargs):    \n",
    "    #grab tokenizer and trunc_at to pass into HF_BaseInput.show\n",
    "    hf_before_batch_tfm = get_blurr_tfm(learner.dls.before_batch)\n",
    "    kwargs['hf_tokenizer'] = hf_before_batch_tfm.hf_tokenizer\n",
    "    kwargs['trunc_at'] = trunc_at\n",
    "    \n",
    "    if ctxs is None: ctxs = get_empty_df(min(len(samples), max_n))\n",
    "    ctxs = show_batch[object](x, y, samples, max_n=max_n, ctxs=ctxs, **kwargs)\n",
    "    \n",
    "    n_preds_per_input = len(outs[0])\n",
    "    if (n_preds_per_input == 1): \n",
    "        for i,ctx in enumerate(ctxs): ctx['target'] = outs[i][0]\n",
    "    else:\n",
    "        for pred_idx in range(n_preds_per_input):\n",
    "            for i,ctx in enumerate(ctxs):  ctx[f'target{pred_idx+1}'] = outs[i][pred_idx]\n",
    "\n",
    "    display_df(pd.DataFrame(ctxs))\n",
    "    return ctxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The trouble with the book, \"Memoirs of a Geisha\" is that it had Japanese surfaces but underneath the surfaces it was all an American man's way of thinking. Reading the book is like watching a magnificent ballet with great music, sets, and costumes yet performed by barnyard animals dressed in those costumesso far from Japanese ways of thinking were the characters.&lt;br /&gt;&lt;br /&gt;The movie isn't about Japan or real geisha. It is a story about a few American men's mistaken ideas about Japan and geish</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;br /&gt;&lt;br /&gt;I'm sure things didn't exactly go the same way in the real life of Homer Hickam as they did in the film adaptation of his book, Rocket Boys, but the movie \"October Sky\" (an anagram of the book's title) is good enough to stand alone. I have not read Hickam's memoirs, but I am still able to enjoy and understand their film adaptation. The film, directed by Joe Johnston and written by Lewis Colick, records the story of teenager Homer Hickam (Jake Gyllenhaal), beginning in October of 195</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, max_n=2, trunc_at=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def blurr_predict(self:Learner, items, rm_type_tfms=None):\n",
    "    hf_before_batch_tfm = get_blurr_tfm(self.dls.before_batch)\n",
    "    \n",
    "    is_split_str = hf_before_batch_tfm.is_split_into_words and isinstance(items[0], str)\n",
    "    is_df = isinstance(items, pd.DataFrame)\n",
    "    \n",
    "    if (not is_df and (is_split_str or not is_listy(items))): items = [items]\n",
    "    dl = self.dls.test_dl(items, rm_type_tfms=rm_type_tfms, num_workers=0)\n",
    "    \n",
    "    with self.no_bar():\n",
    "        probs, _, decoded_preds = self.get_preds(dl=dl, with_input=False, with_decoded=True)\n",
    "\n",
    "    trg_tfms = self.dls.tfms[self.dls.n_inp:]\n",
    "    \n",
    "    outs = []\n",
    "    probs, decoded_preds = L(probs), L(decoded_preds)\n",
    "    for i in range(len(items)):\n",
    "        item_probs = probs.itemgot(i)\n",
    "        item_dec_preds = decoded_preds.itemgot(i)\n",
    "        item_dec_labels = tuplify([tfm.decode(item_dec_preds[tfm_idx]) for tfm_idx, tfm in enumerate(trg_tfms)])\n",
    "        \n",
    "        outs.append((item_dec_labels, item_dec_preds, item_probs))\n",
    "    \n",
    "    return outs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as with `summary`, we need to replace fastai's `Learner.predict` method with the one above which is able to work with inputs that are represented by multiple tensors included in a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('positive',), (#1) [tensor(1)], (#1) [tensor([0.1070, 0.8930])])]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.blurr_predict('I really liked the movie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('positive',), (#1) [tensor(1)], (#1) [tensor([0.1070, 0.8930])]),\n",
       " (('negative',), (#1) [tensor(0)], (#1) [tensor([0.5693, 0.4307])])]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.blurr_predict(['I really liked the movie', 'I really hated the movie'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.271944</td>\n",
       "      <td>0.264807</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.214700</td>\n",
       "      <td>0.277946</td>\n",
       "      <td>0.905000</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "learn.fit_one_cycle(2, lr_max=slice(1e-7, 1e-4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.recorder.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The trouble with the book, \"Memoirs of a Geisha\" is that it had Japanese surfaces but underneath the surfaces it was all an American man's way of thinking. Reading the book is like watching a magnificent ballet with great music, sets, and costumes yet performed by barnyard animals dressed in those costumesso far from Japanese ways of thinking were the characters.&lt;br /&gt;&lt;br /&gt;The movie isn't about Japan or real geisha. It is a story about a few American men's mistaken ideas about Japan and geish</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;br /&gt;&lt;br /&gt;I'm sure things didn't exactly go the same way in the real life of Homer Hickam as they did in the film adaptation of his book, Rocket Boys, but the movie \"October Sky\" (an anagram of the book's title) is good enough to stand alone. I have not read Hickam's memoirs, but I am still able to enjoy and understand their film adaptation. The film, directed by Joe Johnston and written by Lewis Colick, records the story of teenager Homer Hickam (Jake Gyllenhaal), beginning in October of 195</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, max_n=2, trunc_at=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('positive',), (#1) [tensor(1)], (#1) [tensor([0.0989, 0.9011])])]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.blurr_predict(\"This was a really good movie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('negative',), (#1) [tensor(0)], (#1) [tensor([0.8622, 0.1378])])]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.blurr_predict(\"Acting was so bad it was almost funny.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_fname = 'seq_class_learn_export'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using fast.ai `Learner.export` and `load_learner`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.export(fname=f'{export_fname}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('negative',), (#1) [tensor(0)], (#1) [tensor([0.9236, 0.0764])])]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_learn = load_learner(fname=f'{export_fname}.pkl')\n",
    "inf_learn.blurr_predict(\"This movie should not be seen by anyone!!!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using ONNX - (TEMPORARILY UNAVAILABLE)\n",
    "\n",
    "Much of the inspiration for the code below comes from Zach Mueller's excellent [fastinference library](https://muellerzr.github.io/fastinference/), and in many places I simply adapted his code to work with blurr and the various huggingface transformers tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #export\n",
    "# import onnxruntime as ort\n",
    "# from onnxruntime.quantization import quantize_dynamic, QuantType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #export\n",
    "# @patch\n",
    "# def blurr_to_onnx(self:Learner, fname='export', path=None, quantize=False, excluded_input_names=[]):\n",
    "#     \"\"\"Export model to `ONNX` format\"\"\"\n",
    "#     if (path == None): path = self.path\n",
    "        \n",
    "#     dummy_b = self.dls.one_batch()    \n",
    "    \n",
    "#     # inputs\n",
    "#     for n in excluded_input_names:\n",
    "#         if (n in dummy_b[0]): del dummy_b[0][n]\n",
    "            \n",
    "#     input_names = list(dummy_b[0].keys())\n",
    "#     dynamic_axes = { n: {0:'batch_size', 1:'sequence'} for n in input_names if n in self.model.hf_model_fwd_args}\n",
    "    \n",
    "#     # outputs\n",
    "#     output_names = [ f'output_{i}' for i in range(len(dummy_b) - self.dls.n_inp) ]\n",
    "#     for n in output_names: dynamic_axes[n] = { 0:'batch_size' }\n",
    "    \n",
    "#     torch.onnx.export(model=self.model, \n",
    "#                       args=dummy_b[:self.dls.n_inp],    # everything but the targets\n",
    "#                       f=self.path/f'{fname}.onnx',      # onnx filename\n",
    "#                       opset_version=11,                 # required for get errors\n",
    "#                       input_names=input_names,          # transformer dictionary keys for input\n",
    "#                       output_names=output_names,        # one for each target\n",
    "#                       dynamic_axes=dynamic_axes)        # see above\n",
    "    \n",
    "#     if (quantize):\n",
    "#         quant_model_fpath = self.path/f'{fname}-quant.onnx'\n",
    "#         quant_model = quantize_dynamic(self.path/f'{fname}.onnx', quant_model_fpath, weight_type=QuantType.QUInt8)\n",
    "\n",
    "#     dls_export = self.dls.new_empty()\n",
    "#     dls_export.loss_func = self.loss_func\n",
    "#     dls_export.hf_model_fwd_args = self.model.hf_model_fwd_args # we need this to exclude non-model args in onnx\n",
    "    \n",
    "#     torch.save(dls_export, self.path/f'{fname}-dls.pkl', pickle_protocol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #slow\n",
    "# learn.blurr_to_onnx(export_fname, quantize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #export\n",
    "# class blurrONNX():\n",
    "#     def __init__(self, fname='export', path=Path('.'), use_quant_version=False): \n",
    "#         self.fname, self.path = fname, path\n",
    "        \n",
    "#         onnx_fname = f'{fname}-quant.onnx' if (use_quant_version) else f'{fname}.onnx'\n",
    "#         self.ort_session = ort.InferenceSession(str(self.path/onnx_fname))\n",
    "        \n",
    "#         self.dls = torch.load(f'{self.path}/{fname}-dls.pkl')\n",
    "#         self.trg_tfms = self.dls.tfms[self.dls.n_inp:]\n",
    "#         self.tok_is_split_into_words = self.dls.before_batch[0].is_split_into_words\n",
    "#         self.hf_model_fwd_args = self.dls.hf_model_fwd_args\n",
    "        \n",
    "#     def predict(self, items, rm_type_tfms=None):\n",
    "#         is_split_str = self.tok_is_split_into_words and isinstance(items[0], str)\n",
    "#         is_df = isinstance(items, pd.DataFrame)\n",
    "\n",
    "#         if (not is_df and (is_split_str or not is_listy(items))): items = [items]\n",
    "#         dl = self.dls.test_dl(items, rm_type_tfms=rm_type_tfms, num_workers=0)\n",
    "\n",
    "#         outs = []\n",
    "#         for b in dl:\n",
    "#             xb = b[0]\n",
    "#             inp = self._to_np(xb)\n",
    "            \n",
    "#             # remove any args not found in the transformers forward func\n",
    "#             for k in list(inp.keys()):\n",
    "#                 if (k not in self.hf_model_fwd_args): del inp[k]\n",
    "                    \n",
    "#             res = self.ort_session.run(None, inp)\n",
    "#             tensor_res = [ tensor(r) for r in res ]\n",
    "#             probs = L([ self.dls.loss_func.activation(tr) for tr in tensor_res ])\n",
    "#             decoded_preds = L([ self.dls.loss_func.decodes(tr) for tr in tensor_res ])\n",
    "\n",
    "#             for i in range(len(xb['input_ids'])):\n",
    "#                 item_probs = probs.itemgot(i)\n",
    "#                 item_dec_preds = decoded_preds.itemgot(i)\n",
    "#                 item_dec_labels = tuplify([tfm.decode(item_dec_preds[tfm_idx]) \n",
    "#                                            for tfm_idx, tfm in enumerate(self.trg_tfms)])\n",
    "\n",
    "#                 outs.append((item_dec_labels, item_dec_preds, item_probs))\n",
    "            \n",
    "#         return outs\n",
    "\n",
    "#     #----- utility -----\n",
    "#     def _to_np(self, xb): return { k: v.cpu().numpy() for k,v in xb.items() }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #slow\n",
    "# onnx_inf = blurrONNX(export_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #slow\n",
    "# onnx_inf.predict(['I really liked the movie'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #slow\n",
    "# %timeit inf_learn.blurr_predict(['I really liked the movie', 'I hated everything in it'])\n",
    "# %timeit onnx_inf.predict(['I really liked the movie', 'I hated everything in it'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #slow\n",
    "# onnx_inf = blurrONNX(export_fname, use_quant_version=True)\n",
    "# onnx_inf.predict(['I hated everything in it'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #slow\n",
    "# %timeit inf_learn.blurr_predict(['I really liked the movie', 'I hated everything in it'])\n",
    "# %timeit onnx_inf.predict(['I really liked the movie', 'I hated everything in it'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High-level API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blearner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of constructing our low-level `Learner`, we can use the `Blearner` class which will default to give you want your normally want for traning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "try: del learn; del inf_learn; torch.cuda.empty_cache()\n",
    "except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide_output\n",
    "model_cls = AutoModelForSequenceClassification\n",
    "\n",
    "pretrained_model_name = \"distilroberta-base\" # \"distilbert-base-uncased\" \"bert-base-uncased\"\n",
    "hf_arch, hf_config, hf_tokenizer, hf_model = BLURR.get_hf_objects(pretrained_model_name, model_cls=model_cls)\n",
    "\n",
    "dls = dblock.dataloaders(imdb_df, bs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@delegates(Learner.__init__)\n",
    "class Blearner(Learner):\n",
    "\n",
    "    def __init__(self, dls, hf_model, base_model_cb=HF_BaseModelCallback, **kwargs):\n",
    "\n",
    "        model = kwargs.get('model', HF_BaseModelWrapper(hf_model))\n",
    "        loss_func = kwargs.pop('loss_func', dls.loss_func)\n",
    "        splitter = kwargs.pop('splitter', hf_splitter)\n",
    "        \n",
    "        super().__init__(dls, model=model, loss_func=loss_func, splitter=splitter, **kwargs)\n",
    "        \n",
    "        self.add_cb(base_model_cb)\n",
    "        self.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Blearner(dls, hf_model, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.392141</td>\n",
       "      <td>0.355955</td>\n",
       "      <td>0.855000</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "learn.fit_one_cycle(1, lr_max=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The trouble with the book, \"Memoirs of a Geisha\" is that it had Japanese surfaces but underneath the surfaces it was all an American man's way of thinking. Reading the book is like watching a magnificent ballet with great music, sets, and costumes yet performed by barnyard animals dressed in those costumesso far from Japanese ways of thinking were the characters.&lt;br /&gt;&lt;br /&gt;The movie isn't about Japan or real geisha. It is a story about a few American men's mistaken ideas about Japan and geish</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;br /&gt;&lt;br /&gt;I'm sure things didn't exactly go the same way in the real life of Homer Hickam as they did in the film adaptation of his book, Rocket Boys, but the movie \"October Sky\" (an anagram of the book's title) is good enough to stand alone. I have not read Hickam's memoirs, but I am still able to enjoy and understand their film adaptation. The film, directed by Joe Johnston and written by Lewis Colick, records the story of teenager Homer Hickam (Jake Gyllenhaal), beginning in October of 195</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, max_n=2, trunc_at=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('positive',), (#1) [tensor(1)], (#1) [tensor([0.3941, 0.6059])])]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.blurr_predict(\"This was a really good movie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('negative',), (#1) [tensor(0)], (#1) [tensor([0.9340, 0.0660])])]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.export(fname=f'{export_fname}.pkl')\n",
    "inf_learn = load_learner(fname=f'{export_fname}.pkl')\n",
    "inf_learn.blurr_predict(\"This movie should not be seen by anyone!!!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BlearnerForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also introduct a task specific `Blearner` that handles everything for you using sensible defaults ... DataBlock, DataLoaders, and Blearner!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "try: del learn; del inf_learn; torch.cuda.empty_cache()\n",
    "except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@delegates(Blearner.__init__)\n",
    "class BlearnerForSequenceClassification(Blearner):\n",
    "\n",
    "    def __init__(self, dls, hf_model, **kwargs):\n",
    "        super().__init__(dls, hf_model, **kwargs)\n",
    "        \n",
    "    @classmethod\n",
    "    def get_model_cls(self): \n",
    "        return AutoModelForSequenceClassification\n",
    "    \n",
    "    @classmethod\n",
    "    def _get_x(cls, r, attr): \n",
    "        return r[attr] if (isinstance(attr, str)) else tuple(r[inp] for inp in attr)\n",
    "    \n",
    "    @classmethod\n",
    "    def _get_y(cls, r, attr): \n",
    "        return r[attr] if (isinstance(attr, str)) else [r[inp] for inp in attr]\n",
    "    \n",
    "    @classmethod\n",
    "    def _create_learner(cls, data, pretrained_model_name_or_path, preprocess_func, \n",
    "                        text, label, n_labels, \n",
    "                        dblock_splitter, dl_kwargs, learner_kwargs):\n",
    "        \n",
    "        # get our hf objects\n",
    "        hf_arch, hf_config, hf_tokenizer, hf_model = BLURR.get_hf_objects(pretrained_model_name_or_path, \n",
    "                                                                          model_cls=cls.get_model_cls(), \n",
    "                                                                          config_kwargs={'num_labels': n_labels})\n",
    "        \n",
    "        # if we need to preprocess the raw data before creating our DataLoaders\n",
    "        if (preprocess_func):\n",
    "            data = preprocess_func(data, hf_arch, hf_config, hf_tokenizer, hf_model, text, label)\n",
    "            \n",
    "        # not all architectures include a native pad_token (e.g., gpt2, ctrl, etc...), so we add one here\n",
    "        if (hf_tokenizer.pad_token is None): \n",
    "            hf_tokenizer.add_special_tokens({'pad_token': '<pad>'})  \n",
    "            hf_config.pad_token_id = hf_tokenizer.get_vocab()['<pad>']\n",
    "            hf_model.resize_token_embeddings(len(hf_tokenizer))\n",
    "        \n",
    "        # build dblock, dls, and default metrics (optionsl)\n",
    "        if (isinstance(data, pd.DataFrame)):\n",
    "            get_x = ColReader(text)\n",
    "            get_y = ColReader(label)\n",
    "        else:\n",
    "            get_x = partial(cls._get_x, attr=text)\n",
    "            get_y = partial(cls._get_y, attr=label)\n",
    "            \n",
    "        if (is_listy(label)):\n",
    "            trg_block = MultiCategoryBlock(encoded=True, vocab=label)\n",
    "            learner_kwargs['metrics'] = learner_kwargs.get('metrics', [F1ScoreMulti(), accuracy_multi])\n",
    "        else: \n",
    "            trg_block = CategoryBlock\n",
    "            learner_kwargs['metrics'] = learner_kwargs.get('metrics', [F1Score(), accuracy])\n",
    "        \n",
    "        blocks = (HF_TextBlock(hf_arch, hf_config, hf_tokenizer, hf_model), trg_block)\n",
    "        dblock = DataBlock(blocks=blocks, \n",
    "                           get_x=get_x,   \n",
    "                           get_y=get_y, \n",
    "                           splitter=dblock_splitter)\n",
    "        \n",
    "        dls = dblock.dataloaders(data, **dl_kwargs.copy())\n",
    "        \n",
    "        # return BLearner instance\n",
    "        return cls(dls, hf_model, **learner_kwargs.copy())\n",
    "    \n",
    "    @classmethod\n",
    "    def from_dataframe(cls, df, pretrained_model_name_or_path, preprocess_func=None,\n",
    "                       text='text', label='label', n_labels=None, dblock_splitter=ColSplitter(), \n",
    "                       dl_kwargs={}, learner_kwargs={}):\n",
    "        \n",
    "        # we need to tell transformer how many labels/classes to expect\n",
    "        if (n_labels is None):\n",
    "            n_labels = len(label) if(is_listy(label)) else len(df[label].unique())\n",
    "            \n",
    "        return cls._create_learner(df, pretrained_model_name_or_path, preprocess_func, \n",
    "                                   text, label, n_labels, dblock_splitter, dl_kwargs, learner_kwargs)\n",
    "    \n",
    "        \n",
    "    @classmethod\n",
    "    def from_csv(cls, csv_file, pretrained_model_name_or_path, preprocess_func=None,\n",
    "                 text='text', label='label', n_labels=None, dblock_splitter=None, \n",
    "                 dl_kwargs={}, learner_kwargs={}):\n",
    "        \n",
    "        df = pd.read_csv(csv_file)\n",
    "        \n",
    "        return cls.from_dataframe(df, \n",
    "                                  pretrained_model_name_or_path=pretrained_model_name_or_path, \n",
    "                                  preprocess_func=preprocess_func,\n",
    "                                  text=text, label=label, n_labels=n_labels, \n",
    "                                  dblock_splitter=dblock_splitter, \n",
    "                                  dl_kwargs=dl_kwargs, learner_kwargs=learner_kwargs)\n",
    "    \n",
    "    @classmethod\n",
    "    def from_dictionaries(cls, ds, pretrained_model_name_or_path, preprocess_func=None,\n",
    "                          text='text', label='label', n_labels=None, dblock_splitter=RandomSplitter(), \n",
    "                          dl_kwargs={}, learner_kwargs={}):\n",
    "        \n",
    "        # we need to tell transformer how many labels/classes to expect\n",
    "        if (n_labels is None):\n",
    "            n_labels = len(label) if(is_listy(label)) else len(set([item[label] for item in ds]))\n",
    "            \n",
    "        return cls._create_learner(ds, pretrained_model_name_or_path, preprocess_func, \n",
    "                                   text, label, n_labels, dblock_splitter, dl_kwargs, learner_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = BlearnerForSequenceClassification.from_dataframe(imdb_df, 'distilroberta-base', \n",
    "                                                         text='text', label='label', dl_kwargs={'bs':4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.374203</td>\n",
       "      <td>0.291758</td>\n",
       "      <td>0.881356</td>\n",
       "      <td>0.895000</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "learn.fit_one_cycle(1, lr_max=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The trouble with the book, \"Memoirs of a Geisha\" is that it had Japanese surfaces but underneath the surfaces it was all an American man's way of thinking. Reading the book is like watching a magnificent ballet with great music, sets, and costumes yet performed by barnyard animals dressed in those costumesso far from Japanese ways of thinking were the characters.&lt;br /&gt;&lt;br /&gt;The movie isn't about Japan or real geisha. It is a story about a few American men's mistaken ideas about Japan and geish</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;br /&gt;&lt;br /&gt;I'm sure things didn't exactly go the same way in the real life of Homer Hickam as they did in the film adaptation of his book, Rocket Boys, but the movie \"October Sky\" (an anagram of the book's title) is good enough to stand alone. I have not read Hickam's memoirs, but I am still able to enjoy and understand their film adaptation. The film, directed by Joe Johnston and written by Lewis Colick, records the story of teenager Homer Hickam (Jake Gyllenhaal), beginning in October of 195</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results(learner=learn, max_n=2, trunc_at=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('positive',), (#1) [tensor(1)], (#1) [tensor([0.1881, 0.8119])])]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.blurr_predict(\"This was a really good movie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('negative',), (#1) [tensor(0)], (#1) [tensor([0.7814, 0.2186])])]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.export(fname=f'{export_fname}.pkl')\n",
    "inf_learn = load_learner(fname=f'{export_fname}.pkl')\n",
    "inf_learn.blurr_predict(\"This movie should not be seen by anyone!!!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests\n",
    "\n",
    "The tests below to ensure the core training code above works for **all** pretrained sequence classification models available in huggingface.  These tests are excluded from the CI workflow because of how long they would take to run and the amount of data that would be required to download.\n",
    "\n",
    "**Note**: Feel free to modify the code below to test whatever pretrained classification models you are working with ... and if any of your pretrained sequence classification models fail, please submit a github issue *(or a PR if you'd like to fix it yourself)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: del learn; del inf_learn; torch.cuda.empty_cache()\n",
    "except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[transformers.models.albert.modeling_albert.AlbertForSequenceClassification,\n",
       " transformers.models.bart.modeling_bart.BartForSequenceClassification,\n",
       " transformers.models.bert.modeling_bert.BertForSequenceClassification,\n",
       " transformers.models.big_bird.modeling_big_bird.BigBirdForSequenceClassification,\n",
       " transformers.models.bigbird_pegasus.modeling_bigbird_pegasus.BigBirdPegasusForSequenceClassification,\n",
       " transformers.models.ctrl.modeling_ctrl.CTRLForSequenceClassification,\n",
       " transformers.models.camembert.modeling_camembert.CamembertForSequenceClassification,\n",
       " transformers.models.convbert.modeling_convbert.ConvBertForSequenceClassification,\n",
       " transformers.models.deberta.modeling_deberta.DebertaForSequenceClassification,\n",
       " transformers.models.deberta_v2.modeling_deberta_v2.DebertaV2ForSequenceClassification,\n",
       " transformers.models.distilbert.modeling_distilbert.DistilBertForSequenceClassification,\n",
       " transformers.models.electra.modeling_electra.ElectraForSequenceClassification,\n",
       " transformers.models.flaubert.modeling_flaubert.FlaubertForSequenceClassification,\n",
       " transformers.models.funnel.modeling_funnel.FunnelForSequenceClassification,\n",
       " transformers.models.gpt2.modeling_gpt2.GPT2ForSequenceClassification,\n",
       " transformers.models.gpt_neo.modeling_gpt_neo.GPTNeoForSequenceClassification,\n",
       " transformers.models.ibert.modeling_ibert.IBertForSequenceClassification,\n",
       " transformers.models.led.modeling_led.LEDForSequenceClassification,\n",
       " transformers.models.layoutlm.modeling_layoutlm.LayoutLMForSequenceClassification,\n",
       " transformers.models.longformer.modeling_longformer.LongformerForSequenceClassification,\n",
       " transformers.models.mbart.modeling_mbart.MBartForSequenceClassification,\n",
       " transformers.models.mpnet.modeling_mpnet.MPNetForSequenceClassification,\n",
       " transformers.models.megatron_bert.modeling_megatron_bert.MegatronBertForSequenceClassification,\n",
       " transformers.models.mobilebert.modeling_mobilebert.MobileBertForSequenceClassification,\n",
       " transformers.models.openai.modeling_openai.OpenAIGPTForSequenceClassification,\n",
       " transformers.models.reformer.modeling_reformer.ReformerForSequenceClassification,\n",
       " transformers.models.roberta.modeling_roberta.RobertaForSequenceClassification,\n",
       " transformers.models.squeezebert.modeling_squeezebert.SqueezeBertForSequenceClassification,\n",
       " transformers.models.tapas.modeling_tapas.TapasForSequenceClassification,\n",
       " transformers.models.transfo_xl.modeling_transfo_xl.TransfoXLForSequenceClassification,\n",
       " transformers.models.xlm.modeling_xlm.XLMForSequenceClassification,\n",
       " transformers.models.xlm_roberta.modeling_xlm_roberta.XLMRobertaForSequenceClassification,\n",
       " transformers.models.xlnet.modeling_xlnet.XLNetForSequenceClassification]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ model_type for model_type in BLURR.get_models(task='SequenceClassification') \n",
    " if (not model_type.__name__.startswith('TF')) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model_names = [\n",
    "    'albert-base-v1',\n",
    "    'facebook/bart-base',\n",
    "    'bert-base-uncased',\n",
    "    'google/bigbird-roberta-base',\n",
    "    'sshleifer/tiny-ctrl',\n",
    "    'camembert-base',\n",
    "    'sarnikowski/convbert-medium-small-da-cased',\n",
    "    'microsoft/deberta-base',\n",
    "    'microsoft/deberta-v2-xlarge',\n",
    "    'distilbert-base-uncased',\n",
    "    'monologg/electra-small-finetuned-imdb',\n",
    "    'flaubert/flaubert_small_cased', \n",
    "    'huggingface/funnel-small-base',\n",
    "    'gpt2',\n",
    "    'kssteven/ibert-roberta-base',\n",
    "    'allenai/led-base-16384',\n",
    "    'microsoft/layoutlm-base-uncased',\n",
    "    'allenai/longformer-base-4096',\n",
    "    'sshleifer/tiny-mbart', \n",
    "    'microsoft/mpnet-base',\n",
    "    'google/mobilebert-uncased',\n",
    "    'openai-gpt',\n",
    "    #'reformer-enwik8',                  # (see model card; does not work with/require a tokenizer so no bueno here)\n",
    "    'roberta-base',\n",
    "    'squeezebert/squeezebert-uncased',\n",
    "    #'google/tapas-base',                # (requires pip install torch-scatter)\n",
    "    'transfo-xl-wt103', \n",
    "    'xlm-mlm-en-2048',\n",
    "    'xlm-roberta-base',\n",
    "    'xlnet-base-cased'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.IMDB_SAMPLE)\n",
    "\n",
    "model_path = Path('models')\n",
    "imdb_df = pd.read_csv(path/'texts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== albert-base-v1 ===\n",
      "\n",
      "architecture:\talbert\n",
      "tokenizer:\tAlbertTokenizerFast\n",
      "model:\t\tAlbertForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the trouble with the book, \"memoirs of a geisha\" is that it had japanese surfaces but underneath the surfaces it was all an american man's way of thinking. reading the book is like watching a magnificent ballet with great music, sets, and costumes ye</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>to review this movie, i without any doubt would have to quote that memorable scene in tarantino's \"pulp fiction\" (1994) when jules and vincent are talking about mia wallace and what she does for a living. jules tells vincent that the \"only thing she</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== facebook/bart-base ===\n",
      "\n",
      "architecture:\tbart\n",
      "tokenizer:\tBartTokenizerFast\n",
      "model:\t\tBartForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The trouble with the book, \"Memoirs of a Geisha\" is that it had Japanese surfaces but underneath the surfaces it was all an American man's way of thinking. Reading the book is like watching a magnificent ballet with great music, sets, and costumes y</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How viewers react to this new \"adaption\" of Shirley Jackson's book, which was promoted as NOT being a remake of the original 1963 movie (true enough), will be based, I suspect, on the following: those who were big fans of either the book or original</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== bert-base-uncased ===\n",
      "\n",
      "architecture:\tbert\n",
      "tokenizer:\tBertTokenizerFast\n",
      "model:\t\tBertForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the trouble with the book, \" memoirs of a geisha \" is that it had japanese surfaces but underneath the surfaces it was all an american man's way of thinking. reading the book is like watching a magnificent ballet with great music, sets, and costumes</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt; br / &gt; &lt; br / &gt; i'm sure things didn't exactly go the same way in the real life of homer hickam as they did in the film adaptation of his book, rocket boys, but the movie \" october sky \" ( an anagram of the book's title )</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== google/bigbird-roberta-base ===\n",
      "\n",
      "architecture:\tbig_bird\n",
      "tokenizer:\tBigBirdTokenizerFast\n",
      "model:\t\tBigBirdForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The trouble with the book, \"Memoirs of a Geisha\" is that it had Japanese surfaces but underneath the surfaces it was all an American man's way of thinking. Reading the book is like watching a magnificent ballet with great music, sets, and costumes ye</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;br /&gt;&lt;br /&gt;I'm sure things didn't exactly go the same way in the real life of Homer Hickam as they did in the film adaptation of his book, Rocket Boys, but the movie \"October Sky\" (an anagram of the book's title) is good enough to stand alone</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== sshleifer/tiny-ctrl ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\tctrl\n",
      "tokenizer:\tCTRLTokenizer\n",
      "model:\t\tCTRLForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The trouble with the book, \"Memoirs of a Geisha\" is that it had Japanese surfaces but underneath the surfaces it was all an American man's way of thinking. Reading the book is like watching a magnificent ballet with great music, sets, and costumes ye</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;br /&gt;&lt;br /&gt;I'm sure things didn't exactly go the same way in the real life of Homer Hickam as they did in the film adaptation of his book, Rocket Boys, but the movie \"October Sky\" (an anagram of the book's title) is good enough to stand alone. I hav</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== camembert-base ===\n",
      "\n",
      "architecture:\tcamembert\n",
      "tokenizer:\tCamembertTokenizerFast\n",
      "model:\t\tCamembertForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The trouble with the book, \"Memoirs of a Geisha\" is that it had Japanese surfaces but underneath the surfaces it was all an American man's way of thinking. Reading the book is like watching a magnificent ballet with great music,</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;br /&gt;&lt;br /&gt;I'm sure things didn't exactly go the same way in the real life of Homer Hickam as they did in the film adaptation of his book, Rocket Boys, but the movie \"O</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== sarnikowski/convbert-medium-small-da-cased ===\n",
      "\n",
      "architecture:\tconvbert\n",
      "tokenizer:\tConvBertTokenizerFast\n",
      "model:\t\tConvBertForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The trouble with the book, \" Memoirs of a Geisha \" is that it had Japanese surfaces but underneath the surfaces it was all an American man's way of thinking. Reading the book is like watching a mag</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt; br / &gt; &lt; br / &gt; I'm sure things didn't exactly go the same way in the real life of Homer Hickam as they did in the film adaptation of his book, Rocket Boys, but the movie</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== microsoft/deberta-base ===\n",
      "\n",
      "architecture:\tdeberta\n",
      "tokenizer:\tDebertaTokenizerFast\n",
      "model:\t\tDebertaForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The trouble with the book, \"Memoirs of a Geisha\" is that it had Japanese surfaces but underneath the surfaces it was all an American man's way of thinking. Reading the book is like watching a magnificent ballet with great music, sets, and costumes ye</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;br /&gt;&lt;br /&gt;I'm sure things didn't exactly go the same way in the real life of Homer Hickam as they did in the film adaptation of his book, Rocket Boys, but the movie \"October Sky\" (an anagram of the book's title) is good enough to stand alone</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== microsoft/deberta-v2-xlarge ===\n",
      "\n",
      "architecture:\tdeberta_v2\n",
      "tokenizer:\tDebertaV2Tokenizer\n",
      "model:\t\tDebertaV2ForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The trouble with the book, \"Memoirs of a Geisha\" is that it had Japanese surfaces but underneath the surfaces it was all an American man's way of thinking. Reading the book is like watching a magnificent ballet with great music, sets, and costumes ye</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>To review this movie, I without any doubt would have to quote that memorable scene in Tarantino's \"Pulp Fiction\" (1994) when Jules and Vincent are talking about Mia Wallace and what she does for a living. Jules tells Vincent that the \"Only thing she</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== distilbert-base-uncased ===\n",
      "\n",
      "architecture:\tdistilbert\n",
      "tokenizer:\tDistilBertTokenizerFast\n",
      "model:\t\tDistilBertForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the trouble with the book, \" memoirs of a geisha \" is that it had japanese surfaces but underneath the surfaces it was all an american man's way of thinking. reading the book is like watching a magnificent ballet with great music, sets, and costumes</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt; br / &gt; &lt; br / &gt; i'm sure things didn't exactly go the same way in the real life of homer hickam as they did in the film adaptation of his book, rocket boys, but the movie \" october sky \" ( an anagram of the book's title )</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== monologg/electra-small-finetuned-imdb ===\n",
      "\n",
      "architecture:\telectra\n",
      "tokenizer:\tElectraTokenizerFast\n",
      "model:\t\tElectraForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the trouble with the book, \" memoirs of a geisha \" is that it had japanese surfaces but underneath the surfaces it was all an american man's way of thinking. reading the book is like watching a magnificent ballet with great music, sets, and costumes</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>how viewers react to this new \" adaption \" of shirley jackson's book, which was promoted as not being a remake of the original 1963 movie ( true enough ), will be based, i suspect, on the following : those who were big fans of either the book or orig</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== flaubert/flaubert_small_cased ===\n",
      "\n",
      "architecture:\tflaubert\n",
      "tokenizer:\tFlaubertTokenizer\n",
      "model:\t\tFlaubertForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The trouble with the book, \" Memoirs of a Geisha \" is that it had Japanese surfaces but underneath the surfaces it was all an American man' s way of thinking. Reading the book is like watching a magnificent ballet with great music, sets</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt; br / &gt; &lt; br / &gt; I' m sure things didn' t exactly go the same way in the real life of Homer Hickam as they did in the film adaptation of his book, Rocket Boys, but the movie \" October Sky \" ( an</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== huggingface/funnel-small-base ===\n",
      "\n",
      "architecture:\tfunnel\n",
      "tokenizer:\tFunnelTokenizerFast\n",
      "model:\t\tFunnelForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the trouble with the book, \" memoirs of a geisha \" is that it had japanese surfaces but underneath the surfaces it was all an american man's way of thinking. reading the book is like watching a magnificent ballet with great music, sets, and costumes</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt; br / &gt; &lt; br / &gt; i'm sure things didn't exactly go the same way in the real life of homer hickam as they did in the film adaptation of his book, rocket boys, but the movie \" october sky \" ( an anagram of the book's title )</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== gpt2 ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\tgpt2\n",
      "tokenizer:\tGPT2TokenizerFast\n",
      "model:\t\tGPT2ForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The trouble with the book, \"Memoirs of a Geisha\" is that it had Japanese surfaces but underneath the surfaces it was all an American man's way of thinking. Reading the book is like watching a magnificent ballet with great music, sets, and costumes y</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;br /&gt;&lt;br /&gt;I'm sure things didn't exactly go the same way in the real life of Homer Hickam as they did in the film adaptation of his book, Rocket Boys, but the movie \"October Sky\" (an anagram of the book's title) is good enough to stand alone. I</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== kssteven/ibert-roberta-base ===\n",
      "\n",
      "architecture:\tibert\n",
      "tokenizer:\tRobertaTokenizer\n",
      "model:\t\tIBertForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The trouble with the book, \"Memoirs of a Geisha\" is that it had Japanese surfaces but underneath the surfaces it was all an American man's way of thinking. Reading the book is like watching a magnificent ballet with great music, sets, and costumes y</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;br /&gt;&lt;br /&gt;I'm sure things didn't exactly go the same way in the real life of Homer Hickam as they did in the film adaptation of his book, Rocket Boys, but the movie \"October Sky\" (an anagram of the book's title) is good enough to stand alone</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== allenai/led-base-16384 ===\n",
      "\n",
      "architecture:\tled\n",
      "tokenizer:\tLEDTokenizerFast\n",
      "model:\t\tLEDForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/400 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== microsoft/layoutlm-base-uncased ===\n",
      "\n",
      "architecture:\tlayoutlm\n",
      "tokenizer:\tLayoutLMTokenizerFast\n",
      "model:\t\tLayoutLMForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the trouble with the book, \" memoirs of a geisha \" is that it had japanese surfaces but underneath the surfaces it was all an american man's way of thinking. reading the book is like watching a magnificent ballet with great music, sets, and costumes</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>to review this movie, i without any doubt would have to quote that memorable scene in tarantino's \" pulp fiction \" ( 1994 ) when jules and vincent are talking about mia wallace and what she does for a living. jules tells vincent that the \" only thing</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== allenai/longformer-base-4096 ===\n",
      "\n",
      "architecture:\tlongformer\n",
      "tokenizer:\tLongformerTokenizerFast\n",
      "model:\t\tLongformerForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The trouble with the book, \"Memoirs of a Geisha\" is that it had Japanese surfaces but underneath the surfaces it was all an American man's way of thinking. Reading the book is like watching a magnificent ballet with great music, sets, and costumes y</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How viewers react to this new \"adaption\" of Shirley Jackson's book, which was promoted as NOT being a remake of the original 1963 movie (true enough), will be based, I suspect, on the following: those who were big fans of either the book or original</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== sshleifer/tiny-mbart ===\n",
      "\n",
      "architecture:\tmbart\n",
      "tokenizer:\tMBartTokenizerFast\n",
      "model:\t\tMBartForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The trouble with the book, \"Memoirs of a Geisha\" is that it had Japanese surfaces but underneath the surfaces it was all an American man's way of thinking. Reading the book is like watching a magnificent ballet with great music, sets, and costume</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;br /&gt;&lt;br /&gt;I'm sure things didn't exactly go the same way in the real life of Homer Hickam as they did in the film adaptation of his book, Rocket Boys, but the movie \"October Sky\" (an anagram of the book's title</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== microsoft/mpnet-base ===\n",
      "\n",
      "architecture:\tmpnet\n",
      "tokenizer:\tMPNetTokenizerFast\n",
      "model:\t\tMPNetForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the trouble with the book, \" memoirs of a geisha \" is that it had japanese surfaces but underneath the surfaces it was all an american man's way of thinking. reading the book is like watching a magnificent ballet with great music, sets, and costumes</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>how viewers react to this new \" adaption \" of shirley jackson's book, which was promoted as not being a remake of the original 1963 movie ( true enough ), will be based, i suspect, on the following : those who were big fans of either the book or orig</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== google/mobilebert-uncased ===\n",
      "\n",
      "architecture:\tmobilebert\n",
      "tokenizer:\tMobileBertTokenizerFast\n",
      "model:\t\tMobileBertForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the trouble with the book, \" memoirs of a geisha \" is that it had japanese surfaces but underneath the surfaces it was all an american man's way of thinking. reading the book is like watching a magnificent ballet with great music, sets, and costumes</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>how viewers react to this new \" adaption \" of shirley jackson's book, which was promoted as not being a remake of the original 1963 movie ( true enough ), will be based, i suspect, on the following : those who were big fans of either the book or orig</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== openai-gpt ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\topenai\n",
      "tokenizer:\tOpenAIGPTTokenizerFast\n",
      "model:\t\tOpenAIGPTForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the trouble with the book, \" memoirs of a geisha \" is that it had japanese surfaces but underneath the surfaces it was all an american man's way of thinking. reading the book is like watching a magnificent ballet with great music, sets, and costumes</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt; br / &gt; &lt; br / &gt; i'm sure things didn't exactly go the same way in the real life of homer hickam as they did in the film adaptation of his book, rocket boys, but the movie \" october sky \" ( an anagram of the book's title ) is</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== roberta-base ===\n",
      "\n",
      "architecture:\troberta\n",
      "tokenizer:\tRobertaTokenizerFast\n",
      "model:\t\tRobertaForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The trouble with the book, \"Memoirs of a Geisha\" is that it had Japanese surfaces but underneath the surfaces it was all an American man's way of thinking. Reading the book is like watching a magnificent ballet with great music, sets, and costumes y</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;br /&gt;&lt;br /&gt;I'm sure things didn't exactly go the same way in the real life of Homer Hickam as they did in the film adaptation of his book, Rocket Boys, but the movie \"October Sky\" (an anagram of the book's title) is good enough to stand alone</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== squeezebert/squeezebert-uncased ===\n",
      "\n",
      "architecture:\tsqueezebert\n",
      "tokenizer:\tSqueezeBertTokenizerFast\n",
      "model:\t\tSqueezeBertForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the trouble with the book, \" memoirs of a geisha \" is that it had japanese surfaces but underneath the surfaces it was all an american man's way of thinking. reading the book is like watching a magnificent ballet with great music, sets, and costumes</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt; br / &gt; &lt; br / &gt; i'm sure things didn't exactly go the same way in the real life of homer hickam as they did in the film adaptation of his book, rocket boys, but the movie \" october sky \" ( an anagram of the book's title )</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== transfo-xl-wt103 ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/miniconda3/envs/blurr/lib/python3.9/site-packages/torch/nn/modules/container.py:435: UserWarning: Setting attributes on ParameterList is not supported.\n",
      "  warnings.warn(\"Setting attributes on ParameterList is not supported.\")\n",
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture:\ttransfo_xl\n",
      "tokenizer:\tTransfoXLTokenizer\n",
      "model:\t\tTransfoXLForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wgilliam/miniconda3/envs/blurr/lib/python3.9/site-packages/torch/nn/modules/container.py:435: UserWarning: Setting attributes on ParameterList is not supported.\n",
      "  warnings.warn(\"Setting attributes on ParameterList is not supported.\")\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The trouble with the book, \"Memoirs of a Geisha\" is that it had Japanese surfaces but underneath the surfaces it was all an American man's way of thinking. Reading the book is like watching a magnificent ballet with great music, sets, and costumes ye</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt; br / &gt; &lt; br / &gt; I'm sure things didn't exactly go the same way in the real life of Homer Hickam as they did in the film adaptation of his book, Rocket Boys, but the movie \"October Sky\" (an anagram of the book's title) is good enough to stand alone.</td>\n",
       "      <td>positive</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== xlm-mlm-en-2048 ===\n",
      "\n",
      "architecture:\txlm\n",
      "tokenizer:\tXLMTokenizer\n",
      "model:\t\tXLMForSequenceClassification\n",
      "\n",
      "*** TESTING DataLoaders ***\n",
      "*** TESTING Training/Results ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the trouble with the book, \" memoirs of a geisha \" is that it had japanese surfaces but underneath the surfaces it was all an american man's way of thinking. reading the book is like watching a magnificent ballet with great music, sets, and costumes</td>\n",
       "      <td>negative</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bonanza had a great cast of wonderful actors. lorne greene, pernell whitaker, michael landon, dan blocker, and even guy williams ( as the cousin who was brought in for several episodes during 1964 to replace adam when he was leaving the series ). the</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== xlm-roberta-base ===\n",
      "\n",
      "architecture:\txlm_roberta\n",
      "tokenizer:\tXLMRobertaTokenizerFast\n",
      "model:\t\tXLMRobertaForSequenceClassification\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 734.00 MiB (GPU 1; 10.91 GiB total capacity; 9.36 GiB already allocated; 652.25 MiB free; 9.61 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-eff15dac96f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m# 3. configure our Learner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHF_BaseModelWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhf_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     learn = Learner(dls, \n\u001b[1;32m     43\u001b[0m                     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/blurr/lib/python3.9/site-packages/fastcore/meta.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'__pre_init__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__pre_init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'__post_init__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__post_init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-ef1362c0b137>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, hf_model, output_hidden_states, output_attentions, hf_model_kwargs)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mstore_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'output_hidden_states, output_attentions, hf_model_kwargs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhf_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhf_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mhf_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhf_model_fwd_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhf_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/blurr/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    461\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m         \"\"\"\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/blurr/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/blurr/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/blurr/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/blurr/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    379\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/blurr/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    461\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m         \"\"\"\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 734.00 MiB (GPU 1; 10.91 GiB total capacity; 9.36 GiB already allocated; 652.25 MiB free; 9.61 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "#slow\n",
    "#hide_output\n",
    "model_cls = AutoModelForSequenceClassification\n",
    "bsz = 2\n",
    "seq_sz = 64\n",
    "\n",
    "test_results = []\n",
    "for model_name in pretrained_model_names:\n",
    "    error=None\n",
    "    \n",
    "    print(f'=== {model_name} ===\\n')\n",
    "    \n",
    "    # 1. get/configure our huggingface objects\n",
    "    tok_class = RobertaTokenizer if ('/ibert' in model_name) else None\n",
    "    \n",
    "    hf_arch, hf_config, hf_tokenizer, hf_model = BLURR.get_hf_objects(model_name, \n",
    "                                                                      model_cls=model_cls, \n",
    "                                                                      tokenizer_cls=tok_class,\n",
    "                                                                      config_kwargs={'num_labels': 2})\n",
    "    \n",
    "    print(f'architecture:\\t{hf_arch}\\ntokenizer:\\t{type(hf_tokenizer).__name__}\\nmodel:\\t\\t{type(hf_model).__name__}\\n')\n",
    "\n",
    "    # not all architectures include a native pad_token (e.g., gpt2, ctrl, etc...), so we add one here\n",
    "    if (hf_tokenizer.pad_token is None): \n",
    "        hf_tokenizer.add_special_tokens({'pad_token': '<pad>'})  \n",
    "        hf_config.pad_token_id = hf_tokenizer.get_vocab()['<pad>']\n",
    "        hf_model.resize_token_embeddings(len(hf_tokenizer))\n",
    "                    \n",
    "    # 2. get our DataLoaders\n",
    "    blocks = (HF_TextBlock(hf_arch, hf_config, hf_tokenizer, hf_model, max_length=seq_sz, padding='max_length'), \n",
    "              CategoryBlock)\n",
    "\n",
    "    dblock = DataBlock(blocks=blocks, \n",
    "                       get_x=ColReader('text'), \n",
    "                       get_y=ColReader('label'), \n",
    "                       splitter=ColSplitter(col='is_valid'))\n",
    "    \n",
    "    dls = dblock.dataloaders(imdb_df, bs=bsz)\n",
    "    \n",
    "    # 3. configure our Learner\n",
    "    model = HF_BaseModelWrapper(hf_model)\n",
    "    learn = Learner(dls, \n",
    "                    model,\n",
    "                    opt_func=partial(Adam),\n",
    "                    loss_func=CrossEntropyLossFlat(),\n",
    "                    metrics=[accuracy],\n",
    "                    cbs=[HF_BaseModelCallback],\n",
    "                    splitter=hf_splitter)\n",
    "\n",
    "    learn.freeze()\n",
    "    \n",
    "    b = dls.one_batch()\n",
    "    \n",
    "    # 4. train\n",
    "    try:\n",
    "        print('*** TESTING DataLoaders ***')\n",
    "        test_eq(len(b), bsz)\n",
    "        test_eq(len(b[0]['input_ids']), bsz)\n",
    "        test_eq(b[0]['input_ids'].shape, torch.Size([bsz, seq_sz]))\n",
    "        test_eq(len(b[1]), bsz)\n",
    "\n",
    "    #         print('*** TESTING One pass through the model ***')\n",
    "    #         preds = learn.model(b[0])\n",
    "    #         test_eq(len(preds[0]), bsz)\n",
    "    #         test_eq(preds[0].shape, torch.Size([bsz, 2]))\n",
    "\n",
    "        print('*** TESTING Training/Results ***')\n",
    "        learn.fit_one_cycle(1, lr_max=1e-3, cbs=ShortEpochCallback(pct=0.2, short_valid=True))\n",
    "\n",
    "        test_results.append((hf_arch, type(hf_tokenizer).__name__, type(hf_model).__name__, 'PASSED', ''))\n",
    "        learn.show_results(learner=learn, max_n=2, trunc_at=250)\n",
    "    except Exception as err:\n",
    "        test_results.append((hf_arch, type(hf_tokenizer).__name__, type(hf_model).__name__, 'FAILED', err))\n",
    "    finally:\n",
    "        # cleanup\n",
    "        del learn; torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arch</th>\n",
       "      <th>tokenizer</th>\n",
       "      <th>model</th>\n",
       "      <th>result</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>albert</td>\n",
       "      <td>AlbertTokenizerFast</td>\n",
       "      <td>AlbertForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bart</td>\n",
       "      <td>BartTokenizerFast</td>\n",
       "      <td>BartForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bert</td>\n",
       "      <td>BertTokenizerFast</td>\n",
       "      <td>BertForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>big_bird</td>\n",
       "      <td>BigBirdTokenizerFast</td>\n",
       "      <td>BigBirdForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ctrl</td>\n",
       "      <td>CTRLTokenizer</td>\n",
       "      <td>CTRLForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>camembert</td>\n",
       "      <td>CamembertTokenizerFast</td>\n",
       "      <td>CamembertForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>convbert</td>\n",
       "      <td>ConvBertTokenizerFast</td>\n",
       "      <td>ConvBertForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>deberta</td>\n",
       "      <td>DebertaTokenizerFast</td>\n",
       "      <td>DebertaForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>deberta_v2</td>\n",
       "      <td>DebertaV2Tokenizer</td>\n",
       "      <td>DebertaV2ForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>distilbert</td>\n",
       "      <td>DistilBertTokenizerFast</td>\n",
       "      <td>DistilBertForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>electra</td>\n",
       "      <td>ElectraTokenizerFast</td>\n",
       "      <td>ElectraForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>flaubert</td>\n",
       "      <td>FlaubertTokenizer</td>\n",
       "      <td>FlaubertForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>funnel</td>\n",
       "      <td>FunnelTokenizerFast</td>\n",
       "      <td>FunnelForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>GPT2TokenizerFast</td>\n",
       "      <td>GPT2ForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ibert</td>\n",
       "      <td>RobertaTokenizer</td>\n",
       "      <td>IBertForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>led</td>\n",
       "      <td>LEDTokenizerFast</td>\n",
       "      <td>LEDForSequenceClassification</td>\n",
       "      <td>FAILED</td>\n",
       "      <td>You have to specify either decoder_input_ids or decoder_inputs_embeds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>layoutlm</td>\n",
       "      <td>LayoutLMTokenizerFast</td>\n",
       "      <td>LayoutLMForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>longformer</td>\n",
       "      <td>LongformerTokenizerFast</td>\n",
       "      <td>LongformerForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>mbart</td>\n",
       "      <td>MBartTokenizerFast</td>\n",
       "      <td>MBartForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>mpnet</td>\n",
       "      <td>MPNetTokenizerFast</td>\n",
       "      <td>MPNetForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>mobilebert</td>\n",
       "      <td>MobileBertTokenizerFast</td>\n",
       "      <td>MobileBertForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>openai</td>\n",
       "      <td>OpenAIGPTTokenizerFast</td>\n",
       "      <td>OpenAIGPTForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>roberta</td>\n",
       "      <td>RobertaTokenizerFast</td>\n",
       "      <td>RobertaForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>squeezebert</td>\n",
       "      <td>SqueezeBertTokenizerFast</td>\n",
       "      <td>SqueezeBertForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>transfo_xl</td>\n",
       "      <td>TransfoXLTokenizer</td>\n",
       "      <td>TransfoXLForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>xlm</td>\n",
       "      <td>XLMTokenizer</td>\n",
       "      <td>XLMForSequenceClassification</td>\n",
       "      <td>PASSED</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#slow\n",
    "#hide_input\n",
    "test_results_df = pd.DataFrame(test_results, columns=['arch', 'tokenizer', 'model', 'result', 'error'])\n",
    "display_df(test_results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_utils.ipynb.\n",
      "Converted 01_data-core.ipynb.\n",
      "Converted 01_modeling-core.ipynb.\n",
      "Converted 02_data-language-modeling.ipynb.\n",
      "Converted 02_modeling-language-modeling.ipynb.\n",
      "Converted 03_data-token-classification.ipynb.\n",
      "Converted 03_modeling-token-classification.ipynb.\n",
      "Converted 04_data-question-answering.ipynb.\n",
      "Converted 04_modeling-question-answering.ipynb.\n",
      "Converted 10_data-seq2seq-core.ipynb.\n",
      "Converted 10_modeling-seq2seq-core.ipynb.\n",
      "Converted 11_data-seq2seq-summarization.ipynb.\n",
      "Converted 11_modeling-seq2seq-summarization.ipynb.\n",
      "Converted 12_data-seq2seq-translation.ipynb.\n",
      "Converted 12_modeling-seq2seq-translation.ipynb.\n",
      "Converted 99a_examples-high-level-api.ipynb.\n",
      "Converted 99b_examples-glue.ipynb.\n",
      "Converted 99c_examples-glue-plain-pytorch.ipynb.\n",
      "Converted 99d_examples-multilabel.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
