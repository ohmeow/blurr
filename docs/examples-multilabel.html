---

title: Multi-label classification


keywords: fastai
sidebar: home_sidebar

summary: "This is an example of how to use blurr for multilabel classification tasks using both the mid and high level Blurr API"
description: "This is an example of how to use blurr for multilabel classification tasks using both the mid and high level Blurr API"
nb_path: "nbs/99d_examples-multilabel.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/99d_examples-multilabel.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Here&#39;s what we&#39;re running with ...

torch: 1.10.1+cu111
fastai: 2.5.3
transformers: 4.16.2
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's start by building our <code>DataBlock</code></p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">raw_datasets</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;civil_comments&quot;</span><span class="p">)</span>
<span class="n">raw_datasets</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>Using custom data configuration default
Reusing dataset civil_comments (/home/wgilliam/.cache/huggingface/datasets/civil_comments/default/0.9.0/e7a3aacd2ab7d135fa958e7209d10b1fa03807d44c486e3c34897aa08ea8ffab)
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>DatasetDict({
    train: Dataset({
        features: [&#39;identity_attack&#39;, &#39;insult&#39;, &#39;obscene&#39;, &#39;severe_toxicity&#39;, &#39;sexual_explicit&#39;, &#39;text&#39;, &#39;threat&#39;, &#39;toxicity&#39;],
        num_rows: 1804874
    })
    validation: Dataset({
        features: [&#39;identity_attack&#39;, &#39;insult&#39;, &#39;obscene&#39;, &#39;severe_toxicity&#39;, &#39;sexual_explicit&#39;, &#39;text&#39;, &#39;threat&#39;, &#39;toxicity&#39;],
        num_rows: 97320
    })
    test: Dataset({
        features: [&#39;identity_attack&#39;, &#39;insult&#39;, &#39;obscene&#39;, &#39;severe_toxicity&#39;, &#39;sexual_explicit&#39;, &#39;text&#39;, &#39;threat&#39;, &#39;toxicity&#39;],
        num_rows: 97320
    })
})</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">raw_train_df</span> <span class="o">=</span> <span class="n">raw_datasets</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">10000</span><span class="p">))</span><span class="o">.</span><span class="n">to_pandas</span><span class="p">()</span>
<span class="n">raw_valid_df</span> <span class="o">=</span> <span class="n">raw_datasets</span><span class="p">[</span><span class="s2">&quot;validation&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">2000</span><span class="p">))</span><span class="o">.</span><span class="n">to_pandas</span><span class="p">()</span>

<span class="c1"># --- Option 2: Full dataset (using the predefined training and validation sets) ---</span>
<span class="c1"># raw_train_df = pd.DataFrame(raw_datasets[&#39;train&#39;], columns=list(raw_datasets[&#39;train&#39;].features.keys()))</span>
<span class="c1"># raw_valid_df = pd.DataFrame(raw_datasets[&#39;validation&#39;], columns=list(raw_datasets[&#39;validation&#39;].features.keys()))</span>

<span class="n">raw_train_df</span><span class="p">[</span><span class="s2">&quot;is_valid&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span>
<span class="n">raw_valid_df</span><span class="p">[</span><span class="s2">&quot;is_valid&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>

<span class="n">toxic_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">raw_train_df</span><span class="p">,</span> <span class="n">raw_valid_df</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">toxic_df</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>Loading cached shuffled indices for dataset at /home/wgilliam/.cache/huggingface/datasets/civil_comments/default/0.9.0/e7a3aacd2ab7d135fa958e7209d10b1fa03807d44c486e3c34897aa08ea8ffab/cache-8b5168c3a65cf5ce.arrow
Loading cached shuffled indices for dataset at /home/wgilliam/.cache/huggingface/datasets/civil_comments/default/0.9.0/e7a3aacd2ab7d135fa958e7209d10b1fa03807d44c486e3c34897aa08ea8ffab/cache-0ee0733b0b10f4a7.arrow
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>12000
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">toxic_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>identity_attack</th>
      <th>insult</th>
      <th>obscene</th>
      <th>severe_toxicity</th>
      <th>sexual_explicit</th>
      <th>text</th>
      <th>threat</th>
      <th>toxicity</th>
      <th>is_valid</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.0</td>
      <td>0.200000</td>
      <td>0.300000</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>Socialists? What the hell does that have to do with climate science? Good grief.</td>
      <td>0.0</td>
      <td>0.300000</td>
      <td>False</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.0</td>
      <td>0.794118</td>
      <td>0.088235</td>
      <td>0.029412</td>
      <td>0.0</td>
      <td>And I always thought that Eric Trump was the dumbest son.  Sorry, Eric!</td>
      <td>0.0</td>
      <td>0.808824</td>
      <td>False</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>I’m disappointed there’s no report from CB on the transportation committee meeting today and the discussion about eminent domain.  It centered on the Bloodbank and the HART CEO’s lack of knowledge that HART filed a lawsuit against the Bloodbank the day before Councilmember Anderson asked about the status of that property (May 16).\n\nTo sum it up, Murthy nor the board knew that HART was suing the Bloodbank.  It’s troubling that a lawsuit can be started without explicit authority from the CEO and board.\n\nThe other part of the discussion that was disappointing was the deputy corporation co...</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>False</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.0</td>
      <td>0.166667</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>Nothing like subsidizing a country that is threatening trade barriers with us.\n\nBut again we are talking about Kathleen and her cronies.  I do love electric cars, but in a province that still allows gas blowing leaf blowers, classic cars that admit 100 times what normal ICE emit, two cycle outboard marine engines, idiotic two cycle jet skis and snowmobiles....and the list goes on and on. If she wants real easy environmental solutions get rid of these dinosaur beasts. Its easy, politically tough in certain jurisdictions, and quit pandering to the US car companies and wealthy individuals w...</td>
      <td>0.0</td>
      <td>0.166667</td>
      <td>False</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>The only way to save the rhino is to legalize the trade in horn and allow the farmers to breed the animals and make a profit. Nobody is seriously thinking that legal trade will satisfy the demand or stop the poaching entirely, but farmers will have enough money to jack up security. Rhino numbers will undoubtedly increase, and isn't that the primary consideration? One thing we know: the ban is a disaster. This entire poaching catastrophe has taken place with the BAN INTACT. We can't be entirely sure what will work, but we know without a doubt what is not working: the BAN. Kill the ban or ki...</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>False</td>
    </tr>
  </tbody>
</table>
</div></div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">lbl_cols</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;identity_attack&quot;</span><span class="p">,</span> <span class="s2">&quot;insult&quot;</span><span class="p">,</span> <span class="s2">&quot;obscene&quot;</span><span class="p">,</span> <span class="s2">&quot;toxicity&quot;</span><span class="p">,</span> <span class="s2">&quot;severe_toxicity&quot;</span><span class="p">,</span> <span class="s2">&quot;sexual_explicit&quot;</span><span class="p">,</span> <span class="s2">&quot;threat&quot;</span><span class="p">]</span>
<span class="n">lbl_cols</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[&#39;identity_attack&#39;,
 &#39;insult&#39;,
 &#39;obscene&#39;,
 &#39;toxicity&#39;,
 &#39;severe_toxicity&#39;,
 &#39;sexual_explicit&#39;,
 &#39;threat&#39;]</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">toxic_df</span> <span class="o">=</span> <span class="n">toxic_df</span><span class="o">.</span><span class="n">round</span><span class="p">({</span><span class="n">col</span><span class="p">:</span> <span class="mi">0</span> <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">lbl_cols</span><span class="p">})</span>
<span class="n">toxic_df</span> <span class="o">=</span> <span class="n">toxic_df</span><span class="o">.</span><span class="n">convert_dtypes</span><span class="p">()</span>

<span class="n">toxic_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>identity_attack</th>
      <th>insult</th>
      <th>obscene</th>
      <th>severe_toxicity</th>
      <th>sexual_explicit</th>
      <th>text</th>
      <th>threat</th>
      <th>toxicity</th>
      <th>is_valid</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>Socialists? What the hell does that have to do with climate science? Good grief.</td>
      <td>0</td>
      <td>0</td>
      <td>False</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>And I always thought that Eric Trump was the dumbest son.  Sorry, Eric!</td>
      <td>0</td>
      <td>1</td>
      <td>False</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>I’m disappointed there’s no report from CB on the transportation committee meeting today and the discussion about eminent domain.  It centered on the Bloodbank and the HART CEO’s lack of knowledge that HART filed a lawsuit against the Bloodbank the day before Councilmember Anderson asked about the status of that property (May 16).

To sum it up, Murthy nor the board knew that HART was suing the Bloodbank.  It’s troubling that a lawsuit can be started without explicit authority from the CEO and board.

The other part of the discussion that was disappointing was the deputy corporation counse...</td>
      <td>0</td>
      <td>0</td>
      <td>False</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>Nothing like subsidizing a country that is threatening trade barriers with us.

But again we are talking about Kathleen and her cronies.  I do love electric cars, but in a province that still allows gas blowing leaf blowers, classic cars that admit 100 times what normal ICE emit, two cycle outboard marine engines, idiotic two cycle jet skis and snowmobiles....and the list goes on and on. If she wants real easy environmental solutions get rid of these dinosaur beasts. Its easy, politically tough in certain jurisdictions, and quit pandering to the US car companies and wealthy individuals who...</td>
      <td>0</td>
      <td>0</td>
      <td>False</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>The only way to save the rhino is to legalize the trade in horn and allow the farmers to breed the animals and make a profit. Nobody is seriously thinking that legal trade will satisfy the demand or stop the poaching entirely, but farmers will have enough money to jack up security. Rhino numbers will undoubtedly increase, and isn't that the primary consideration? One thing we know: the ban is a disaster. This entire poaching catastrophe has taken place with the BAN INTACT. We can't be entirely sure what will work, but we know without a doubt what is not working: the BAN. Kill the ban or ki...</td>
      <td>0</td>
      <td>0</td>
      <td>False</td>
    </tr>
  </tbody>
</table>
</div></div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Mid-level-API">Mid-level API<a class="anchor-link" href="#Mid-level-API"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Step-1:-Build-our-Hugging-Face-objects">Step 1: Build our Hugging Face objects<a class="anchor-link" href="#Step-1:-Build-our-Hugging-Face-objects"> </a></h3><p>For our huggingface model, let's used the distilled version of RoBERTa. This should allow us to train the model on bigger mini-batches without much performance loss.  Even on my 1080Ti, I should be able to train all the parameters (which isn't possible with the <code>roberta-base</code> model)</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model_cls</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span>

<span class="n">pretrained_model_name</span> <span class="o">=</span> <span class="s2">&quot;distilroberta-base&quot;</span>
<span class="n">config</span> <span class="o">=</span> <span class="n">AutoConfig</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">pretrained_model_name</span><span class="p">)</span>
<span class="n">config</span><span class="o">.</span><span class="n">num_labels</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">lbl_cols</span><span class="p">)</span>

<span class="n">hf_arch</span><span class="p">,</span> <span class="n">hf_config</span><span class="p">,</span> <span class="n">hf_tokenizer</span><span class="p">,</span> <span class="n">hf_model</span> <span class="o">=</span> <span class="n">BLURR</span><span class="o">.</span><span class="n">get_hf_objects</span><span class="p">(</span><span class="n">pretrained_model_name</span><span class="p">,</span> <span class="n">model_cls</span><span class="o">=</span><span class="n">model_cls</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">)</span>
<span class="n">hf_model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">problem_type</span> <span class="o">=</span> <span class="s2">&quot;multi_label_classification&quot;</span>

<span class="nb">print</span><span class="p">(</span><span class="n">hf_arch</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">hf_config</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">hf_tokenizer</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">hf_model</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>roberta
&lt;class &#39;transformers.models.roberta.configuration_roberta.RobertaConfig&#39;&gt;
&lt;class &#39;transformers.models.roberta.tokenization_roberta_fast.RobertaTokenizerFast&#39;&gt;
&lt;class &#39;transformers.models.roberta.modeling_roberta.RobertaForSequenceClassification&#39;&gt;
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Note how we have to configure the <code>num_labels</code> to the number of labels we are predicting. Given that our labels are already encoded, we use a <code>MultiCategoryBlock</code> with encoded=True and vocab equal to the columns with our 1's and 0's.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Step-2:-Build-our-DataLoaders">Step 2: Build our <code>DataLoaders</code><a class="anchor-link" href="#Step-2:-Build-our-DataLoaders"> </a></h3>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">blocks</span> <span class="o">=</span> <span class="p">(</span><span class="n">TextBlock</span><span class="p">(</span><span class="n">hf_arch</span><span class="p">,</span> <span class="n">hf_config</span><span class="p">,</span> <span class="n">hf_tokenizer</span><span class="p">,</span> <span class="n">hf_model</span><span class="p">),</span> <span class="n">MultiCategoryBlock</span><span class="p">(</span><span class="n">encoded</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">vocab</span><span class="o">=</span><span class="n">lbl_cols</span><span class="p">))</span>
<span class="n">dblock</span> <span class="o">=</span> <span class="n">DataBlock</span><span class="p">(</span><span class="n">blocks</span><span class="o">=</span><span class="n">blocks</span><span class="p">,</span> <span class="n">get_x</span><span class="o">=</span><span class="n">ColReader</span><span class="p">(</span><span class="s2">&quot;text&quot;</span><span class="p">),</span> <span class="n">get_y</span><span class="o">=</span><span class="n">ColReader</span><span class="p">(</span><span class="n">lbl_cols</span><span class="p">),</span> <span class="n">splitter</span><span class="o">=</span><span class="n">ColSplitter</span><span class="p">())</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dls</span> <span class="o">=</span> <span class="n">dblock</span><span class="o">.</span><span class="n">dataloaders</span><span class="p">(</span><span class="n">toxic_df</span><span class="p">,</span> <span class="n">bs</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">val_bs</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">b</span> <span class="o">=</span> <span class="n">dls</span><span class="o">.</span><span class="n">one_batch</span><span class="p">()</span>
<span class="nb">len</span><span class="p">(</span><span class="n">b</span><span class="p">),</span> <span class="n">b</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">b</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(2, torch.Size([4, 512]), torch.Size([4, 7]))</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Step-3:-Build-our-Learner">Step 3: Build our <code>Learner</code><a class="anchor-link" href="#Step-3:-Build-our-Learner"> </a></h3><p>With our DataLoaders built, we can now build our <code>Learner</code> and train.  We'll use mixed precision so we can train with bigger batches</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">BaseModelWrapper</span><span class="p">(</span><span class="n">hf_model</span><span class="p">)</span>

<span class="n">learn</span> <span class="o">=</span> <span class="n">Learner</span><span class="p">(</span>
    <span class="n">dls</span><span class="p">,</span>
    <span class="n">model</span><span class="p">,</span>
    <span class="n">opt_func</span><span class="o">=</span><span class="n">partial</span><span class="p">(</span><span class="n">Adam</span><span class="p">),</span>
    <span class="n">loss_func</span><span class="o">=</span><span class="n">BCEWithLogitsLossFlat</span><span class="p">(),</span> <span class="c1">#PreCalculatedBCELoss()</span>
    <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="n">partial</span><span class="p">(</span><span class="n">accuracy_multi</span><span class="p">,</span> <span class="n">thresh</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)],</span>
    <span class="n">cbs</span><span class="o">=</span><span class="p">[</span><span class="n">BaseModelCallback</span><span class="p">],</span>
    <span class="n">splitter</span><span class="o">=</span><span class="n">blurr_splitter</span><span class="p">,</span>
<span class="p">)</span><span class="o">.</span><span class="n">to_fp16</span><span class="p">()</span>

<span class="n">learn</span><span class="o">.</span><span class="n">loss_func</span><span class="o">.</span><span class="n">thresh</span> <span class="o">=</span> <span class="mf">0.15</span>
<span class="n">learn</span><span class="o">.</span><span class="n">freeze</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">preds</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">b</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">preds</span><span class="o">.</span><span class="n">logits</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">preds</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(torch.Size([4, 7]),
 SequenceClassifierOutput(loss=TensorMultiCategory(0.6883, device=&#39;cuda:1&#39;, grad_fn=&lt;AliasBackward0&gt;), logits=tensor([[ 0.1167, -0.0263, -0.0486,  0.0855, -0.2629,  0.0408,  0.0399],
         [ 0.1197, -0.0469, -0.0620,  0.1100, -0.3081,  0.0406,  0.0286],
         [ 0.1124, -0.0415, -0.0589,  0.0902, -0.2831,  0.0457,  0.0382],
         [ 0.1143, -0.0424, -0.0541,  0.1056, -0.3118,  0.0455,  0.0257]],
        device=&#39;cuda:1&#39;, grad_fn=&lt;AddmmBackward0&gt;), hidden_states=None, attentions=None))</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Step-4:-Train">Step 4: Train<a class="anchor-link" href="#Step-4:-Train"> </a></h3>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">lr_find</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea "></div>

</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>SuggestedLRs(valley=0.0004786300996784121)</pre>
</div>

</div>

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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"
>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">lr_max</span><span class="o">=</span><span class="mf">1e-2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea "><table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy_multi</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.080708</td>
      <td>0.064087</td>
      <td>0.984928</td>
      <td>01:10</td>
    </tr>
  </tbody>
</table></div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">show_results</span><span class="p">(</span><span class="n">learner</span><span class="o">=</span><span class="n">learn</span><span class="p">,</span> <span class="n">max_n</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea "></div>

</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea "><table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>text</th>
      <th>target</th>
      <th>prediction</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Richard Ellmyer - I think most sane, patriotic Americans hear and agree with your total exasperation at this lawless, ridiculous situation.  However, while I agree I am very disturbed at the approach by the FBI SACs in Nevada and Portland, I think you are missing who is responsible here.  On January 4, the White House made a public announcement that this terrorist takeover of U.S. Federal Government land and buildings was "ultimately a local law enforcement matter."  Then after that, "Obama administration leaders" told Reuters that the Obama administration had "ordered" federal law enforcement not to have a "conflict" with these Sovereign Citizen terrorists in Oregon. So while there is plenty of blame to go around, I think the focus needs to be on the person who is actually making the REAL decisions here, and it is not ultimately FBI Portland SAC.  I urge Oregonians to contact the White House and also presidential candidates and DEMAND a restoral of the rule of law to this anarchic situation.  More children, more citizens are put at risk, and history has shown the failure to act in Nevada in 2014 ultimately cost the lives of other Americans in Las Vegas down the road from such terrorist supporters.  It is time our leadership spends time doing THEIR JOB, not playing political games with media.</td>
      <td>[]</td>
      <td>[]</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Wow-  that was a depressing article. Depressing because of the bishops' unwillingness to treat their priests, or anyone for that matter, as adults. \n\nOur northeast diocese is in a restructuring process. We've been told that no decisions have been made. but if you believe that one, I have a bridge in Brooklyn  I would like to sell you. \n\nDeceptive, devious, and deplorable paternalistic pressure on the priests by the bishop have resulted in a startling corrosive spiral of low moral that I dare say will lead us in the way of the Irish church. \n\nA trending model of US Bishops, raise lots of money, fix up your Cathedral (do not forget nice grounds to attract the people to it ie Crystal Cathedral), close parishes, and restructure central services (a bu## $h!t euphemism for the diocesan curia) so central office can micro-manage parish level activities through a myriad of programs and campaigns hoisted on the parish. Oh I forget, then have a robust charity program so you can justify it all.YAK</td>
      <td>[]</td>
      <td>[]</td>
    </tr>
  </tbody>
</table></div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">unfreeze</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">lr_max</span><span class="o">=</span><span class="nb">slice</span><span class="p">(</span><span class="mf">1e-8</span><span class="p">,</span> <span class="mf">1e-4</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea "><table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy_multi</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.061642</td>
      <td>0.063728</td>
      <td>0.984928</td>
      <td>02:17</td>
    </tr>
  </tbody>
</table></div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">show_results</span><span class="p">(</span><span class="n">learner</span><span class="o">=</span><span class="n">learn</span><span class="p">,</span> <span class="n">max_n</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea "></div>

</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea "><table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>text</th>
      <th>target</th>
      <th>prediction</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Richard Ellmyer - I think most sane, patriotic Americans hear and agree with your total exasperation at this lawless, ridiculous situation.  However, while I agree I am very disturbed at the approach by the FBI SACs in Nevada and Portland, I think you are missing who is responsible here.  On January 4, the White House made a public announcement that this terrorist takeover of U.S. Federal Government land and buildings was "ultimately a local law enforcement matter."  Then after that, "Obama administration leaders" told Reuters that the Obama administration had "ordered" federal law enforcement not to have a "conflict" with these Sovereign Citizen terrorists in Oregon. So while there is plenty of blame to go around, I think the focus needs to be on the person who is actually making the REAL decisions here, and it is not ultimately FBI Portland SAC.  I urge Oregonians to contact the White House and also presidential candidates and DEMAND a restoral of the rule of law to this anarchic situation.  More children, more citizens are put at risk, and history has shown the failure to act in Nevada in 2014 ultimately cost the lives of other Americans in Las Vegas down the road from such terrorist supporters.  It is time our leadership spends time doing THEIR JOB, not playing political games with media.</td>
      <td>[]</td>
      <td>[]</td>
    </tr>
    <tr>
      <th>1</th>
      <td>The answer is "no". We are not going to work longer. There is no need for our labor, since the US has a surplus of workers, while jobs are being outsourced and automated. Working-class people wear out, as do many who sit at a desk. You get to the point where you want to do something else with your life besides going to work every day, especially if you get little satisfaction, or money, from your work. After 50 few employers want to hire us. We can't compete with younger workers, especially if our work is physical. \n\nMany of us who are retired contribute to society as volunteers, doing something we actually care about and are good at, instead of what people are willing to pay for, which also helps keep our minds active. As a volunteer you can limit your effort to what you aging body can handle.\n\nWhat Samuelson is really about is cutting the payroll taxes that pay for Social Security and Medicare, so that rich people can make even more money. Not something us common folk should support.</td>
      <td>[]</td>
      <td>[]</td>
    </tr>
  </tbody>
</table></div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">loss_func</span><span class="o">.</span><span class="n">thresh</span> <span class="o">=</span> <span class="mf">0.02</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">comment</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">Those damned affluent white people should only eat their own food, like cod cakes and boiled potatoes. </span>
<span class="s2">No enchiladas for them!</span>
<span class="s2">&quot;&quot;&quot;</span>
<span class="n">learn</span><span class="o">.</span><span class="n">blurr_predict</span><span class="p">(</span><span class="n">comment</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[{&#39;labels&#39;: [&#39;insult&#39;, &#39;toxicity&#39;],
  &#39;scores&#39;: [0.04031343758106232, 0.0572819747030735],
  &#39;class_indices&#39;: [0, 1, 0, 1, 0, 0, 0],
  &#39;class_labels&#39;: [&#39;identity_attack&#39;, &#39;insult&#39;, &#39;obscene&#39;, &#39;toxicity&#39;, &#39;severe_toxicity&#39;, &#39;sexual_explicit&#39;, &#39;threat&#39;],
  &#39;probs&#39;: [0.0031480707693845034,
   0.04031343758106232,
   0.00482972152531147,
   0.0572819747030735,
   4.289332991902484e-06,
   0.0010403185151517391,
   0.00031999824568629265]}]</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">preds</span><span class="p">,</span> <span class="n">targs</span><span class="p">,</span> <span class="n">losses</span> <span class="o">=</span> <span class="n">learn</span><span class="o">.</span><span class="n">get_preds</span><span class="p">(</span><span class="n">with_loss</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">preds</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">targs</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">losses</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea "></div>

</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(torch.Size([2000, 7]), torch.Size([2000, 7]), torch.Size([2000]))</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="High-level-API">High-level API<a class="anchor-link" href="#High-level-API"> </a></h2><p>With the high-level API, we can create our DataBlock, DataLoaders, and Blearner in one line of code</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Step-1:-Build-our-Hugging-Face-objects">Step 1: Build our Hugging Face objects<a class="anchor-link" href="#Step-1:-Build-our-Hugging-Face-objects"> </a></h3>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model_cls</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span>

<span class="n">pretrained_model_name</span> <span class="o">=</span> <span class="s2">&quot;distilroberta-base&quot;</span>
<span class="n">config</span> <span class="o">=</span> <span class="n">AutoConfig</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">pretrained_model_name</span><span class="p">)</span>
<span class="n">config</span><span class="o">.</span><span class="n">num_labels</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">lbl_cols</span><span class="p">)</span>

<span class="n">hf_arch</span><span class="p">,</span> <span class="n">hf_config</span><span class="p">,</span> <span class="n">hf_tokenizer</span><span class="p">,</span> <span class="n">hf_model</span> <span class="o">=</span> <span class="n">BLURR</span><span class="o">.</span><span class="n">get_hf_objects</span><span class="p">(</span><span class="n">pretrained_model_name</span><span class="p">,</span> <span class="n">model_cls</span><span class="o">=</span><span class="n">model_cls</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">)</span>
<span class="n">hf_model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">problem_type</span> <span class="o">=</span> <span class="s2">&quot;multi_label_classification&quot;</span>

<span class="nb">print</span><span class="p">(</span><span class="n">hf_arch</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">hf_config</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">hf_tokenizer</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">hf_model</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>roberta
&lt;class &#39;transformers.models.roberta.configuration_roberta.RobertaConfig&#39;&gt;
&lt;class &#39;transformers.models.roberta.tokenization_roberta_fast.RobertaTokenizerFast&#39;&gt;
&lt;class &#39;transformers.models.roberta.modeling_roberta.RobertaForSequenceClassification&#39;&gt;
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Step-2:-Configure-our-BlearnerForSequenceClassification">Step 2: Configure our <a href="/blurr/modeling-core.html#BlearnerForSequenceClassification"><code>BlearnerForSequenceClassification</code></a><a class="anchor-link" href="#Step-2:-Configure-our-BlearnerForSequenceClassification"> </a></h3>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span> <span class="o">=</span> <span class="n">BlearnerForSequenceClassification</span><span class="o">.</span><span class="n">from_data</span><span class="p">(</span>
    <span class="n">toxic_df</span><span class="p">,</span> <span class="n">pretrained_model_name</span><span class="p">,</span> <span class="n">text_attr</span><span class="o">=</span><span class="s2">&quot;text&quot;</span><span class="p">,</span> <span class="n">label_attr</span><span class="o">=</span><span class="n">lbl_cols</span><span class="p">,</span> <span class="n">dl_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;bs&quot;</span><span class="p">:</span> <span class="mi">4</span><span class="p">}</span>
<span class="p">)</span>

<span class="n">learn</span><span class="o">.</span><span class="n">loss_func</span><span class="o">.</span><span class="n">thresh</span> <span class="o">=</span> <span class="mf">0.1</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Step-3:-Train">Step 3: Train<a class="anchor-link" href="#Step-3:-Train"> </a></h3>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">fit_one_cycle</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">lr_max</span><span class="o">=</span><span class="mf">1e-2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea "><table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>f1_score</th>
      <th>accuracy_multi</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.075515</td>
      <td>0.064132</td>
      <td>0.000000</td>
      <td>0.984928</td>
      <td>01:04</td>
    </tr>
  </tbody>
</table></div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/home/wgilliam/miniconda3/envs/blurr/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, &#34;true nor predicted&#34;, &#34;F-score is&#34;, len(true_sum))
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">show_results</span><span class="p">(</span><span class="n">learner</span><span class="o">=</span><span class="n">learn</span><span class="p">,</span> <span class="n">max_n</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea "></div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/home/wgilliam/miniconda3/envs/blurr/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, &#34;true nor predicted&#34;, &#34;F-score is&#34;, len(true_sum))
</pre>
</div>
</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea "><table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>text</th>
      <th>target</th>
      <th>prediction</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Richard Ellmyer - I think most sane, patriotic Americans hear and agree with your total exasperation at this lawless, ridiculous situation.  However, while I agree I am very disturbed at the approach by the FBI SACs in Nevada and Portland, I think you are missing who is responsible here.  On January 4, the White House made a public announcement that this terrorist takeover of U.S. Federal Government land and buildings was "ultimately a local law enforcement matter."  Then after that, "Obama administration leaders" told Reuters that the Obama administration had "ordered" federal law enforcement not to have a "conflict" with these Sovereign Citizen terrorists in Oregon. So while there is plenty of blame to go around, I think the focus needs to be on the person who is actually making the REAL decisions here, and it is not ultimately FBI Portland SAC.  I urge Oregonians to contact the White House and also presidential candidates and DEMAND a restoral of the rule of law to this anarchic situation.  More children, more citizens are put at risk, and history has shown the failure to act in Nevada in 2014 ultimately cost the lives of other Americans in Las Vegas down the road from such terrorist supporters.  It is time our leadership spends time doing THEIR JOB, not playing political games with media.</td>
      <td>[]</td>
      <td>[]</td>
    </tr>
    <tr>
      <th>1</th>
      <td>PAC money of $30 million being spent on Strange, compared to Moore's $3 million. So, basically, Trump handled his support for Strange correctly, by NOT attacking Moore, and essentially telling Alabama that they could vote for whom they wanted, although supporting Strange by saying that he wanted Strange, and that Strange was getting a bum wrap on the Bently scandal, and the rap that Strange was McConnell's puppet. \n\nHowever, Breitbart launched a scorched earth campaign for Moore and against Strange. Strange was the Swamp candidate, who had been a D.C. lobbyist for 20 years. \n\nAfter Trump's rally for Strange, the last polls seemed to be indicating that his appearance didn't have a lot of effect. It is hard to say how much effect trump had. The last poll done just before the election showed Moore up 16 points, while the average poll over the past many weeks was showing Moore up 8-10 points, and the result from the election was a bit over 9 points.\n\nBannon of Breitabrt, and Trump's key...</td>
      <td>[]</td>
      <td>[]</td>
    </tr>
  </tbody>
</table></div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">loss_func</span><span class="o">.</span><span class="n">thresh</span> <span class="o">=</span> <span class="mf">0.01</span>

<span class="n">comment</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">Those damned affluent white people should only eat their own food, like cod cakes and boiled potatoes. </span>
<span class="s2">No enchiladas for them!</span>
<span class="s2">&quot;&quot;&quot;</span>
<span class="n">learn</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">comment</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[{&#39;labels&#39;: [&#39;insult&#39;, &#39;toxicity&#39;],
  &#39;scores&#39;: [0.05178017541766167, 0.07180110365152359],
  &#39;class_indices&#39;: [0, 1, 0, 1, 0, 0, 0],
  &#39;class_labels&#39;: [&#39;identity_attack&#39;, &#39;insult&#39;, &#39;obscene&#39;, &#39;toxicity&#39;, &#39;severe_toxicity&#39;, &#39;sexual_explicit&#39;, &#39;threat&#39;],
  &#39;probs&#39;: [0.003337000496685505,
   0.05178017541766167,
   0.00497784186154604,
   0.07180110365152359,
   2.178122038287711e-08,
   0.0006545696523971856,
   0.001216338132508099]}]</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">preds</span><span class="p">,</span> <span class="n">targs</span> <span class="o">=</span> <span class="n">learn</span><span class="o">.</span><span class="n">get_preds</span><span class="p">(</span><span class="n">with_loss</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">preds</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">targs</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea "></div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/home/wgilliam/miniconda3/envs/blurr/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, &#34;true nor predicted&#34;, &#34;F-score is&#34;, len(true_sum))
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(torch.Size([2000, 7]), torch.Size([2000, 7]))</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Low-level-API">Low-level API<a class="anchor-link" href="#Low-level-API"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Step-1:-Build-our-Hugging-Face-objects">Step 1: Build our Hugging Face objects<a class="anchor-link" href="#Step-1:-Build-our-Hugging-Face-objects"> </a></h3>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model_cls</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span>

<span class="n">pretrained_model_name</span> <span class="o">=</span> <span class="s2">&quot;distilroberta-base&quot;</span>
<span class="n">config</span> <span class="o">=</span> <span class="n">AutoConfig</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">pretrained_model_name</span><span class="p">)</span>
<span class="n">config</span><span class="o">.</span><span class="n">num_labels</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">lbl_cols</span><span class="p">)</span>

<span class="n">hf_arch</span><span class="p">,</span> <span class="n">hf_config</span><span class="p">,</span> <span class="n">hf_tokenizer</span><span class="p">,</span> <span class="n">hf_model</span> <span class="o">=</span> <span class="n">BLURR</span><span class="o">.</span><span class="n">get_hf_objects</span><span class="p">(</span><span class="n">pretrained_model_name</span><span class="p">,</span> <span class="n">model_cls</span><span class="o">=</span><span class="n">model_cls</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">)</span>
<span class="n">hf_model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">problem_type</span> <span class="o">=</span> <span class="s2">&quot;multi_label_classification&quot;</span>

<span class="nb">print</span><span class="p">(</span><span class="n">hf_arch</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">hf_config</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">hf_tokenizer</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">hf_model</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>roberta
&lt;class &#39;transformers.models.roberta.configuration_roberta.RobertaConfig&#39;&gt;
&lt;class &#39;transformers.models.roberta.tokenization_roberta_fast.RobertaTokenizerFast&#39;&gt;
&lt;class &#39;transformers.models.roberta.modeling_roberta.RobertaForSequenceClassification&#39;&gt;
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Step-2:-Prepare-your-dataset">Step 2: Prepare your dataset<a class="anchor-link" href="#Step-2:-Prepare-your-dataset"> </a></h3><p>We'll create a <code>labels</code> column that includes the OHE labels for each example. The raw values come in the form of probabilities ranging from 0. to 1., so we simply round those &gt;= .51 to 1.0, else set it to 0. for our purposes here</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">raw_datasets</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;civil_comments&quot;</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;train[:1000]&quot;</span><span class="p">,</span> <span class="s2">&quot;validation[:500]&quot;</span><span class="p">])</span>
<span class="n">raw_datasets</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>Using custom data configuration default
Reusing dataset civil_comments (/home/wgilliam/.cache/huggingface/datasets/civil_comments/default/0.9.0/e7a3aacd2ab7d135fa958e7209d10b1fa03807d44c486e3c34897aa08ea8ffab)
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[Dataset({
     features: [&#39;identity_attack&#39;, &#39;insult&#39;, &#39;obscene&#39;, &#39;severe_toxicity&#39;, &#39;sexual_explicit&#39;, &#39;text&#39;, &#39;threat&#39;, &#39;toxicity&#39;],
     num_rows: 1000
 }),
 Dataset({
     features: [&#39;identity_attack&#39;, &#39;insult&#39;, &#39;obscene&#39;, &#39;severe_toxicity&#39;, &#39;sexual_explicit&#39;, &#39;text&#39;, &#39;threat&#39;, &#39;toxicity&#39;],
     num_rows: 500
 })]</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">tokenize_function</span><span class="p">(</span><span class="n">example</span><span class="p">):</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="n">hf_tokenizer</span><span class="p">(</span><span class="n">example</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">targets</span> <span class="o">=</span> <span class="p">[</span>
        <span class="nb">float</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">example</span><span class="p">[</span><span class="n">lbl</span><span class="p">]))</span> <span class="k">for</span> <span class="n">lbl</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;identity_attack&quot;</span><span class="p">,</span> <span class="s2">&quot;insult&quot;</span><span class="p">,</span> <span class="s2">&quot;obscene&quot;</span><span class="p">,</span> <span class="s2">&quot;severe_toxicity&quot;</span><span class="p">,</span> <span class="s2">&quot;sexual_explicit&quot;</span><span class="p">,</span> <span class="s2">&quot;threat&quot;</span><span class="p">,</span> <span class="s2">&quot;toxicity&quot;</span><span class="p">]</span>
    <span class="p">]</span>
    <span class="k">return</span> <span class="p">{</span><span class="o">**</span><span class="n">inputs</span><span class="p">,</span> <span class="o">**</span><span class="p">{</span><span class="s2">&quot;labels&quot;</span><span class="p">:</span> <span class="n">targets</span><span class="p">}}</span>


<span class="n">tokenized_datasets</span> <span class="o">=</span> <span class="p">[</span><span class="n">ds</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="k">for</span> <span class="n">ds</span> <span class="ow">in</span> <span class="n">raw_datasets</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>Loading cached processed dataset at /home/wgilliam/.cache/huggingface/datasets/civil_comments/default/0.9.0/e7a3aacd2ab7d135fa958e7209d10b1fa03807d44c486e3c34897aa08ea8ffab/cache-4194376abb79b824.arrow
Loading cached processed dataset at /home/wgilliam/.cache/huggingface/datasets/civil_comments/default/0.9.0/e7a3aacd2ab7d135fa958e7209d10b1fa03807d44c486e3c34897aa08ea8ffab/cache-c46fb51b55074122.arrow
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Step-3:-Build-our-DataLoaders">Step 3: Build our <code>DataLoaders</code><a class="anchor-link" href="#Step-3:-Build-our-DataLoaders"> </a></h3><p>By assigning the aforementioned labels to the <code>label_names</code> argument of our <a href="/blurr/data-core.html#BlurrDataLoader"><code>BlurrDataLoader</code></a>s, we get the friendly label printed when we run <code>show_batch</code> or <code>show_results</code> intead of the label's index.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">label_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;identity_attack&quot;</span><span class="p">,</span> <span class="s2">&quot;insult&quot;</span><span class="p">,</span> <span class="s2">&quot;obscene&quot;</span><span class="p">,</span> <span class="s2">&quot;severe_toxicity&quot;</span><span class="p">,</span> <span class="s2">&quot;sexual_explicit&quot;</span><span class="p">,</span> <span class="s2">&quot;threat&quot;</span><span class="p">,</span> <span class="s2">&quot;toxicity&quot;</span><span class="p">]</span>

<span class="n">trn_dl</span> <span class="o">=</span> <span class="n">BlurrDataLoader</span><span class="p">(</span>
    <span class="n">tokenized_datasets</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
    <span class="n">hf_arch</span><span class="o">=</span><span class="n">hf_arch</span><span class="p">,</span>
    <span class="n">hf_config</span><span class="o">=</span><span class="n">hf_config</span><span class="p">,</span>
    <span class="n">hf_tokenizer</span><span class="o">=</span><span class="n">hf_tokenizer</span><span class="p">,</span>
    <span class="n">hf_model</span><span class="o">=</span><span class="n">hf_model</span><span class="p">,</span>
    <span class="n">preproccesing_func</span><span class="o">=</span><span class="n">preproc_hf_dataset</span><span class="p">,</span>
    <span class="n">batch_decode_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;labels&quot;</span><span class="p">:</span> <span class="n">label_names</span><span class="p">},</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">val_dl</span> <span class="o">=</span> <span class="n">BlurrDataLoader</span><span class="p">(</span>
    <span class="n">tokenized_datasets</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
    <span class="n">hf_arch</span><span class="o">=</span><span class="n">hf_arch</span><span class="p">,</span>
    <span class="n">hf_config</span><span class="o">=</span><span class="n">hf_config</span><span class="p">,</span>
    <span class="n">hf_tokenizer</span><span class="o">=</span><span class="n">hf_tokenizer</span><span class="p">,</span>
    <span class="n">hf_model</span><span class="o">=</span><span class="n">hf_model</span><span class="p">,</span>
    <span class="n">preproccesing_func</span><span class="o">=</span><span class="n">preproc_hf_dataset</span><span class="p">,</span>
    <span class="n">batch_decode_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;labels&quot;</span><span class="p">:</span> <span class="n">label_names</span><span class="p">},</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">dls</span> <span class="o">=</span> <span class="n">DataLoaders</span><span class="p">(</span><span class="n">trn_dl</span><span class="p">,</span> <span class="n">val_dl</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">b</span> <span class="o">=</span> <span class="n">dls</span><span class="o">.</span><span class="n">one_batch</span><span class="p">()</span>
<span class="n">b</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">b</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(torch.Size([8, 161]), torch.Size([8, 7]))</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dls</span><span class="o">.</span><span class="n">show_batch</span><span class="p">(</span><span class="n">dataloaders</span><span class="o">=</span><span class="n">dls</span><span class="p">,</span> <span class="n">max_n</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">trunc_at</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea "><table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>text</th>
      <th>target</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>It's great that Civil is a local Portland startup.  YAY for the home team!</td>
      <td>[]</td>
    </tr>
    <tr>
      <th>1</th>
      <td>I have some news for our Govenor, oregon does not stop at the cascades.  I live in Bend, and the cost of living here is just as much if not more than Portland.  To suggest that Portlander's deserve a higher minimum wage than the rest of the state is preposterous.</td>
      <td>[]</td>
    </tr>
  </tbody>
</table></div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Step-4:-Train">Step 4: Train<a class="anchor-link" href="#Step-4:-Train"> </a></h3>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">BaseModelWrapper</span><span class="p">(</span><span class="n">hf_model</span><span class="p">)</span>

<span class="n">learn</span> <span class="o">=</span> <span class="n">Learner</span><span class="p">(</span>
    <span class="n">dls</span><span class="p">,</span>
    <span class="n">model</span><span class="p">,</span>
    <span class="n">opt_func</span><span class="o">=</span><span class="n">partial</span><span class="p">(</span><span class="n">Adam</span><span class="p">),</span>
    <span class="n">loss_func</span><span class="o">=</span><span class="n">PreCalculatedBCELoss</span><span class="p">(),</span>
    <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="n">partial</span><span class="p">(</span><span class="n">accuracy_multi</span><span class="p">,</span> <span class="n">thresh</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)],</span>
    <span class="n">cbs</span><span class="o">=</span><span class="p">[</span><span class="n">BaseModelCallback</span><span class="p">],</span>
    <span class="n">splitter</span><span class="o">=</span><span class="n">blurr_splitter</span><span class="p">,</span>
<span class="p">)</span><span class="o">.</span><span class="n">to_fp16</span><span class="p">()</span>

<span class="n">learn</span><span class="o">.</span><span class="n">loss_func</span><span class="o">.</span><span class="n">thresh</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="n">learn</span><span class="o">.</span><span class="n">freeze</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mf">1e-2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea "><table border="1" class="dataframe">
  <thead>
    <tr style="text-align: left;">
      <th>epoch</th>
      <th>train_loss</th>
      <th>valid_loss</th>
      <th>accuracy_multi</th>
      <th>time</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>0.091192</td>
      <td>0.116662</td>
      <td>0.983714</td>
      <td>00:10</td>
    </tr>
  </tbody>
</table></div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span><span class="o">.</span><span class="n">show_results</span><span class="p">(</span><span class="n">learner</span><span class="o">=</span><span class="n">learn</span><span class="p">,</span> <span class="n">max_n</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea "></div>

</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea "><table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>text</th>
      <th>target</th>
      <th>prediction</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>You mean another chance to self promote? Too late for that. Can we have our money back?</td>
      <td>[]</td>
      <td>[]</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Just out of curiosity, do you judge political candidates by their athletic prowess -- cause that would make as much sense.</td>
      <td>[]</td>
      <td>[]</td>
    </tr>
  </tbody>
</table></div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Summary">Summary<a class="anchor-link" href="#Summary"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>If your sequence classification model isn't training, make sure you have set the <code>num_labels</code> correctly (95% of the time this is the culprit).  And with this example, you can see that Blurr can make both your multiclassification and multilabel classification tasks a breeze.</p>

</div>
</div>
</div>
</div>
 

